#!/usr/bin/env python3

from peakhood import hoodlib
import numpy as np
import statistics
import argparse
import random
import uuid
import sys
import re
import os

__version__ = "0.1"

"""
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~ OPEN FOR BUSINESS ~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


AuthoR: uhlm [at] informatik [dot] uni-freiburg [dot] de


~~~~~~~~~~~~~~~~~~~~~~~~~~
Check out available modes
~~~~~~~~~~~~~~~~~~~~~~~~~~

peakhood -h


~~~~~~~~~~~~~
Run doctests
~~~~~~~~~~~~~

cd peakhood
python3 -m doctest hoodlib.py


"""


################################################################################

def setup_argument_parser():
    """Setup argparse parser."""
    # Tool description text.
    help_description = """

    Authentic site context extraction for CLIP-Seq peak regions.

    """

    # Define argument parser.
    p = argparse.ArgumentParser(#add_help=False,
                                prog="peakhood",
                                description=help_description)

    # Tool version.
    p.add_argument("-v", "--version", action="version",
                   version="peakhood v" + __version__)

    # Add subparsers.
    subparsers = p.add_subparsers(help='Program modes')

    """
    Context extraction mode.
    """
    p_ex = subparsers.add_parser('extract',
                                  help='Site context extraction')
    p_ex.set_defaults(which='extract')
    # Add required arguments group.
    p_exm = p_ex.add_argument_group("required arguments")
    # Required arguments for extract.
    p_exm.add_argument("--in",
                   dest="in_bed",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Genomic CLIP-seq peak regions file in BED format (6-column BED)")
    p_exm.add_argument("--bam",
                   dest="list_bam",
                   type=str,
                   metavar='str',
                   nargs='+',
                   required = True,
                   help="BAM file or list of BAM files (--bam rep1.bam rep2.bam .. ) containing CLIP-seq library reads used for estimating --in site context")
    p_exm.add_argument("--gtf",
                   dest="in_gtf",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Genomic annotations GTF file (.gtf or .gtf.gz)")
    p_exm.add_argument("--gen",
                   dest="in_2bit",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Genomic sequences .2bit file")
    p_exm.add_argument("--out",
                   dest="out_folder",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Site context extraction results output folder")

    # Optional arguments for extract.
    p_ex.add_argument("--site-id",
                   dest="list_site_ids",
                   type=str,
                   metavar='str',
                   nargs='+',
                   default=False,
                   help = "Provide site ID(s) from --in (BED column 4) (e.g. --site-id CLIP85 CLIP124 ) and run peakhood extract only for these regions")
    p_ex.add_argument("--thr",
                   dest="sc_thr",
                   type = float,
                   metavar='float',
                   default = None,
                   help = "Minimum site score (--in BED column 5) for filtering (assuming higher score == better site) (default: None)")
    p_ex.add_argument("--thr-rev-filter",
                   dest="rev_filter",
                   default = False,
                   action = "store_true",
                   help = "Reverse --thr filtering (i.e. the lower the better, e.g. for p-values) (default: False)")
    p_ex.add_argument("--max-len",
                   dest = "max_len",
                   type = int,
                   metavar='int',
                   default = 250,
                   help = "Maximum length of --in sites (default: 250)")
    p_ex.add_argument("--min-exon-overlap",
                   dest = "min_eol",
                   type = float,
                   metavar='float',
                   default = 0.9,
                   help = "Minimum exon overlap of a site to be considered for transcript context extraction (intersectBed -f parameter) (default: 0.9)")
    p_ex.add_argument("--min-ei-ratio",
                   dest = "min_ei_ratio",
                   type = float,
                   metavar='float',
                   default = 4,
                   help = "Minimum exon to neighboring intron coverage for exonic site to be reported as exonic site with transcript context (default: 4)")
    p_ex.add_argument("--min-eib-ratio",
                   dest = "min_eib_ratio",
                   type = float,
                   metavar='float',
                   default = 4,
                   help = "Minimum exon border to neighboring intron border region coverage for an exon to be considered for transcript context selection (default: 4)")
    p_ex.add_argument("--eib-width",
                   dest = "eib_width",
                   type = int,
                   metavar='int',
                   default = 20,
                   help = "Width of exon-intron border regions (EIB) to calculate coverage drops from exon to intron region (default: 20)")
    p_ex.add_argument("--eibr-mode",
                   dest="eib_ratio_mode",
                   type = int,
                   default = 1,
                   choices = [1,2],
                   help = "How to extract the exon-intron border ratio of an exon. 1: return the exon-intro border ratio with the higher coverage. 2: average the two exon-intron border ratios of the exon (default: 1)")
    p_ex.add_argument("--no-eibr-filter",
                   dest="no_eibr_filter",
                   default = False,
                   action = "store_true",
                   help = "Disable exon-intron border ratio (EIBR) filtering of exons. By default, exons with low EIBR are not considered for transcript context selection")
    p_ex.add_argument("--no-eir-wt-filter",
                   dest="no_eir_wt_filter",
                   default = False,
                   action = "store_true",
                   help = "Disable exon-intron ratio filtering by checking the ratios of whole transcripts (all transcript exons)")
    p_ex.add_argument("--no-eibr-wt-filter",
                   dest="no_eibr_wt_filter",
                   default = False,
                   action = "store_true",
                   help = "Disable exon-intron border ratio filtering by checking the ratios of whole transcripts (all transcript exons)")
    p_ex.add_argument("--bam-pp-mode",
                   dest="bam_pp_mode",
                   type = int,
                   default = 1,
                   choices = [1,2,3],
                   help = "Define type of preprocessing for read-in --bam files. 1: no preprocessing (just merge if several given). 2: use only R2 reads for site context extraction (for eCLIP data) 3: use only R1 reads for site context extraction (e.g. for iCLIP data) (default: 1)")
    p_ex.add_argument("--read-pos-mode",
                   dest="read_pos_mode",
                   type = int,
                   default = 1,
                   choices = [1,2,3],
                   help = "Define which BAM read part to take for overlap and coverage calculations. 1: full-length read. 2: 5' end of the read. 2: center position of the read (default: 1)")
    p_ex.add_argument("--tbt-filter-ids",
                   dest="list_tbt_filter_ids",
                   type=str,
                   metavar='str',
                   nargs='+',
                   default=False,
                   help = "Manually provide transcript biotype ID(s) to filter out transcripts with these biotypes (e.g. --tbt-filter-ids nonsense_mediated_decay retained_intron non_stop_decay). By default, \"nonsense_mediated_decay\", \"retained_intron\", \"non_stop_decay\", and \"processed_transcript\" are used for filtering")
    p_ex.add_argument("--no-biotype-filter",
                   dest="no_tbt_filter",
                   default = False,
                   action = "store_true",
                   help = "Disable transcript biotype filter. By default, if biotype information is given inside --gtf, transcripts with biotypes \"nonsense_mediated_decay\", \"retained_intron\", \"non_stop_decay\", and \"processed_transcript\" are not considered for transcript context selection")
    p_ex.add_argument("--discard-single-ex-tr",
                   dest="discard_single_ex_tr",
                   default = False,
                   action = "store_true",
                   help = "Exclude single exon transcripts from transcript context selection (default: False)")
    p_ex.add_argument("--isr-ext-mode",
                   dest = "isr_ext_mode",
                   type = int,
                   default = 1,
                   choices = [1,2],
                   help = "Define which portions of intron-spanning reads to use for overlap calculations. 1: use whole matching region. 2: use end positions only (at exon ends). If 1 is set, maximum region length is further controlled by --isr-max-reg-len (default: 1)")
    p_ex.add_argument("--isr-max-reg-len",
                   dest = "isr_max_reg_len",
                   type = int,
                   metavar='int',
                   default = 10,
                   help = "Set maximum region length for intron-spanning read matches. This means that if intron-spanning read match on exon is 15, and --isr-max-reg-len 10, shorten the match region to 10. Set to 0 to deactivate, i.e., always use full match lengths for coverage calculations (default: 10)")
    p_ex.add_argument("--no-isr-double-count",
                   dest="no_isr_double_count",
                   default = False,
                   action = "store_true",
                   help = "Do not count intron-spanning reads twice for intron-exon coverage calculations (default: False)")
    p_ex.add_argument("--no-isr-sub-count",
                   dest="no_isr_sub_count",
                   default = False,
                   action = "store_true",
                   help = "Do not substract the intron-spanning read count from the intronic read count of the intron for intron-exon coverage calculations (default: False)")
    p_ex.add_argument("--min-exbs-isr-c",
                   dest="min_exbs_isr_c",
                   type = int,
                   metavar='int',
                   default = 2,
                   help = "Minimum intron-spanning read count to connect two sites at adjacent exon borders. Exon border sites featuring >= --min-exbs-isr-c will be merged into one site (default: 2)")
    p_ex.add_argument("--no-tis-filter",
                   dest="no_tis_filter",
                   default = False,
                   action = "store_true",
                   help = "Do not discard transcripts containing intronic sites from transcript context selection")
    p_ex.add_argument("--min-tis-sites",
                   dest = "min_n_tis_sites",
                   type = int,
                   metavar='int',
                   default = 3,
                   help = "Minimum number of intronic sites needed per transcript to assign all sites on the transcript to genomic context (default: 2)")
    p_ex.add_argument("--f1-filter",
                   dest="list_f1_filter",
                   type=str,
                   metavar='str',
                   nargs='+',
                   default=False,
                   help="Define F1 filters to be applied for F1 transcript selection filtering (F1: sequential filtering). e.g. --f1-filter TSC ISRN (order matters!) (default: TSC)")
    p_ex.add_argument("--no-f1-filter",
                   dest="no_f1_filter",
                   default = False,
                   action = "store_true",
                   help = "Disable F1 sequential filtering step")
    p_ex.add_argument("--f2-filter",
                   dest="list_f2_filter",
                   type=str,
                   metavar='str',
                   nargs='+',
                   default=False,
                   help="Define F2 filters to be applied for F2 transcript selection filtering (F2: sequential or majority vote filtering, set with --f2-mode). Set order matters only if --f2-mode 2 (default: EIR ISRN ISR ISRFC SEO FUCO TCOV)")
    p_ex.add_argument("--f2-mode",
                   dest="f2_mode",
                   type = int,
                   default = 1,
                   choices = [1,2],
                   help = "Define transcript selection strategy for a given exonic site during F2 filtering. (1) majority vote filtering, (2) sequential filtering. (default: 1)")
    p_ex.add_argument("--isrn-prefilter",
                   dest="isrn_prefilter",
                   type = int,
                   metavar='int',
                   default = False,
                   help = "Enable prefilerting of exons (before F1, F2) by exon neigbhorhood intron-spanning read count. A minimum number of intron-spanning reads to neighboring exons has to be provided, e.g. --isr-prefilter 5 (default: False)")
    p_ex.add_argument("--merge-mode",
                   dest="merge_mode",
                   type = int,
                   default = 1,
                   choices = [1,2],
                   help = "Defines whether or how to merge nearby sites before applying --seq-ext. The merge operation is done separately for genomic and transcript context sites, AFTER extracting transcript context extraction. For pre-merging check out --pre-merge option. (1) Do NOT merge sites, (2) merge overlapping and adjacent sites (merge distance controlled by --merge-ext). For an overlapping set of sites, the site with highest column 5 BED score is chosen, and the others discarded. NOTE that if no BED scores are given, merge is done by alphabetical ordering of site IDs (default: 1)")
    p_ex.add_argument("--merge-ext",
                   dest="merge_ext",
                   type = int,
                   metavar='int',
                   default = 0,
                   help = "Extend regions by --merge-ext before merging overlapping regions (if --merge-mode 2) (default: 0)")
    p_ex.add_argument("--pre-merge",
                   dest="pre_merge",
                   default = False,
                   action = "store_true",
                   help = "Merge book-ended and overlapping --in sites BEFORE transcript context extraction. In contrast to --merge-mode 2, do not choose the best site from a set of overlapping sites, but keep the entire region for each overlapping set")
    p_ex.add_argument("--seq-ext-mode",
                   dest="seq_ext_mode",
                   type = int,
                   default = 1,
                   choices = [1,2,3],
                   help = "Define mode for site context sequence extraction after determining context. (1) Take the complete site, (2) Take the center of each site, (3) Take the upstream end for each site (default: 1)")
    p_ex.add_argument("--seq-ext",
                   dest = "seq_ext",
                   type = int,
                   metavar='int',
                   default = 0,
                   help = "Up- and downstream sequence extension length of sites (site definition by --seq-ext-mode) (default: 0)")
    p_ex.add_argument("--rnaseq-bam",
                   dest="rnaseq_bam",
                   type=str,
                   metavar='str',
                   default = False,
                   help = "RNA-Seq BAM file to extract additional intron-spanning reads from")
    p_ex.add_argument("--rnaseq-bam-rev",
                   dest="rnaseq_bam_rev",
                   default = False,
                   action = "store_true",
                   help = "Enable if --rnaseq-bam reads are reverse strand-specific (reads mapping to reverse strand of corresponding transcript feature) (default: False)")
    p_ex.add_argument("--keep-bam",
                   dest="keep_bam",
                   default = False,
                   action = "store_true",
                   help = "Keep filtered BAM files in --out folder (default: False)")
    p_ex.add_argument("--new-site-id",
                   dest="new_site_id",
                   type=str,
                   metavar='str',
                   default = False,
                   help = "Generate new IDs with stem ID --new-site-id to exchange --in BED column 4 site IDs. NOTE that site IDs have to be unique if --new-site-id is not provided. Defines first part of site ID for assigning new site IDs, E.g. --new-site-id RBP1 will result in new site IDs RBP1_1, RBP1_2, etc. (default: False)")
    p_ex.add_argument("--data-id",
                   dest="data_id",
                   type=str,
                   metavar='str',
                   default = False,
                   help = "Define dataset ID for the input dataset to be stored in --out folder. This will later be used as dataset ID in peakhood merge for assigning new site IDs. By default, the dataset ID is extracted from the --in file name")
    p_ex.add_argument("--report",
                   dest="report",
                   default = False,
                   action = "store_true",
                   help = "Generate an .html report containing various additional statistics and plots (default: False)")

    """
    Merge extracted datasets mode.
    """
    p_mrg = subparsers.add_parser('merge',
                                  help='Merge extracted transcript context sets')
    p_mrg.set_defaults(which='merge')
    # Add required arguments group.
    p_mrgm = p_mrg.add_argument_group("required arguments")
    # Required arguments for merge.
    p_mrgm.add_argument("--in",
                   dest="list_in_folders",
                   type=str,
                   metavar='str',
                   nargs='+',
                   required = True,
                   help = "List of folders generated by peakhood extract (results folder --out) for merging")
    p_mrgm.add_argument("--out",
                   dest="out_folder",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Results output folder")

    # Optional arguments for merge.
    p_mrg.add_argument("--gtf",
                   dest="in_gtf",
                   type=str,
                   metavar='str',
                   help = "Genomic annotations GTF file (.gtf or .gtf.gz) for additional gene region annotations")
    p_mrg.add_argument("--report",
                   dest="report",
                   default = False,
                   action = "store_true",
                   help = "Generate an .html report containing additional statistics and plots (default: False)")

    """
    Batch process datasets (extract + merge) mode.
    """
    p_batch = subparsers.add_parser('batch',
                                  help='Batch processing (extract + merge)')
    p_batch.set_defaults(which='batch')
    # Add required arguments group.
    p_batchm = p_batch.add_argument_group("required arguments")
    # Required arguments for batch.
    p_batchm.add_argument("--in",
                   dest="in_folder",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Input folder containing BAM and BED files for batch processing. Naming convention: datasetid_rep1.bam, datasetid_rep2.bam, ... and datasetid.bed")
    p_batchm.add_argument("--gtf",
                   dest="in_gtf",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Genomic annotations GTF file (.gtf or .gtf.gz)")
    p_batchm.add_argument("--gen",
                   dest="in_2bit",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Genomic sequences .2bit file")
    p_batchm.add_argument("--out",
                   dest="out_folder",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Results output folder")

    # Optional arguments for batch.
    p_batch.add_argument("--thr",
                   dest="sc_thr",
                   type = float,
                   metavar='float',
                   default = None,
                   help = "Minimum site score (--in BED files column 5) for filtering (assuming higher score == better site) (default: None)")
    p_batch.add_argument("--thr-rev-filter",
                   dest="rev_filter",
                   default = False,
                   action = "store_true",
                   help = "Reverse --thr filtering (i.e. the lower the better, e.g. for p-values) (default: False)")
    p_batch.add_argument("--max-len",
                   dest = "max_len",
                   type = int,
                   metavar='int',
                   default = 250,
                   help = "Maximum length of --in sites (default: 250)")
    p_batch.add_argument("--min-exon-overlap",
                   dest = "min_eol",
                   type = float,
                   metavar='float',
                   default = 0.9,
                   help = "Minimum exon overlap of a site to be considered for transcript context extraction (intersectBed -f parameter) (default: 0.9)")
    p_batch.add_argument("--min-ei-ratio",
                   dest = "min_ei_ratio",
                   type = float,
                   metavar='float',
                   default = 4,
                   help = "Minimum exon to neighboring intron coverage for exonic site to be reported as exonic site with transcript context (default: 4)")
    p_batch.add_argument("--min-eib-ratio",
                   dest = "min_eib_ratio",
                   type = float,
                   metavar='float',
                   default = 4,
                   help = "Minimum exon border to neighboring intron border region coverage for an exon to be considered for transcript context selection (default: 4)")
    p_batch.add_argument("--eib-width",
                   dest = "eib_width",
                   type = int,
                   metavar='int',
                   default = 20,
                   help = "Width of exon-intron border regions (EIB) to calculate coverage drops from exon to intron region (default: 20)")
    p_batch.add_argument("--eibr-mode",
                   dest="eib_ratio_mode",
                   type = int,
                   default = 1,
                   choices = [1,2],
                   help = "How to extract the exon-intron border ratio of an exon. 1: return the exon-intro border ratio with the higher coverage. 2: average the two exon-intron border ratios of the exon (default: 1)")
    p_batch.add_argument("--no-eibr-filter",
                   dest="no_eibr_filter",
                   default = False,
                   action = "store_true",
                   help = "Disable exon-intron border ratio (EIBR) filtering of exons. By default, exons with low EIBR are not considered for transcript context selection")
    p_batch.add_argument("--no-eir-wt-filter",
                   dest="no_eir_wt_filter",
                   default = False,
                   action = "store_true",
                   help = "Disable exon-intron ratio filtering by checking the ratios of whole transcripts (all transcript exons)")
    p_batch.add_argument("--no-eibr-wt-filter",
                   dest="no_eibr_wt_filter",
                   default = False,
                   action = "store_true",
                   help = "Disable exon-intron border ratio filtering by checking the ratios of whole transcripts (all transcript exons)")
    p_batch.add_argument("--bam-pp-mode",
                   dest="bam_pp_mode",
                   type = int,
                   default = 1,
                   choices = [1,2,3],
                   help = "Define type of preprocessing for read-in --bam files. 1: no preprocessing (just merge if several given). 2: use only R2 reads for site context extraction (for eCLIP data) 3: use only R1 reads for site context extraction (e.g. for iCLIP data) (default: 1)")
    p_batch.add_argument("--read-pos-mode",
                   dest="read_pos_mode",
                   type = int,
                   default = 1,
                   choices = [1,2,3],
                   help = "Define which BAM read part to take for overlap and coverage calculations. 1: full-length read. 2: 5' end of the read. 2: center position of the read (default: 1)")
    p_batch.add_argument("--tbt-filter-ids",
                   dest="list_tbt_filter_ids",
                   type=str,
                   metavar='str',
                   nargs='+',
                   default=False,
                   help = "Manually provide transcript biotype ID(s) to filter out transcripts with these biotypes (e.g. --tbt-filter-ids nonsense_mediated_decay retained_intron non_stop_decay). By default, \"nonsense_mediated_decay\", \"retained_intron\", \"non_stop_decay\", and \"processed_transcript\" are used for filtering")
    p_batch.add_argument("--no-biotype-filter",
                   dest="no_tbt_filter",
                   default = False,
                   action = "store_true",
                   help = "Disable transcript biotype filter. By default, if biotype information is given inside --gtf, transcripts with biotypes \"nonsense_mediated_decay\", \"retained_intron\", \"non_stop_decay\", and \"processed_transcript\" are not considered for transcript context selection")
    p_batch.add_argument("--min-exbs-isr-c",
                   dest="min_exbs_isr_c",
                   type = int,
                   metavar='int',
                   default = 2,
                   help = "Minimum intron-spanning read count to connect two sites at adjacent exon borders. Exon border sites featuring >= --min-exbs-isr-c will be merged into one site (default: 2)")
    p_batch.add_argument("--no-tis-filter",
                   dest="no_tis_filter",
                   default = False,
                   action = "store_true",
                   help = "Do not discard transcripts containing intronic sites from transcript context selection")
    p_batch.add_argument("--min-tis-sites",
                   dest = "min_n_tis_sites",
                   type = int,
                   metavar='int',
                   default = 3,
                   help = "Minimum number of intronic sites needed per transcript to assign all sites on the transcript to genomic context (default: 2)")
    p_batch.add_argument("--f1-filter",
                   dest="list_f1_filter",
                   type=str,
                   metavar='str',
                   nargs='+',
                   default=False,
                   help="Define F1 filters to be applied for F1 transcript selection filtering (F1: sequential filtering). e.g. --f1-filter TSC ISRN (order matters!) (default: TSC)")
    p_batch.add_argument("--no-f1-filter",
                   dest="no_f1_filter",
                   default = False,
                   action = "store_true",
                   help = "Disable F1 sequential filtering step")
    p_batch.add_argument("--f2-filter",
                   dest="list_f2_filter",
                   type=str,
                   metavar='str',
                   nargs='+',
                   default=False,
                   help="Define F2 filters to be applied for F2 transcript selection filtering (F2: sequential or majority vote filtering, set with --f2-mode). Set order matters only if --f2-mode 2 (default: EIR ISRN ISR ISRFC SEO FUCO TCOV)")
    p_batch.add_argument("--f2-mode",
                   dest="f2_mode",
                   type = int,
                   default = 1,
                   choices = [1,2],
                   help = "Define transcript selection strategy for a given exonic site during F2 filtering. (1) majority vote filtering, (2) sequential filtering. (default: 1)")
    p_batch.add_argument("--isrn-prefilter",
                   dest="isrn_prefilter",
                   type = int,
                   metavar='int',
                   default = False,
                   help = "Enable prefilerting of exons (before F1, F2) by exon neigbhorhood intron-spanning read count. A minimum number of intron-spanning reads to neighboring exons has to be provided, e.g. --isr-prefilter 5 (default: False)")
    p_batch.add_argument("--isr-ext-mode",
                   dest = "isr_ext_mode",
                   type = int,
                   default = 1,
                   choices = [1,2],
                   help = "Define which portions of intron-spanning reads to use for overlap calculations. 1: use whole matching region. 2: use end positions only (at exon ends). If 1 is set, maximum region length is further controlled by --isr-max-reg-len (default: 1)")
    p_batch.add_argument("--isr-max-reg-len",
                   dest = "isr_max_reg_len",
                   type = int,
                   metavar='int',
                   default = 10,
                   help = "Set maximum region length for intron-spanning read matches. This means that if intron-spanning read match on exon is 15, and --isr-max-reg-len 10, shorten the match region to 10. Set to 0 to deactivate, i.e., always use full match lengths for coverage calculations (default: 10)")
    p_batch.add_argument("--merge-mode",
                   dest="merge_mode",
                   type = int,
                   default = 1,
                   choices = [1,2],
                   help = "Defines whether or how to merge nearby sites before applying --seq-ext. The merge operation is done separately for genomic and transcript context sites, AFTER extracting transcript context extraction. For pre-merging check out --pre-merge option. (1) Do NOT merge sites, (2) merge overlapping and adjacent sites (merge distance controlled by --merge-ext). For an overlapping set of sites, the site with highest column 5 BED score is chosen, and the others discarded. NOTE that if no BED scores are given, merge is done by alphabetical ordering of site IDs (default: 1)")
    p_batch.add_argument("--merge-ext",
                   dest="merge_ext",
                   type = int,
                   metavar='int',
                   default = 0,
                   help = "Extend regions by --merge-ext before merging overlapping regions (if --merge-mode 2) (default: 0)")
    p_batch.add_argument("--pre-merge",
                   dest="pre_merge",
                   default = False,
                   action = "store_true",
                   help = "Merge book-ended and overlapping --in sites BEFORE transcript context extraction. In contrast to --merge-mode 2, do not choose the best site from a set of overlapping sites, but keep the entire region for each overlapping set")
    p_batch.add_argument("--seq-ext-mode",
                   dest="seq_ext_mode",
                   type = int,
                   default = 1,
                   choices = [1,2,3],
                   help = "Define mode for site context sequence extraction after determining context. (1) Take the complete site, (2) Take the center of each site, (3) Take the upstream end for each site (default: 1)")
    p_batch.add_argument("--seq-ext",
                   dest = "seq_ext",
                   type = int,
                   metavar='int',
                   default = 0,
                   help = "Up- and downstream sequence extension length of sites (site definition by --seq-ext-mode) (default: 0)")
    p_batch.add_argument("--rnaseq-bam",
                   dest="rnaseq_bam",
                   type=str,
                   metavar='str',
                   default = False,
                   help = "RNA-Seq BAM file to extract additional intron-spanning reads from")
    p_batch.add_argument("--rnaseq-bam-rev",
                   dest="rnaseq_bam_rev",
                   default = False,
                   action = "store_true",
                   help = "Enable if --rnaseq-bam reads are reverse strand-specific (reads mapping to reverse strand of corresponding transcript feature) (default: False)")
    p_batch.add_argument("--new-ids",
                   dest="new_ids",
                   default = False,
                   action = "store_true",
                   help = "Generate new IDs to exchange --in BED column 4 site IDs. Use dataset ID from --in file names as stem (see --in option). NOTE that site IDs have to be unique if --new-site-id is not set (default: False)")
    p_batch.add_argument("--add-gtf",
                   dest="merge_gtf",
                   type=str,
                   metavar='str',
                   default=False,
                   help = "Additional genomic annotations GTF file (.gtf or .gtf.gz) for transcript to gene region annotation (corresponding to peakhood merge --gtf)")
    p_batch.add_argument("--report",
                   dest="report",
                   default = False,
                   action = "store_true",
                   help = "Generate .html reports for extract and merge, containing dataset statistics and plots (default: False)")

    """
    Motif search mode.
    """
    p_mtf = subparsers.add_parser('motif',
                                  help='Search for motif in context sets')
    p_mtf.set_defaults(which='motif')
    # Add required arguments group.
    p_mtfm = p_mtf.add_argument_group("required arguments")
    # Required arguments for eir.
    p_mtfm.add_argument("--in",
                   dest="in_data",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Three different inputs possible: (1) output folder of peakhood extract with genomic and transcript context sequence sets in which to look for given --motif. (2) BED file (genomic or transcript regions) in which to look for given --motif. (3) Transcript list file, to search for --motif in the respective transcript sequences. Note that (2)+(3) need --gtf and --gen.")
    p_mtfm.add_argument("--motif",
                   dest="in_regex",
                   type=str,
                   metavar='str',
                   required = True,
                   help = "Motif or regular expression (RNA letters!) to search for in --in folder context sequences (e.g. --motif '[AC]UGCUAA')")
    # Optional arguments.
    p_mtf.add_argument("--gtf",
                   dest="in_gtf",
                   type=str,
                   metavar='str',
                   help = "Genomic annotations GTF file (.gtf or .gtf.gz). Required for --in type (2) or (3)")
    p_mtf.add_argument("--gen",
                   dest="in_2bit",
                   type=str,
                   metavar='str',
                   help = "Genomic sequences .2bit file. Required for --in type (2) or (3)")
    p_mtf.add_argument("--out",
                   dest="out_folder",
                   type=str,
                   metavar='str',
                   default=False,
                   help = "Output results folder, to store motif hit regions in BED files")
    p_mtf.add_argument("--stats-out",
                   dest="stats_out",
                   type=str,
                   metavar='str',
                   help = "Output table to store motif search results in (for --in type (1) (requires --data-id to be set). If table exists, append results row to table")
    p_mtf.add_argument("--data-id",
                   dest="data_id",
                   type=str,
                   metavar='str',
                   help = "Data ID (column 1) for --stats-out output table to store motif search results (requires --stats-out to be set)")
    return p


################################################################################

def main_extract(args):
    """
    Extract authentic site context.

    Output different context sites to BED
    Merge entries (optionally)

    Remove intron spanning sites, i.e. mapping to two exons (?)
    These will be removed since not -f 0.9 overlapping



    Useful output:
    unique_exon_regions.bed all unique exon regions
    sel_tr_exon_regions.bed selected transcript / exon regions


    """

    print("Running for you in EXTRACT mode ... ")


    """
    Output files.

    """

    tr_sol_bed = args.out_folder + "/" + "tr_regions_with_sites.bed"
    exons_tr_sol_bed = args.out_folder + "/" + "unique_exon_regions.bed"
    sites_no_tol_bed = args.out_folder + "/" + "intergenic_sites.bed"
    sites_no_tol_fa = args.out_folder + "/" + "intergenic_sites.fa"
    sites_tol_intron_bed = args.out_folder + "/" + "intronic_sites.bed"
    sites_tol_intron_fa = args.out_folder + "/" + "intronic_sites.fa"
    next_ol_tr_se_pos_bed = args.out_folder + "/" + "next_ol_tr_se_pos.bed"
    tr_ex_sol_bed = args.out_folder + "/" + "transcript_regions_with_exon_sites.bed"
    tr_ex_sol_merged_bed = args.out_folder + "/" + "transcript_regions_with_exon_sites.merged.bed"
    # BAM reads overlapping with transcript regions.
    tr_regions_bam = args.out_folder + "/" + "transcript_regions.bam"
    # RNA-seq BAM reads overlapping with transcript regions.
    tr_regions_rnaseq_bam = args.out_folder + "/" + "transcript_regions.rnaseq.bam"
    # Exon regions of transcripts containing transcript context exonic sites.
    exon_regions_all_tr_bed = args.out_folder + "/" + "exon_regions.all_tr.bed"
    exon_regions_all_tr_igv_bed = args.out_folder + "/" + "exon_regions.all_tr.igv.bed"
    # Exon regions of selected transcripts containing transcript context exonic sites.
    exon_regions_sel_tr_bed = args.out_folder + "/" + "exon_regions.sel_tr.bed"
    exon_regions_sel_tr_igv_bed = args.out_folder + "/" + "exon_regions.sel_tr.igv.bed"
    exonic_site_stats_out = args.out_folder + "/" + "transcript_context_site_stats.tsv"
    chr_lengths_file = args.out_folder + "/" + "reference_lengths.out"
    # Transcript sequence files with exonic sites.
    exonic_sites_tr_con_all_tr_bed = args.out_folder + "/" + "exonic_sites.tr_con.all_tr.bed"
    exonic_sites_tr_con_all_tr_fa = args.out_folder + "/" + "exonic_sites.tr_con.all_tr.fa"
    exonic_sites_tr_con_sel_tr_bed = args.out_folder + "/" + "exonic_sites.tr_con.sel_tr.bed"
    exonic_sites_tr_con_sel_tr_fa = args.out_folder + "/" + "exonic_sites.tr_con.sel_tr.fa"
    # Genome sequence files with exonic sites.
    exonic_sites_tr_con_gen_bed = args.out_folder + "/" + "exonic_sites.tr_con.gen.bed"
    exonic_sites_tr_con_gen_fa = args.out_folder + "/" + "exonic_sites.tr_con.gen.fa"
    exonic_sites_gen_con_bed = args.out_folder + "/" + "exonic_sites.gen_con.bed"
    exonic_sites_gen_con_fa = args.out_folder + "/" + "exonic_sites.gen_con.fa"
    all_sites_igv_out = args.out_folder + "/" + "all_sites.tsv"
    # Reference lengths out.
    ref_len_out = args.out_folder + "/" + "ref_lengths.out"
    # Transcript gene annotations out.
    tr_gene_annot_out = args.out_folder + "/" + "tr_gene_annot.tsv"
    # Sites overlapping with transcripts infos out.
    sites_ol_gene_infos_out = args.out_folder + "/" + "sites_and_overlapping_genes.out"
    # Extract stats out.
    extract_stats_out = args.out_folder + "/" + "extract_stats.out"
    # All exon-intron ratios out.
    eir_all_out = args.out_folder + "/" + "eir_all.out"
    # All exon-intron border ratios (above threshold -1) out.
    eibr_all_out = args.out_folder + "/" + "eibr_all.out"
    # Exon border pair groups (> 2 connections) output files.
    exb_groups_bed_out = args.out_folder + "/" + "exon_border_pair_groups.bed"
    exb_groups_tsv_out = args.out_folder + "/" + "exon_border_pair_groups.igv.tsv"
    # Exon regions, intron regions, border regions BED.
    exon_intron_bed = args.out_folder + "/" + "exon_intron_regions.bed"
    # Transcript regions overlapping with sites in 12-column BED format.
    tr_sol_igv_bed = args.out_folder + "/" + "all_transcripts.igv.bed"
    # Transcript FASTA output.
    tr_seqs_fa = args.out_folder + "/" + "transcript_sequences.fa"
    # Input site lengths (after pre-merging and pre-filtering).
    input_site_len_out = args.out_folder + "/" + "input_site_lengths.out"


    """
    General checks.

    """
    assert os.path.exists(args.in_bed), "--in BED file \"%s\" not found" %(args.in_bed)
    assert os.path.exists(args.in_gtf), "--gtf GTF file \"%s\" not found" %(args.in_gtf)
    assert os.path.exists(args.in_2bit), "--gen .2bit file \"%s\" not found" %(args.in_2bit)
    assert args.min_eol <= 1 and args.min_eol >= 0.5, "set reasonable --min-exon-overlap (>= 0.5 and <= 1.0)"
    assert args.isr_max_reg_len >= 0 and args.isr_max_reg_len <= 50, "set reasonable --isr-max-reg-len (>= 0 and <= 50)"

    # assert args.min_iol <= 1 and args.min_iol >= 0.1, "set reasonable --min-intron-overlap (>= 0.1 and <= 1.0)"
    # one_min_eol = 1 - args.min_eol
    # assert args.min_iol > one_min_eol, "--min-intron-overlap needs to be > (1 - --min-exon-overlap). Increase --min-intron-overlap or increase --min-exon-overlap"
    assert args.min_ei_ratio > 1, "set reasonable --min-ei-ratio (> 1)"
    assert args.min_eib_ratio > 1, "set reasonable --min-eib-ratio (> 1)"

    for bam_file in args.list_bam:
        assert os.path.exists(bam_file), "--bam BAM file \"%s\" not found" %(bam_file)

    c_in_sites = hoodlib.count_file_rows(args.in_bed, nr_cols=6)
    assert c_in_sites, "--in BED file \"%s\" contains no 6-column BED regions. Make sure to provide --in BED file with genomic regions in 6-column format" %(args.in_bed)

    if args.isrn_prefilter:
        assert args.isrn_prefilter > 0, "given --isr-prefilter read number has to be > 0"

    if args.rnaseq_bam:
        assert os.path.exists(args.rnaseq_bam), "--rnaseq-bam BAM file \"%s\" not found" %(args.rnaseq_bam)

    # Results output folder.
    if not os.path.exists(args.out_folder):
        os.makedirs(args.out_folder)

    # Output mode settings.
    settings_file = args.out_folder + "/settings.peakhood_extract.out"
    SETOUT = open(settings_file, "w")
    for arg in vars(args):
        SETOUT.write("%s\t%s\n" %(arg, str(getattr(args, arg))))
    SETOUT.close()

    # FASTA sequence output.
    to_upper = True # Convert sequences to uppercase before output.

    # ISR double counting for intron-exon coverage calculations?
    count_isr_double = True
    if args.no_isr_double_count:
        count_isr_double = False
    # Substract ISR reads from intronic reads for coverage calculations?
    substr_isrc_from_int_c = True
    if args.no_isr_sub_count:
        substr_isrc_from_int_c = False

    """
    UNDER THE HOOD PARAMETERS.

    min_isolated_eib_ratio:
        For isolated single exon transcripts, use a different exon-intron
        border ratio to decide whether exon is transcript or genomic context.
        A ratio < min_eib_ratio results in single exon transcripts more likely
        to be assigned to transcript (spliced) context.
    min_eir_bonus_ratio:
        Decrease min_eib_ratio to min_isolated_eib_ratio, if ei_ratio of exon
        is >= min_eir_bonus_ratio. Set to False to deactivate.
    min_border_region_cov:
        Minimum border region read coverage for EIBR calculation. If neither
        the exon nor the intron border region has >= min_border_region_cov
        reads overlapping their regions, do not take into account this border.
    min_outer_last_exb_ratio:
        If the outer last exon-intron border coverage (sum of two coverages) is
        > the inner last exon-intron border coverage * min_outer_last_exb_ratio,
        prioritize the outer border again, i.e. select the outer ratio
        for EIB ratio calculation. This prioritization is due to the sometimes
        longer 3'UTRs compared to the GTF annotation, which distorts the outer
        border ratio, falsely leading to genomic context selection.
        Increase this ratio to further prioritize the inner border.
    min_intron_site_c_overlap:
        Minimum exon overlap of intronic sites to be included into TIS filtering.
    min_intron_reg_isrc:
        Minimum ISR count an intronic region needs to have, to be included
        in overlap calculations, to remove exons fully overlapping
        with such introns.
    min_ol_gene_isr_count:
        Minimum ISR count of a gene to be considered for removing overlapping
        genes. If gene A has IS reads, and gene B has not, and gene B fully
        overlaps gene A (remove_overlapping_genes () ), then remove gene B,
        if gene A ISR count >= min_ol_gene_isr_count.
    remove_single_ex_genes:
        If True, remove fully overlapping single exon genes in any case,
        even if gene A has < min_ol_gene_isr_count.
        to True, to remove
        fully overlapping single exon genes in any case.
    max_read2isr_ratio:
        Maximum ratio of # total reads / # ISR reads of an ISR intron,
        for filtering out fully overlapping exons. ISR introns with higher
        ratios are not used for filtering out fully overlapping exons.

    """

    min_isolated_eib_ratio = 2.5
    min_eir_bonus_ratio = 8
    min_border_region_cov = 8
    min_outer_last_exb_ratio = 2.5
    min_intron_site_c_overlap = 0.5
    min_intron_reg_isrc = 4
    min_ol_gene_isr_count = 4
    remove_single_ex_genes = True
    max_read2isr_ratio = 8


    """
    Transcript biotype filter settings.

    """

    reject_tr_bt_dic = {}
    if args.list_tbt_filter_ids:
        for tr_bt in args.list_tbt_filter_ids:
            reject_tr_bt_dic[tr_bt] = 1

    """
    Filter setting checks.

    """
    list_f1_filter, list_f2_filter = hoodlib.get_filter_lists(args.list_f1_filter,
                                                              args.list_f2_filter)

    """
    Process --in sites, get --gtf gene regions, overlap and report
    overlaps.

    """

    print("Get chromosome IDs from --gen ... ")
    chr_len_dic = hoodlib.get_chromosome_lengths_from_2bit(args.in_2bit, chr_lengths_file)

    # This also checks for unique IDs, or optionally converts to new IDs.
    id2sc_dic = {} # site ID to col5 score.
    id2len_dic = {} # site ID to length.
    filt_stats_dic = {}
    id2gen_se_dic = {}  # site ID to [gen_start, gen_end]

    new_ids = False
    if args.new_site_id:
        new_ids = True

    id2row_dic = hoodlib.bed_read_rows_into_dic(args.in_bed,
                                       new_stem_id=args.new_site_id,
                                       id2sc_dic=id2sc_dic,
                                       id2len_dic=id2len_dic,
                                       filt_stats_dic=filt_stats_dic,
                                       max_len=args.max_len,
                                       sc_thr=args.sc_thr,
                                       id2gen_se_dic=id2gen_se_dic,
                                       rev_filter=args.rev_filter,
                                       new_ids=new_ids)
    # Filter results.
    print("# --in sites pre-filtering:      %i" %(filt_stats_dic['c_in']))
    if filt_stats_dic["max_len"]:
        print("# --in sites > --max-len:        %i" %(filt_stats_dic["max_len"]))
    if filt_stats_dic["sc_thr"]:
        print("# --in sites not meeting --thr:  %i" %(filt_stats_dic["sc_thr"]))
    if filt_stats_dic["chr_filt"]:
        print("# --in sites non-std chrom IDs:  %i" %(filt_stats_dic["chr_filt"]))
    print("# --in sites post-filtering:     %i" %(filt_stats_dic['c_out']))


    """
    Pre-merge --in sites.

    Pre-merge --in sites that are book-ended or overlapping,
    keep entire regions for each overlapping set of sites, and
    use average score as new BED score.

    """
    if args.pre_merge:

        id2sc_dic = {}
        id2len_dic = {}
        id2gen_se_dic = {}

        print("--pre-merge set. Merge --in sites ... ")
        pm_id2row_dic = hoodlib.pm_ext_merge_bed_regions(
                                            id2row_dic,
                                            chr_len_dic,
                                            merge_ext=0,
                                            id2sc_dic=id2sc_dic,
                                            id2len_dic=id2len_dic,
                                            id2gen_se_dic=id2gen_se_dic,
                                            new_stem_id=args.new_site_id)
        c_sites_after_pm = len(pm_id2row_dic)
        print("# --in sites after pre-merging:  %i" %(c_sites_after_pm))
        assert c_sites_after_pm, "no sites left after pre-merging book-ended and overlapping --in sites"
        id2row_dic = pm_id2row_dic
        filt_stats_dic['c_out'] = c_sites_after_pm

    # Input site lengths list.
    site_lengths_list = []
    SLENOUT = open(input_site_len_out,"w")
    for site_id in id2len_dic:
        site_lengths_list.append(id2len_dic[site_id])
        SLENOUT.write("%i\n" %(id2len_dic[site_id]))
    SLENOUT.close()

    # Site ID to site center position on chromosome.
    id2gen_cp_dic = {}
    for site_id in id2gen_se_dic:
        gen_cp = hoodlib.get_center_position(id2gen_se_dic[site_id][0], id2gen_se_dic[site_id][1])
        id2gen_cp_dic[site_id] = gen_cp

    # Filtered --in sites.
    in_sites_tmp_bed = args.out_folder + "/" + "in_sites.tmp.bed"

    if args.list_site_ids:
        print("--site-id set, process only these sites ... ")
        wanted_site_ids_dic = {}
        for site_id in args.list_site_ids:
            assert site_id in id2row_dic, "given --site-id %s not part of --in set. Try to relax filter settings or disable --new-site-id if set (be sure to provide unique --in IDs)" %(site_id)
            wanted_site_ids_dic[site_id] = 1
        hoodlib.bed_write_row_dic_into_file(id2row_dic, in_sites_tmp_bed,
                                            id2out_dic=wanted_site_ids_dic)
        id2newrow_dic = {}
        for wanted_id in wanted_site_ids_dic:
            id2newrow_dic[wanted_id] = id2row_dic[wanted_id]
        id2row_dic = id2newrow_dic
    else:
        hoodlib.bed_write_row_dic_into_file(id2row_dic, in_sites_tmp_bed)

    # Check if --gtf has gene feature.
    gene_feat_check = hoodlib.gtf_check_gene_feat(args.in_gtf,
                                                  n_rows_check=10000)
    if not gene_feat_check:
        print("\"gene\" feature not found in --gtf ... ")

    # Transcript regions BED from --gtf.
    tr_regions_gtf_tmp_bed = args.out_folder + "/" + "tr_regions.gtf.tmp.bed"

    print("Check minus-strand exon order in --gtf ... ")

    min_ex_rev_order = hoodlib.gtf_check_exon_order(args.in_gtf)
    correct_min_ex_order = False
    tr2exc_dic = {}
    if not min_ex_rev_order:
        correct_min_ex_order = True
        print("Need to correct exon number order for minus-strand exons ... ")
        print("Get exon numbers from --gtf ... ")
        tr2exc_dic = hoodlib.gtf_extract_exon_numbers(args.in_gtf)

    keep_tr_ids_dic = {}
    if not tr2exc_dic and args.discard_single_ex_tr:
        print("--discard-single-ex-tr enabled ... ")
        print("Get exon numbers from --gtf ... ")
        tr2exc_dic = hoodlib.gtf_extract_exon_numbers(args.in_gtf)
        for tr_id in tr2exc_dic:
            tr_exc = tr2exc_dic[tr_id]
            if tr_exc != 1:
                keep_tr_ids_dic[tr_id] = 1

    # Extract transcript regions from --gtf.
    print("Extract transcript regions from --gtf ... ")
    # Store genomic regions of transcripts.
    trid2reg_dic = {}  # tr_id -> [chr_id, feat_s, feat_e, feat_pol] # o-based start.
    hoodlib.gtf_extract_transcript_bed(args.in_gtf, tr_regions_gtf_tmp_bed,
                                       trid2reg_dic=trid2reg_dic,
                                       tr_ids_dic=keep_tr_ids_dic)

    # Transcript regions overlap with --in sites.
    tr_sites_intersect_tmp_bed = args.out_folder + "/" + "tr_sites_intersect.tmp.bed"

    print("Get transcript regions overlapping with --in sites ... ")
    id2tr_list_dic, tr2reg_dic = hoodlib.intersect_genes_with_sites(
                                                    tr_regions_gtf_tmp_bed,
                                                    in_sites_tmp_bed,
                                                    tr_sites_intersect_tmp_bed)
    assert id2tr_list_dic, "no overlap between --gtf transcript regions and --in sites"
    c_tr_sol = len(tr2reg_dic)
    print("Transcript regions overlapping with --in sites:  %i" %(c_tr_sol))
    assert c_tr_sol, "no overlap between --gtf transcript regions and --in sites"

    # Output transcript regions overlapping with --in sites to BED.
    hoodlib.bed_write_reg_list_to_file(tr2reg_dic, tr_sol_bed)

    # --in sites overlapping with gene regions.
    c_sites_tol = len(id2tr_list_dic)
    print("--in sites overlapping with transcript regions:  %i" %(c_sites_tol))

    # Get sites not overlapping with genes.
    print("Get --in sites not overlapping with transcript regions ... ")
    params = "-v -s"
    hoodlib.intersect_bed_files(in_sites_tmp_bed, tr_sol_bed, params, sites_no_tol_bed)
    site_no_tol_dic =  hoodlib.bed_get_region_ids(sites_no_tol_bed, check=False)
    c_sites_no_tol = len(site_no_tol_dic)
    print("--in sites not overlapping with transcript regions:  %i" %(c_sites_no_tol))


    """
    Get unique exon regions + transcript and exon infos.

    """

    exid2trid_dic = {}  # exon ID to transcript ID.
    next2exids_dic = {} # NEXT to exon IDs.
    trid2exc_dic = {} # transcript ID to exon count.
    trid2gid_dic = {} # transcript ID to gene ID.
    trid2tsl_dic = {} # transcript ID to TSL info (TSL level, basic_set)
    trid2tbt_dic = {} # transcript ID to transcript biotype.
    trid2gna_dic = {} # transcript ID to gene name.
    trid2gbt_dic = {} # transcript ID to gene biotype.
    trid2len_dic = {} # Transcript ID to transcript length (sum of exon lengths).
    next2reg_dic = {} # NEXT to genomic region.

    print("Extract unique exon regions from transcript regions ... ")
    hoodlib.gtf_extract_unique_exon_bed(args.in_gtf, exons_tr_sol_bed,
                                        no_tbt_filter=args.no_tbt_filter,
                                        correct_min_ex_order=correct_min_ex_order,
                                        tr2exc_dic=tr2exc_dic,
                                        gene_feat_check=False,
                                        reject_tr_bt_dic=reject_tr_bt_dic,
                                        exid2trid_dic=exid2trid_dic,
                                        next2exids_dic=next2exids_dic,
                                        next2reg_dic=next2reg_dic,
                                        trid2exc_dic=trid2exc_dic,
                                        trid2tsl_dic=trid2tsl_dic,
                                        trid2tbt_dic=trid2tbt_dic,
                                        trid2gid_dic=trid2gid_dic,
                                        trid2gna_dic=trid2gna_dic,
                                        trid2gbt_dic=trid2gbt_dic,
                                        trid2len_dic=trid2len_dic,
                                        tr_ids_dic=tr2reg_dic)


    """
    Overlap unique exon regions (NEXTs) with --in sites.

    """

    id2next_list_dic = {} # site ID to overlapping NEXTs list.
    idnext2ol_se_dic = {} # site_next_ID to overlapping region.
    intersect_params = "-s -wb -f %f" %(args.min_eol)

    # NEXT regions overlap with --in sites.
    next_ol_in_sites_tmp_bed = args.out_folder + "/" + "next_ol_in_sites.tmp.bed"

    print("Get --in regions overlapping with exon regions ... ")
    hoodlib.intersect_bed_files(in_sites_tmp_bed, exons_tr_sol_bed,
                                intersect_params, next_ol_in_sites_tmp_bed,
                                ab2ol_se_dic=idnext2ol_se_dic,
                                a2b_list_dic=id2next_list_dic)

    """
    Check merge settings.

    """

    alpha_merge = False
    do_merge = False

    if args.merge_mode == 2:
        print("Merging --in sites activated. Check BED column 5 scores ... ")
        sc2c_dic = hoodlib.bed_get_score_to_count_dic(args.in_bed)
        # Warning in case no col5 scores are present (e.g. each row with score 0).
        if len(sc2c_dic) == 1:
            print("WARNING: --in BED regions all contain the same column 5 score!")
            print("     Selecting best site from a set of overlapping sites")
            print("           based on site scores is not possible!")
            print("             Enabling selection of best sites")
            print("              based on alphabetical order")
            print("                      of site IDs ...")
            alpha_merge = True
        do_merge = True

    # Merge all genomic sites.
    gen_sites_merged_dic = {}
    if do_merge:
        print("Extend and merge genomic sites ... ")
        gen_sites_merged_dic = hoodlib.ext_merge_bed_regions(id2row_dic, chr_len_dic,
                                                alpha_merge=alpha_merge,
                                                merge_ext=args.merge_ext,
                                                rev_filter=args.rev_filter)
        assert gen_sites_merged_dic, "no genomic sites left after merging"
    else:
        for site_id in id2row_dic:
            gen_sites_merged_dic[site_id] = 1

    # Get extended genomic sequences.
    print("Get genomic site sequences ... ")
    gen_rr_ratios_dic = {}
    site_seqs_dic = hoodlib.get_extended_gen_seqs(args, id2row_dic,
                                        ref_len_dic=chr_len_dic,
                                        id2out_dic=gen_sites_merged_dic,
                                        rr_ratios_dic=gen_rr_ratios_dic)


    """
    CASE: no exonic regions found in --in sites.

    """

    if not id2next_list_dic:

        print("WARNING: no >= --min-exon-overlap between unique exon regions and --in sites!")

        # Get intronic and intergenic sites.
        intron_site_ids_dic = {}
        intergen_site_ids_dic = {}
        for site_id in gen_sites_merged_dic:
            if site_id in id2tr_list_dic:
                intron_site_ids_dic[site_id] = site_seqs_dic[site_id]
            else:
                intergen_site_ids_dic[site_id] = site_seqs_dic[site_id]

        # Output intronic sequences and regions.
        if intron_site_ids_dic:
            print("Output intronic sites ... ")
            hoodlib.fasta_output_dic(site_seqs_dic, sites_tol_intron_fa,
                                     out_ids_dic=intron_site_ids_dic,
                                     to_upper=to_upper,
                                     split_size=60,
                                     split=True)
            hoodlib.bed_write_row_dic_into_file(id2row_dic, sites_tol_intron_bed,
                                        ext_mode=args.seq_ext_mode,
                                        ext_lr=args.seq_ext,
                                        zero_scores=False,
                                        chr_len_dic=chr_len_dic,
                                        id2out_dic=intron_site_ids_dic)

        # Output intergenic sequences and regions.
        if intergen_site_ids_dic:
            print("Output intergenic sites ... ")
            hoodlib.fasta_output_dic(site_seqs_dic, sites_no_tol_fa,
                                     out_ids_dic=intergen_site_ids_dic,
                                     to_upper=to_upper,
                                     split_size=60,
                                     split=True)
            hoodlib.bed_write_row_dic_into_file(id2row_dic, sites_no_tol_bed,
                                        ext_mode=args.seq_ext_mode,
                                        ext_lr=args.seq_ext,
                                        zero_scores=False,
                                        chr_len_dic=chr_len_dic,
                                        id2out_dic=intergen_site_ids_dic)

        c_intron_sites = len(intron_site_ids_dic)
        c_intergen_sites = len(intergen_site_ids_dic)

        print("# of intronic sites:                %i" %(len(intron_site_ids_dic)))
        print("# of intergenic sites:              %i" %(len(intergen_site_ids_dic)))

        print("")
        print("OUTPUT FILES")
        print("============")
        if c_intron_sites:
            print("Intronic sites BED:\n%s" %(sites_tol_intron_bed))
            print("Intronic sites FASTA:\n%s" %(sites_tol_intron_fa))
        if c_intergen_sites:
            print("Intergenic sites BED:\n%s" %(sites_no_tol_bed))
            print("Intergenic sites FASTA:\n%s" %(sites_no_tol_fa))
        print("")
        sys.exit()


    """
    CASE: exonic regions found in --in sites.

    Go on with BAM processing, context selection, etc.

    """

    # All NEXT overlapping with --in sites.
    ol_nexts_list = []
    for site_id in id2next_list_dic:
        for next in id2next_list_dic[site_id]:
            ol_nexts_list.append(next)


    """
    Process --bam files.

    """
    # Filtered or merged input BAM.
    in_bam = args.out_folder + "/" + "merged_filtered_in.tmp.bam"

    print("Processing --bam files ... ")

    if len(args.list_bam) > 1:
        if args.bam_pp_mode == 1:
            print("Merging --bam files ... ")
        elif args.bam_pp_mode == 2:
            print("Merging --bam files and filter by R2 reads ... ")
        elif args.bam_pp_mode == 3:
            print("Merging --bam files and filter by R1 reads ... ")
        else:
            assert False, "invalid bam_pp_mode set"
        hoodlib.merge_filter_bam_files(args.list_bam, in_bam,
                                       out_folder=args.out_folder,
                                       pp_mode=args.bam_pp_mode)
    else:
        if args.bam_pp_mode == 1:
            in_bam = args.list_bam[0]
        else:
            if args.bam_pp_mode == 2:
                print("Filter --bam file to keep only R2 reads ... ")
            elif args.bam_pp_mode == 3:
                print("Filter --bam file to keep only R1 reads ... ")
            else:
                assert False, "invalid bam_pp_mode set"
            hoodlib.filter_bam_file(args.list_bam[0], in_bam,
                                    pp_mode=args.bam_pp_mode)


    """
    Get and count intronic sites on transcripts for TIS filtering.
    The idea is to not use all sites < --min-exon-overlap, but rather sites
    with a certain amount of intronic overlap (min_intron_site_c_overlap).

    Since we use -v -f, we need to convert the set min_intron_site_c_overlap,
    e.g. min_intron_site_c_overlap = 0.6 -> 0.4
    This way we can use the exon regions for overlap calculation; no need
    to extract intronic regions at this point.
    Note that -v -f 0.5 does not include "overlapping equal 0.5", so we
    add a small 0.00001, to also get 50% intron overlaps.

    id2tr_list_dic:
        site ID -> overlapping transcripts list

    """

    intron_tis_ids_dic = {}  # Intronic site IDs for TIS filtering.
    trid2intron_site_c_dic = {}  # transcript ID -> intronic site count.

    if not args.no_tis_filter:
        print("Get intronic sites for TIS filtering ... ")

        # Intronic regions overlap with --in sites.
        intronic_sites_tmp_bed = args.out_folder + "/" + "intronic_sites.tmp.bed"

        min_iol_intersect = 1 - min_intron_site_c_overlap + 0.00001
        intersect_params = "-s -v -f %f " %(min_iol_intersect)

        print("Get --in regions overlapping with intron regions ... ")
        hoodlib.intersect_bed_files(in_sites_tmp_bed, exons_tr_sol_bed,
                                    intersect_params, intronic_sites_tmp_bed)

        intron_tis_ids_dic = hoodlib.bed_get_region_ids(intronic_sites_tmp_bed ,check=False)

        # Remove intergenic sites.
        for site_id in site_no_tol_dic:
            if site_id in intron_tis_ids_dic:
                del intron_tis_ids_dic[site_id]

        # Checks.
        for site_id in id2next_list_dic:
            assert site_id not in intron_tis_ids_dic, "site ID %s both in id2next_list_dic (exonic sites) and intron_tis_ids_dic (intronic sites)" %(site_id)
        for site_id in intron_tis_ids_dic:
            assert site_id in id2tr_list_dic, "intronic site ID %s in intron_tis_ids_dic but not in id2tr_list_dic" %(site_id)

        c_tis_intron_sites = len(intron_tis_ids_dic)
        print("# of intronic sites for TIS filtering:  %i" %(c_tis_intron_sites))

        # Count intronic sites on transcripts.
        for site_id in intron_tis_ids_dic:
            for tr_id in id2tr_list_dic[site_id]:
                if tr_id in trid2intron_site_c_dic:
                    trid2intron_site_c_dic[tr_id] += 1
                else:
                    trid2intron_site_c_dic[tr_id] = 1


    """
    Get mappings:
    NEXT -> transcript ID list
    transcript ID -> NEXT list
    Exon ID -> NEXT

    """

    next2trid_list_dic = {}
    for next in next2exids_dic:
        next2trid_list_dic[next] = []
        tr_ids_seen = {}
        for ex_id in next2exids_dic[next]:
            tr_id = exid2trid_dic[ex_id]
            #print(next, tr_id)
            tr_ids_seen[tr_id] = 1
        for tr_id in tr_ids_seen:
            next2trid_list_dic[next].append(tr_id)

    trid2next_list_dic = {}
    for next in next2trid_list_dic:
        for tr_id in next2trid_list_dic[next]:
            if tr_id in trid2next_list_dic:
                trid2next_list_dic[tr_id].append(next)
            else:
                trid2next_list_dic[tr_id] = [next]

    exid2next_dic = {}
    for next in next2exids_dic:
        for ex_id in next2exids_dic[next]:
            exid2next_dic[ex_id] = next


    """
    Exon ID to exon number and exon ID to genomic [start,end] mapping

    exid2exnr_dic:
        exon ID -> exon number
    exid2gen_se_dic:
        exon ID -> [gen_s, gen_e]

    """
    exid2exnr_dic = {}
    exid2gen_se_dic = {}

    for ex_id in exid2trid_dic:
        if re.search(".+_e\d+$", ex_id):
            m = re.search(".+_e(\d+)$", ex_id)
            ex_nr = int(m.group(1))
            exid2exnr_dic[ex_id] = ex_nr
        else:
            assert False, "invalid exon ID %s (format expected: trid_e1)" %(ex_id)
        next_id = exid2next_dic[ex_id]
        gen_s = next2reg_dic[next_id][1]
        gen_e = next2reg_dic[next_id][2]
        exid2gen_se_dic[ex_id] = [gen_s, gen_e]


    """
    Output transcript regions containing --in sites that overlap >= -f  with
    exons from these transcript regions.
    Only output transcripts with NEXT IDs overlapping with --in sites.
    ol_nexts_list: NEXT IDs containing --in sites.

    """

    OUTBED = open(tr_ex_sol_bed, "w")
    tr_ids_ex_ol_dic = {}
    for next in ol_nexts_list:
        for tr_id in next2trid_list_dic[next]:
            if tr_id not in tr_ids_ex_ol_dic:
                reg_list = tr2reg_dic[tr_id]
                OUTBED.write("%s\t%i\t%i\t%s\t0\t%s\n" %(reg_list[0], reg_list[1], reg_list[2], tr_id, reg_list[3]))
                tr_ids_ex_ol_dic[tr_id] = 1
    OUTBED.close()


    """
    Merge transcript regions BED.

    """

    tr2pol_dic = {}
    for tr_id in tr2reg_dic:
        tr2pol_dic[tr_id] = tr2reg_dic[tr_id][3]
    print("Merge transcript regions BED ... ")
    hoodlib.bed_merge_transcript_regions(tr_ex_sol_bed, tr_ex_sol_merged_bed,
                                         new_ids=True,
                                         id2pol_dic=tr2pol_dic)

    c_exonic_sites = len(id2next_list_dic)
    print("# of exonic sites:                %i" %(c_exonic_sites))
    print("# transcripts with exonic sites:  %i" %(len(tr_ids_ex_ol_dic)))

    # Get BAM reads overlapping with these transcript regions.
    print("Extract BAM reads from transcript regions containing exonic sites ... ")
    hoodlib.bam_extract_reads_from_bed_regions(tr_ex_sol_merged_bed, in_bam,
                                               tr_regions_bam,
                                               no_name_check=True)

    c_bam_reads = hoodlib.bam_count_reads(tr_regions_bam)
    print("# of overlapping BAM reads:  %i" %(c_bam_reads))
    assert c_bam_reads, "no --bam reads overlapping with transcripts containing exonic sites. Provide the correct --bam file(s) (--bam file(s) used to determine --in sites), or adjust --bam-pp-mode depending on the used CLIP-seq protocol (e.g. --bam-pp-mode 2 (reverse) for eCLIP, --bam-pp-mode 3 (forward) for iCLIP). Another possible error source is that the BAM file features chromosome names in a format other than chr1,chr2,chr3 (required for Peakhood) .. "


    """
    Output exons (i.e. their start + end positions) of transcripts containing NEXTs
    overlapping with --in sites to BED.

    """

    OUTBED = open(next_ol_tr_se_pos_bed, "w")
    next_seen_dic = {}
    # Transcript IDs with NEXT IDs covered by --in sites.
    ol_tr_ids_dic = {}
    for next in ol_nexts_list:
        for tr_id in next2trid_list_dic[next]:
            ol_tr_ids_dic[tr_id] = 1

    for tr_id in ol_tr_ids_dic:
        for next in trid2next_list_dic[tr_id]:
            if next not in next_seen_dic:
                next_s_s = next2reg_dic[next][1]
                next_s_e = next_s_s + 1
                next_e_s = next2reg_dic[next][2] - 1
                next_e_e = next_e_s + 1
                next_s_id = next #+ "_s"
                next_e_id = next #+ "_e"
                OUTBED.write("%s\t%i\t%i\t%s\t0\t%s\n" %(next2reg_dic[next][0], next_s_s, next_s_e, next_s_id, next2reg_dic[next][3]))
                OUTBED.write("%s\t%i\t%i\t%s\t0\t%s\n" %(next2reg_dic[next][0], next_e_s, next_e_e, next_e_id, next2reg_dic[next][3]))
                next_seen_dic[next] = 1

    OUTBED.close()


    """
    Get intron-spanning (IS) read stats.

    nexts_cisrc_dic:
        Connected NEXT IDs with format "NEXT1,NEXT2" and mapping:
        "NEXT1,NEXT2" -> connecting IS read count
        "NEXT2,NEXT1" -> connecting IS read count
        ...
    isr_intron_reg_dic:
        Intronic region string "chr,s,e,pol" -> ISR count mapping.

    """
    print("Get intron-spanning read stats ... ")

    isr_tmp_bed = args.out_folder + "/" + "is_reads.tmp.bed"

    nexts_cisrc_dic = {}
    isr_intron_reg_dic = {}
    nexts_cisrc_dic = hoodlib.bam_to_bed_get_isr_stats(
                                            tr_regions_bam,
                                            next_ol_tr_se_pos_bed,
                                            isr_ext_mode=args.isr_ext_mode,
                                            isr_max_reg_len=args.isr_max_reg_len,
                                            nexts_cisrc_dic=nexts_cisrc_dic,
                                            isr_intron_reg_dic=isr_intron_reg_dic,
                                            isr_bed=isr_tmp_bed)


    # Make a copy of nexts_cisrc_dic, only storing CLIP info.
    nexts_clip_cisrc_dic = {}
    if args.rnaseq_bam:
        for nexts in nexts_cisrc_dic:
            nexts_clip_cisrc_dic[nexts] = nexts_cisrc_dic[nexts]

    """
    If --rnaseq-bam is set, get RNA-seq reads overlapping with
    transcript regions.

    """

    isr_rnaseq_tmp_bed = args.out_folder + "/" + "is_reads.rnaseq.tmp.bed"

    if args.rnaseq_bam:

        # Get --rnaseq-bam reads overlapping with these transcript regions.
        print("Extract --rnaseq-bam reads from transcript regions containing exonic sites ... ")
        hoodlib.bam_extract_reads_from_bed_regions(tr_ex_sol_merged_bed, args.rnaseq_bam,
                                                   tr_regions_rnaseq_bam,
                                                   reverse_strand=args.rnaseq_bam_rev,
                                                   no_name_check=True)

        c_rnaseq_bam_reads = hoodlib.bam_count_reads(tr_regions_rnaseq_bam)
        print("# of overlapping --rnaseq-bam reads:  %i" %(c_rnaseq_bam_reads))

        if not c_rnaseq_bam_reads:
            print("WARNING: no --rnaseq-bam reads overlapping with transcripts containing exonic sites.")
            print("  Make sure --rnaseq-bam file features chromosome names with format chr1,chr2, ..")
        else:
            print("Get --rnaseq-bam intron-spanning read stats ... ")

            nexts_cisrc_dic = hoodlib.bam_to_bed_get_isr_stats(
                                                    tr_regions_rnaseq_bam,
                                                    next_ol_tr_se_pos_bed,
                                                    reverse_strand=args.rnaseq_bam_rev,
                                                    nexts_cisrc_dic=nexts_cisrc_dic,
                                                    isr_bed=isr_rnaseq_tmp_bed)


    """
    Count for each transcript # of IS reads that connect its exons.
    Also return full connection status (i.e. whether each exon is
    connected via intron-spanning reads).

    trid2isrc_dic:
        transcript ID to intron-spanning reads (ISR) count supporting
        the transcript. Also includes reads from --rnaseq-bam.
    trid2isrfc_dic:
        transcript ID to True or False; store 1 if all exons connected
        via intron-spanning reads, otherwise 0. If only one exon
        also store False.

    """

    # Transcripts with NEXTs overlapping with exonic sites.
    trid2isrc_dic = {}
    # Transcript exons fully conntected by intron-spanning reads?
    trid2isrfc_dic = {}

    for tr_id in ol_tr_ids_dic:
        tr_exc = trid2exc_dic[tr_id]
        tr_isrc, full_con = hoodlib.get_trid_isrc_full_con(tr_id, tr_exc,
                                            exid2next_dic, nexts_cisrc_dic)
        trid2isrc_dic[tr_id] = tr_isrc
        if full_con:
            trid2isrfc_dic[tr_id] = 1
        else:
            trid2isrfc_dic[tr_id] = 0

    """
    Get isolated single exon genes / transcripts.
    E.g.
    H2BC21 H2B clustered histone 21
    Protein coding
    ENST00000369155.3
    2194 nt

    Get longest transcript for each gene
    Get only genes that are isolated + have no introns.

    """

    gid2trids_dic = {} # gene ID -> [tr_id1, tr_id2, ... ]
    gid2isrc_dic = {}  # gene ID -> Intron-spanning read count
    gid2maxtrlen_dic = {} # gene ID -> maximum transcript length
    gid2maxlentr_dic = {} # gene ID -> maximum length transcript
    for tr_id in ol_tr_ids_dic:
        gene_id = trid2gid_dic[tr_id]
        tr_isrc = trid2isrc_dic[tr_id]
        tr_len = trid2len_dic[tr_id]
        if gene_id in gid2trids_dic:
            gid2trids_dic[gene_id].append(tr_id)
            gid2isrc_dic[gene_id] += tr_isrc
            if tr_len > gid2maxtrlen_dic[gene_id]:
                gid2maxtrlen_dic[gene_id] = tr_len
                gid2maxlentr_dic[gene_id] = tr_id
        else:
            gid2trids_dic[gene_id] = [tr_id]
            gid2isrc_dic[gene_id] = tr_isrc
            gid2maxtrlen_dic[gene_id] = tr_len
            gid2maxlentr_dic[gene_id] = tr_id

    # Get longest transcript for each single exon gene.
    single_ex_tr_dic = {}
    for gene_id in gid2trids_dic:
        has_introns = False
        for tr_id in gid2trids_dic[gene_id]:
            tr_exc = trid2exc_dic[tr_id]
            if tr_exc > 1:
                has_introns = True
                break
        if not has_introns:
            single_ex_tr_dic[gid2maxlentr_dic[gene_id]] = 1

    isolated_exon_dic = {} # Isolated single exon IDs.
    if single_ex_tr_dic:
        print("Get isolated single exon genes ... ")
        isolated_tr_ids_dic = hoodlib.get_isolated_transcripts(single_ex_tr_dic, tr2reg_dic)
        if isolated_tr_ids_dic:
            for tr_id in isolated_tr_ids_dic:
                ex_id = tr_id + "_e1"
                isolated_exon_dic[ex_id] = 1
        c_isolated_genes = len(isolated_tr_ids_dic)
        print("# of isolated single exon genes:  %i" %(c_isolated_genes))
        # for tr_id in isolated_tr_ids_dic:
        #     tr_reg = tr2reg_dic[tr_id]
        #     print(tr_id, tr_reg)

    """
    Remove overlapping genes / transcripts.

    Get longest transcript for each gene
    Get ISR count for gene /its transcripts

    trid2isrc_dic:
        these also include rna-seq read infos!

    """

    print("Remove low-evidence overlapping genes ... ")
    gid2remove_dic = hoodlib.remove_overlapping_genes(gid2maxlentr_dic,
                                     gid2isrc_dic, tr2reg_dic,
                                     remove_single_ex_genes=remove_single_ex_genes,
                                     trid2exc_dic=trid2exc_dic,
                                     min_isrc=min_ol_gene_isr_count)

    rem_tr_ids_dic = {}
    if gid2remove_dic:
        for gene_id in gid2remove_dic:
            for tr_id in gid2trids_dic[gene_id]:
                rem_tr_ids_dic[tr_id] = 1
        c_gen_rem = len(gid2remove_dic)
        c_tr_rem = len(rem_tr_ids_dic)
        print("# of overlapping genes to remove:  %i" %(c_gen_rem))
        print("# of associated transcripts:       %i" %(c_tr_rem))
    else:
        print("No overlapping genes removed ... ")


    """
    Remove single exon genes, if:
        Overlap with introns containing intron-spanning reads
        If they overlap other gene with at least > i ISRC
    Remove overlapping >1 exon genes, if:
        Overlapping other gene > i ISRC and this gene as 0 ISRC

        Single exons dont get ...


    Conditions:
        1) Full overlap
        2) Do not remove genes with

    Group of genes fully overlapping ? at least contained in another
    gene ...

    """

    # seen_nexts_dic = {}
    # for nexts in nexts_cisrc_dic:
    #     [next1, next2] = nexts.split(",")
    #     # Get transcripts they have in common.
    #     common_tr_list = hoodlib.two_lists_get_intersect(next2trid_list_dic[next1],
    #                                                      next2trid_list_dic[next2])
    #     if not common_tr_list:
    #         continue
    #     #print(nexts, common_tr_list)
    #     for tr_id in common_tr_list:
    #         if tr_id in trid2isrc_dic:
    #             #print("%s shared by %s and %s" %(tr_id, next1, next2))
    #             trid2isrc_dic[tr_id] += nexts_cisrc_dic[nexts]
    #

    """
    Get transcript support level (TSL) score for each transcript.
    If no transcript support level info in --gtf, assign same score to all
    transcripts.

    trid2tsl_dic[tr_id][0]:
        TSL score
    trid2tsl_dic[tr_id][1]:
        Transcript part of Gencode basic yes/no
    trid2tsl_dic[tr_id][2]:
        Transcript member of consensus CDS gene set (CCDS) yes/no

    """

    # Get TSL score for each transcript.
    trid2tslsc_dic = {}
    for tr_id in trid2tsl_dic:
        tsl = hoodlib.get_tsl_score(trid2tsl_dic[tr_id][0], trid2tsl_dic[tr_id][1], trid2tsl_dic[tr_id][2])
        trid2tslsc_dic[tr_id] = tsl
        if trid2tsl_dic[tr_id][1]:
            trid2tsl_dic[tr_id][1] = "yes"
        else:
            trid2tsl_dic[tr_id][1] = "no"
        if trid2tsl_dic[tr_id][2]:
            trid2tsl_dic[tr_id][2] = "yes"
        else:
            trid2tsl_dic[tr_id][2] = "no"


    """
    Last exon and polarity.

    last_exon_dic:
        Last exon ID -> polarity
    """

    last_exon_dic = {}
    for tr_id in trid2exc_dic:
        last_exon_nr = trid2exc_dic[tr_id]
        # Only for multi-exon transcripts.
        if last_exon_nr > 1:
            last_exon_id = tr_id + "_e%i" %(last_exon_nr)
            last_exon_dic[last_exon_id] = tr2pol_dic[tr_id]


    """
    Get exon + intron region coverage for extracted transcripts.
    Coverage = number of read starts overlapping region / length of region.

    regid2nc_dic = [norm_cov, coverage(# reads overlapping), region_len]
    NOTE that each region gets a pseudo count of +1. I.e. there will be
    no regions with 0 counts (coverage), or 0.0 normalized coverage.
    Does not include --rnaseq-bam read info / coverage.

    reg2cov_dic:
        ["chr,s,e,pol"] -> read overlap count / coverage.

    """
    reg2cov_dic = {}

    print("Get exon-intron coverage of exonic site transcripts ... ")
    regid2nc_dic = hoodlib.gtf_get_intron_exon_cov(
                                args.in_gtf, tr_regions_bam,
                                exon_intron_bed,
                                correct_min_ex_order=correct_min_ex_order,
                                tr2exc_dic=tr2exc_dic,
                                read_pos_mode=args.read_pos_mode,
                                eib_width=args.eib_width,
                                add_isr_bed=isr_tmp_bed,
                                count_isr_double=count_isr_double,
                                reg2cov_dic=reg2cov_dic,
                                isr_sub_count=substr_isrc_from_int_c,
                                isr_intron_reg_dic=isr_intron_reg_dic,
                                tr_ids_dic=trid2isrc_dic)


    """
    Output transcript regions in 12-column BED format for IGV viewing.

    """

    print("Output transcript regions in 12-column BED format ... ")
    hoodlib.bed_output_exon_12col_bed_file(trid2isrc_dic, tr_sol_igv_bed,
                                           trid2reg_dic, trid2exc_dic, next2reg_dic,
                                           exid2next_dic=exid2next_dic)

    """
    Calculate exon ID -> neighboring exon ISR connectivity count.

    """
    exid2isrn_dic = {} # exon ID -> neighboring exon ISR connectivity count.
    next2top_isrn_dic = {} # NEXT ID -> top ISRN count (of all associated exons).

    ol_nexts_dic = {}
    for next_id in ol_nexts_list:
        ol_nexts_dic[next_id] = 1

    print("Get neighboring exon ISR counts ... ")
    for next in ol_nexts_dic:

        for tr_id in next2trid_list_dic[next]:
            tr_exc = trid2exc_dic[tr_id]
            # Calculate for all transcript exons.
            for i in range(tr_exc):
                ex_nr = i + 1
                ex_id = tr_id + "_e" + str(ex_nr)
                if ex_id not in exid2isrn_dic:
                    isrn_c = hoodlib.get_exid_isr_hood_count(ex_id, exid2trid_dic,
                                                    exid2next_dic, nexts_cisrc_dic)
                    exid2isrn_dic[ex_id] = isrn_c
                isrn_c = exid2isrn_dic[ex_id]
                match_next = exid2next_dic[ex_id]
                if match_next in next2top_isrn_dic:
                    if isrn_c > next2top_isrn_dic[match_next]:
                        next2top_isrn_dic[match_next] = isrn_c
                else:
                    next2top_isrn_dic[match_next] = isrn_c


    """
    If --rnaseq-bam, we need to calculate next2top_isrn_dic again, since
    we don't want to have RNAseq reads in this dictionary.

    """

    if args.rnaseq_bam:

        print("--rnaseq-bam provided. Recalculate NEXT to top ISRN counts ... ")

        assert nexts_clip_cisrc_dic, "nexts_clip_cisrc_dic empty"
        exid2_clip_isrn_dic = {}
        next2top_isrn_dic = {}

        for next in ol_nexts_dic:

            for tr_id in next2trid_list_dic[next]:
                tr_exc = trid2exc_dic[tr_id]
                for i in range(tr_exc):
                    ex_nr = i + 1
                    ex_id = tr_id + "_e" + str(ex_nr)
                    if ex_id not in exid2_clip_isrn_dic:
                        isrn_c = hoodlib.get_exid_isr_hood_count(ex_id, exid2trid_dic,
                                                        exid2next_dic, nexts_clip_cisrc_dic)
                        exid2_clip_isrn_dic[ex_id] = isrn_c
                    isrn_c = exid2_clip_isrn_dic[ex_id]
                    match_next = exid2next_dic[ex_id]
                    if match_next in next2top_isrn_dic:
                        if isrn_c > next2top_isrn_dic[match_next]:
                            next2top_isrn_dic[match_next] = isrn_c
                    else:
                        next2top_isrn_dic[match_next] = isrn_c

    """
    Get exons fully overlapping with ISR-containing introns.
    Then later remove those transcripts from transcript context selection.

    min_intron_reg_isrc:
        Minimum ISR count an intronic region needs to be included in
        overlap calculation.
    isr_intron_reg_dic:
        Intronic region ["chr,s,e,pol"] -> ISR count.

    """

    rem_nexts_dic = {}

    if isr_intron_reg_dic:

        print("Remove exons fully overlapping with ISR containing introns ... ")
        rem_nexts_dic = hoodlib.get_exons_fully_ol_with_isr_introns(isr_intron_reg_dic,
                                                    next2reg_dic,
                                                    next_ids_dic=ol_nexts_dic,
                                                    reg2cov_dic=reg2cov_dic,
                                                    next2top_isrn_dic=next2top_isrn_dic,
                                                    max_read2isr_ratio=max_read2isr_ratio,
                                                    min_isrc=min_intron_reg_isrc)

        if rem_nexts_dic:
            c_rem_next = len(rem_nexts_dic)
            print("# of NEXT IDs removed due to full overlap with ISR introns:  %i" %(c_rem_next))
            # Remove IDs.
            for next_id in rem_nexts_dic:
                del ol_nexts_dic[next_id]


    """
    Get transcript ID to normalized coverage mapping.

    """

    trid2tcov_dic = {}
    for reg_id in regid2nc_dic:
        #print(reg_id, regid2nc_dic[reg_id])
        if re.search(".+_e\d+$", reg_id):
            m = re.search("(.+)_e\d+$", reg_id)
            tr_id = m.group(1)
            if tr_id not in trid2tcov_dic:
                trid2tcov_dic[tr_id] = 0.0
            if regid2nc_dic[reg_id][1] > 1: # do not include pseudo-counts.
                trid2tcov_dic[tr_id] += regid2nc_dic[reg_id][0]

            # if tr_id in trid2tcov_dic:
            #
            #         trid2tcov_dic[tr_id] += regid2nc_dic[reg_id][0]
            # else:
            #     trid2tcov_dic[tr_id] = regid2nc_dic[reg_id][0]

    # Get next,tr_id to exon number mapping.
    nexttrid2exnr_dic = {}
    for next in next2exids_dic:
        for ex_id in next2exids_dic[next]:
            assert re.search(".+_e\d", ex_id), "exon ID %s has invalid format"
            m = re.search("(.+)_e(\d+)", ex_id)
            tr_id = m.group(1)
            ex_nr = int(m.group(2))
            nexttrid = "%s,%s" %(next,tr_id)
            nexttrid2exnr_dic[nexttrid] = ex_nr

    # Transcript ID to full coverage mapping.
    trid2fuco_dic = {}
    for tr_id in trid2tcov_dic:
        # Check full coverage (returns True or False).
        full_cov = hoodlib.check_tr_id_full_coverage(tr_id, trid2exc_dic, regid2nc_dic)

        if full_cov:
            trid2fuco_dic[tr_id] = 1
        else:
            trid2fuco_dic[tr_id] = 0


    """
    Go over exonic --in sites and get transcript context sites.

    """

    tc_sites_gen_tmp_bed = args.out_folder + "/" + "exonic_sites.tr_con.gen.tmp.bed"

    # All transcript context sites (> min_eir) with genomic coordinates.
    GENCONBED = open(tc_sites_gen_tmp_bed, "w")

    exid2cov_dic = {} # exon ID -> [ei_ratio, ex_cov, int_cov, ex_read_count, int_read_count]
    id2tr_context_dic = {} # transcript context IDs.
    id2gen_context_dic = {} # genomic context IDs.
    id2exids_dic = {} # site ID to all fitting exon IDs > min_eir (min_eibr)
    trid2site_ids_dic = {} # Transcript ID to fitting site IDs.
    exid2eir_dic = {} # Exon ID to exon-intron ratio.
    exid2eibr_dic = {} # Exon ID to exon-intron border region ratio.
    exid2eibr_crit_dic = {} # Exon ID to exon-intron border region ratio criterion.
    exid2eibrs_dic = {} # Exon ID to exon-intron border region ratio(s) list.
    isrn_prefilter_skip_ids_dic = {} # Store site IDs removed due to --isr-prefilter.
    c_tr_filtered_sites = 0 # Filtered out due to transcript removed.
    c_eir_filtered_sites = 0 # Filtered out sites due to EIR filter.
    c_eir_wt_filtered_sites = 0 # Filtered out sites due to EIR whole transcript filter.
    c_eibr_filtered_sites = 0 # Filtered out sites due to EIBR filter.
    c_eibr_wt_filtered_sites = 0 # Filtered out sites due to EIBR whole transcript filter.
    c_tis_filtered_sites = 0 # Filtered out sites due to TIS filter.
    tr_filtered_gen_ids_dic = {}
    eir_filtered_gen_ids_dic = {}
    eir_wt_filtered_gen_ids_dic = {}
    eibr_filtered_gen_ids_dic = {}
    eibr_wt_filtered_gen_ids_dic = {}
    tis_filtered_gen_ids_dic = {}

    print("Check transcript context for each exonic site ... ")

    # sid = "SRSF1_K562_IDR_1668"
    # for next in id2next_list_dic[sid]:
    #     for tr_id in next2trid_list_dic[next]:
    #         print(sid, tr_id)
    #

    for site_id in id2next_list_dic:
        # Get all transcript IDs which contain NEXTs overlapping with site_id.
        tr_ids_list = []
        # Exon IDs for NEXTs containing site_id.
        ex_ids_list = []
        # Transcript to NEXT mapping.
        trid2next_dic = {}

        # Get correponding transcript IDs, exon IDs, and exon-intron (border) ratios.
        for next in id2next_list_dic[site_id]:

            # Filter out NEXT IDs here.
            if next in rem_nexts_dic:
                continue

            for tr_id in next2trid_list_dic[next]:

                # Filter out transcript IDs here.
                if tr_id in rem_tr_ids_dic:
                    continue

                # From NEXT to exon ID.
                nexttrid = "%s,%s" %(next, tr_id)
                ex_nr = nexttrid2exnr_dic[nexttrid]
                site_ex_id = tr_id + "_e" + str(ex_nr)

                # Number of transcript exons.
                tr_exc = trid2exc_dic[tr_id]

                # Calculate for all transcript exons.
                for i in range(tr_exc):
                    ex_nr = i + 1
                    ex_id = tr_id + "_e" + str(ex_nr)

                    if ex_id not in exid2cov_dic:
                        ex_cov = regid2nc_dic[ex_id][0]
                        ex_rc = regid2nc_dic[ex_id][1]
                        ei_ratio, int_cov, int_rc = hoodlib.get_ei_ratio_from_exon_id(ex_id, regid2nc_dic)
                        exid2cov_dic[ex_id] = [ei_ratio, ex_cov, int_cov, ex_rc, int_rc]
                        exid2eir_dic[ex_id] = ei_ratio

                        # if ex_id == "ENST00000302271.11_e11":
                        #     print(ex_id, "exid2cov_dic:")
                        #     print(exid2cov_dic[ex_id])
                        # if ex_id == "ENST00000478691.5_e10":
                        #     print(ex_id, "exid2cov_dic:")
                        #     print(exid2cov_dic[ex_id])

                        # if ex_id == "ENST00000390180.1_e1":
                        #     print("ex_id:", ex_id)
                        #     print("ex_cov:", ex_cov)
                        #     print("int_cov", int_cov)
                        #     print("ei_ratio", ei_ratio)
                        #     sys.exit()

                        eib_ratio, eib_crit = hoodlib.get_ei_border_ratio_from_exon_id(ex_id, regid2nc_dic,
                                                                                ratio_mode=args.eib_ratio_mode,
                                                                                min_reg_cov=min_border_region_cov,
                                                                                last_exon_dic=last_exon_dic,
                                                                                last_exon_ratio=min_outer_last_exb_ratio,
                                                                                exid2eibrs_dic=exid2eibrs_dic)

                        # if ex_id == "ENST00000366553.3_e2":
                        #     print("eibr_ratio:", eibr_ratio)
                        #     print("eibr_crit:", eibr_crit)
                        #     print("exid2eibrs_dic:", exid2eibrs_dic[ex_id])
                        #     print("ei_ratio:", ei_ratio)

                        exid2eibr_dic[ex_id] = eib_ratio
                        exid2eibr_crit_dic[ex_id] = eib_crit

                tr_ids_list.append(tr_id)
                if tr_id in trid2next_dic:
                    # This should not happen as each OVERLAPPING(!) NEXT should be exclusive with regard to the transcript ID it belongs to.
                    assert False, "transcript ID %s stored > 1 for site ID %s (NEXT: %s)" %(tr_id, site_id, next)
                else:
                    trid2next_dic[tr_id] = next
                ex_ids_list.append(site_ex_id)

        # assert tr_ids_list, "no transcript IDs extracted for site ID %s" %(site_id)
        if not tr_ids_list:
            id2gen_context_dic[site_id] = 1
            tr_filtered_gen_ids_dic[site_id] = 1
            c_tr_filtered_sites += 1
            continue

        # Transcripts overlapping with site ID (no ei_ratio filter).
        tr_ids_list = list(set(tr_ids_list))
        ex_ids_list = list(set(ex_ids_list))
        c_tr_ids_pre_filt = len(tr_ids_list)

        """
        Whole transcript EIR checking.

        Check for the whole transcript whether there are exon-intron ratios
        of the transcript exons <= a threshold (filter_ei_ratio). If there
        is a certain amount of these exons (min_occ_exons).

        filter_ei_ratio:
            Exons with EIR <= filter_ei_ratio are counted for tr_id.
        min_occ_exons_ratio:
            Set ratio of the total number of transcript exons required for
            transcript to be assigned to genomic context (return False).
            So if # of exons <= filter_ei_ratio is >= then the ratio of
            exons (round() to next integer, or math.ceil), return False.
        min_ei_cov:
            Minimum coverage (== read count) the exon or surrounding intron
            region(s) need to have to be included into exon counting.
        min_ei_cov_sum:
            Instead of OR, use the sum of exon and intron region for min_ei_cov.
        exid2isrn_dic:
            Exon ID -> ISR count to neighborhood.
            If this is given, use only exons with ISRN counts <= max_isrn_c.
        max_isrn_c:
            Define maximum ISRN count (exid2isrn_dic) (default: 0).
        exid2cov_dic:
            exon ID -> [ei_ratio, ex_cov, int_cov, ex_read_count, int_read_count]
        trid2exc_dic:
            Transcript ID -> exon count

        """

        if not args.no_eir_wt_filter:
            filt_ex_ids_list = []
            for ex_id in ex_ids_list:
                m = re.search("(.+)_e\d+$", ex_id)
                tr_id = m.group(1)
                check = hoodlib.check_transcript_eir_tc_state(tr_id,
                                                    exid2cov_dic, trid2exc_dic,
                                                    filter_ei_ratio=1.5,
                                                    min_ei_cov=50,
                                                    min_ei_cov_sum=True,
                                                    exid2isrn_dic=False,
                                                    max_isrn_c=10,
                                                    min_occ_exons_ratio=0.25)
                if check:
                    filt_ex_ids_list.append(ex_id)

            if not filt_ex_ids_list:
                id2gen_context_dic[site_id] = 1
                c_eir_wt_filtered_sites += 1
                eir_wt_filtered_gen_ids_dic[site_id] = 1
                continue
            else:
                ex_ids_list = filt_ex_ids_list

        """
        Whole transcript EIBR checking.

        Check whether a given transcript (tr_id) should be assigned transcript
        context (return True), or genomic context (return False). Base this
        decision on EIR ratios present in the transcript. Further controlled
        by parameters:

        filter_ei_ratio:
            Exons with EIBR <= filter_eib_ratio are counted as genomic context
            evidence for tr_id. So the higher filter_ei_ratio is set, the more
            likely tr_id gets assigned to genomic context (returns False).
        min_occ_exons_ratio:
            Set ratio of the total number of transcript exons required for
            transcript to be assigned to genomic context (return False).
            So if # of exons <= filter_ei_ratio is >= then the ratio of
            exons (round() to next integer, or math.ceil), return False.
        exid2eibr_dic:
            exon ID -> exon-intron border ratio
        trid2exc_dic:
            Transcript ID -> exon count

        """

        if not args.no_eibr_wt_filter:
            filt_ex_ids_list = []
            for ex_id in ex_ids_list:
                m = re.search("(.+)_e\d+$", ex_id)
                tr_id = m.group(1)
                #print(site_id, tr_id, "EIBR WT ... ")
                check = hoodlib.check_transcript_eibr_tc_state(tr_id,
                                                    exid2eibr_dic, trid2exc_dic,
                                                    filter_eib_ratio=2.0,
                                                    min_occ_exons_ratio=0.2)
                if check:
                    filt_ex_ids_list.append(ex_id)

            if not filt_ex_ids_list:
                id2gen_context_dic[site_id] = 1
                c_eibr_wt_filtered_sites += 1
                eibr_wt_filtered_gen_ids_dic[site_id] = 1
                continue
            else:
                ex_ids_list = filt_ex_ids_list

        """
        Get transcript IDs with eir > min_eir.

        """
        eir_tr_ids_list = []
        eir_ex_ids_list = []

        for exon_id in ex_ids_list:
            ei_ratio = exid2cov_dic[exon_id][0]

            if ei_ratio >= args.min_ei_ratio:
                eir_tr_ids_list.append(exid2trid_dic[exon_id])
                eir_ex_ids_list.append(exon_id)

        eir_ex_ids_list = list(set(eir_ex_ids_list))
        eir_tr_ids_list = list(set(eir_tr_ids_list))
        # Transcripts overlapping with site_id (after ei_ratio filter).
        c_tr_ids_eir_filt = len(eir_tr_ids_list)
        if not c_tr_ids_eir_filt:
            c_eir_filtered_sites += 1
            eir_filtered_gen_ids_dic[site_id] = 1

        """
        Get transcript IDs with eir > min_eibr.
        min_eibr use same ratio as with min_eir.

        """
        if not args.no_eibr_filter and c_tr_ids_eir_filt:

            eibr_tr_ids_list = []
            eibr_ex_ids_list = []

            for exon_id in eir_ex_ids_list:
                eib_ratio = exid2eibr_dic[exon_id]

                if exon_id in isolated_exon_dic:
                    min_eib_ratio = min_isolated_eib_ratio
                else:
                    min_eib_ratio = args.min_eib_ratio
                # Bonus for higher EIR exons: decrease EIBR.
                if min_eir_bonus_ratio:
                    ei_ratio = exid2cov_dic[exon_id][0]
                    if ei_ratio >= min_eir_bonus_ratio:
                        min_eib_ratio = min_isolated_eib_ratio

                if eib_ratio == -1 or eib_ratio >= min_eib_ratio:
                    eibr_tr_ids_list.append(exid2trid_dic[exon_id])
                    eibr_ex_ids_list.append(exon_id)

            eir_ex_ids_list = list(set(eibr_ex_ids_list))
            eir_tr_ids_list = list(set(eibr_tr_ids_list))
            c_tr_ids_eir_filt = len(eir_tr_ids_list)
            if not c_tr_ids_eir_filt:
                c_eibr_filtered_sites += 1
                eibr_filtered_gen_ids_dic[site_id] = 1

        """
        Filter out transcripts containing intronic sites.

        """

        if not args.no_tis_filter and c_tr_ids_eir_filt:
            tis_tr_ids_list = []
            tis_ex_ids_list = []
            for exon_id in eir_ex_ids_list:
                tr_id = exid2trid_dic[exon_id]
                if tr_id in trid2intron_site_c_dic:
                    if trid2intron_site_c_dic[tr_id] >= args.min_n_tis_sites:
                        continue
                tis_tr_ids_list.append(tr_id)
                tis_ex_ids_list.append(exon_id)

            eir_ex_ids_list = list(set(tis_ex_ids_list))
            eir_tr_ids_list = list(set(tis_tr_ids_list))
            c_tr_ids_eir_filt = len(eir_tr_ids_list)
            if not c_tr_ids_eir_filt:
                c_tis_filtered_sites += 1
                tis_filtered_gen_ids_dic[site_id] = 1

        """
        Optional ISRN pre-filtering.
        Enabled by --isr-prefilter x
        x : minimum number of intron-spanning reads to neighboring exons.
        Intronless exons are not affected by this filtering step.

        exid2isrn_dic:
            This includes CLIP + RNA-seq ISR reads.

        """
        if args.isrn_prefilter and c_tr_ids_eir_filt:
            isr_prefilt_ex_ids_list = []
            for ex_id in eir_ex_ids_list:
                # Check if single exon.
                tr_id = exid2trid_dic[ex_id]
                exc = trid2exc_dic[tr_id]
                if exc == 1:
                    isr_prefilt_ex_ids_list.append(ex_id)
                else:
                    if exid2isrn_dic[ex_id] >= args.isrn_prefilter:
                        isr_prefilt_ex_ids_list.append(ex_id)
            if isr_prefilt_ex_ids_list:
                eir_ex_ids_list = []
                for ex_id in isr_prefilt_ex_ids_list:
                    eir_ex_ids_list.append(ex_id)
                eir_tr_ids_list = []
                for ex_id in eir_ex_ids_list:
                    eir_tr_ids_list.append(exid2trid_dic[ex_id])
                c_tr_ids_eir_filt = len(eir_tr_ids_list)
            else:
                # No exons left, skip site ID.
                isrn_prefilter_skip_ids_dic[site_id] = 1
                c_tr_ids_eir_filt = 0

        # Skip site IDs overlapping with exons < min_eir.
        if c_tr_ids_eir_filt:
            id2tr_context_dic[site_id] = 1
        else:
            id2gen_context_dic[site_id] = 1
            continue

        # Output transcript context sites with genomic coordinates.
        GENCONBED.write("%s\n" %(id2row_dic[site_id]))

        # Site ID to > min_eir exon IDs list.
        id2exids_dic[site_id] = eir_ex_ids_list

        # Store possible exons / transcripts to site mapping.
        for exon_id in eir_ex_ids_list:
            tr_id = exid2trid_dic[exon_id]
            if tr_id in trid2site_ids_dic:
                trid2site_ids_dic[tr_id].append(site_id)
            else:
                trid2site_ids_dic[tr_id] = [site_id]

    GENCONBED.close()

    if c_tr_filtered_sites:
        print("# exonic sites assigned to genomic context (TRS filter):      %i" %(c_tr_filtered_sites))
    if c_eir_wt_filtered_sites:
        print("# exonic sites assigned to genomic context (EIR WT filter):   %i" %(c_eir_wt_filtered_sites))
    if c_eibr_wt_filtered_sites:
        print("# exonic sites assigned to genomic context (EIBR WT filter):  %i" %(c_eibr_wt_filtered_sites))
    if c_eir_filtered_sites:
        print("# exonic sites assigned to genomic context (EIR filter):      %i" %(c_eir_filtered_sites))
    if c_eibr_filtered_sites:
        print("# exonic sites assigned to genomic context (EIBR filter):     %i" %(c_eibr_filtered_sites))
    if c_tis_filtered_sites:
        print("# exonic sites assigned to genomic context (TIS filter):      %i" %(c_tis_filtered_sites))

    # Count number of sites for each transcript ID harboring exonic sites.
    trid2tsc_dic = {}
    # Exon ID to number of exonic sites on corresponding transcript.
    exid2tsc_dic = {}

    for site_id in id2exids_dic:
        for exon_id in id2exids_dic[site_id]:
            tr_id = exid2trid_dic[exon_id]
            site_ids_list = trid2site_ids_dic[tr_id]
            c_sites = len(list(set(site_ids_list)))
            trid2tsc_dic[tr_id] = c_sites
            exid2tsc_dic[exon_id] = c_sites

    c_tr_con_sites = len(id2tr_context_dic)
    c_gen_con_sites = len(id2gen_context_dic)
    c_pot_tr_reg = len(trid2site_ids_dic)

    print("# of overlapping transcripts > --min-ei-ratio:    %i" %(c_pot_tr_reg))
    print("# of exonic sites (assigned transcript context):  %i" %(c_tr_con_sites))
    print("# of exonic sites (assigned genome context):      %i" %(c_gen_con_sites))
    if isrn_prefilter_skip_ids_dic:
        print("# sites < --isr-prefilter (assigned to GC):       %i" %(len(isrn_prefilter_skip_ids_dic)))


    """
    Get sites at exon borders.

    id2gen_se_dic:
        site_id -> [gen_start, gen_end]
    id2next_list_dic:
        Use site ID -> NEXT list mapping, to remove border pairs on same
        NEXT exon regions (can happen if --isr-ext-mode 2)

    """
    print("Get adjacent sites at exon borders ... ")
    id2ids_dic, ids2isrc_dic = hoodlib.get_exon_border_site_pairs(
                                                tc_sites_gen_tmp_bed, isr_tmp_bed,
                                                max_site_dist=args.isr_max_reg_len,
                                                id2gen_se_dic=False,
                                                id2next_list_dic=False)


    """
    Remove exon border pairs which have no common transcripts.

    id2ex_tr_list_dic:
        site ID -> transcript IDs list, with site overlapping exonic parts.

    """
    id2ex_tr_list_dic = {}
    for site_id in id2exids_dic:
        for ex_id in id2exids_dic[site_id]:
            tr_id = exid2trid_dic[ex_id]
            if site_id in id2ex_tr_list_dic:
                id2ex_tr_list_dic[site_id].append(tr_id)
            else:
                id2ex_tr_list_dic[site_id] = [tr_id]

    id2ids_dic = hoodlib.remove_no_common_tr_exb_pairs(id2ids_dic, id2ex_tr_list_dic)

    """
    Remove exon border pairs from id2ids_dic which are not
    on neighboring exons.

    id2ids_dic = hoodlib.rem_exb_pairs_no_neighbor_ex(
                                        id2ids_dic, id2exids_dic,
                                        exid2exnr_dic=exid2exnr_dic,
                                        exid2trid_dic=exid2trid_dic)

    """

    """
    Remove exon border pairs from id2 id2ids_dic which are not on
    neighoring exons, or which are too far away from the adjacent
    exon borders.

    """

    id2ids_dic = hoodlib.rem_exb_pairs_exb_dist(id2ids_dic, id2exids_dic,
                           id2gen_se_dic, id2gen_cp_dic, exid2gen_se_dic,
                           max_exb_dist=args.isr_max_reg_len,
                           exid2exnr_dic=exid2exnr_dic,
                           exid2trid_dic=exid2trid_dic)

    c_exb_sites = len(id2ids_dic)
    print("# adjacent sites at exon borders:  %i" %(c_exb_sites))


    """
    Get info on site-exon overlap (SEO), i.e. whether site fully overlaps
    exon, or just partially.

    siteexid2seo_dic:
        "site_id,ex_id" -> 1 (full overlap), 0 (partial overlap)

    """
    siteexid2seo_dic = {} # site ID,exon ID to full coverage ("yes", "no")

    for site_id in id2exids_dic:

        eir_ex_ids_list = id2exids_dic[site_id]

        for ex_id in eir_ex_ids_list:
            siteexid = site_id + "," + ex_id
            next_id = exid2next_dic[ex_id]
            sitenextid = site_id + "," + next_id
            hit_s = idnext2ol_se_dic[sitenextid][0]
            hit_e = idnext2ol_se_dic[sitenextid][1]
            hit_l = hit_e - hit_s
            site_l = id2len_dic[site_id]
            if hit_l < site_l:
                siteexid2seo_dic[siteexid] = 0
            elif hit_l == site_l:
                siteexid2seo_dic[siteexid] = 1
            else:
                assert False, "site ID length < hit length (%i < %i) for site ID %s" %(site_l, hit_l, site_id)


    """
    Get best ranking transcript IDs for each filter.

    idfilt2best_trids_dic:
        "site_id,filter_id"
        -> top transcript ID(s) after applying filter on exon IDs > min_eir

    10 categories:
    EIR     1
    EXB     1
    TSC     1
    ISRN    1
    ISR     1
    ISRFC   1
    SEO     1
    FUCO    1
    TCOV    1
    TSL     1

    """

    idfilt2best_trids_dic = {}
    idfilt2best_exids_dic = {}
    id2exb_pair_dic = {} # site ID to selected exon border pair ID.
    id2new_pair_id_dic = {} # site ID to new merged pair ID.

    for site_id in id2exids_dic:

        # Exon IDs list > min_eir overlapping with site ID.
        eir_ex_ids_list = id2exids_dic[site_id]
        eir_tr_ids_list = []
        eir_sex_ids_list = []
        for ex_id in eir_ex_ids_list:
            eir_sex_ids_list.append(site_id + "," + ex_id)
            eir_tr_ids_list.append(exid2trid_dic[ex_id])

        # Exon-intron ratio (EIR).
        eir_best_ex_ids_list = hoodlib.get_highest_scoring_ids(eir_ex_ids_list,
                                                    exid2eir_dic)
        eir_best_ex_ids_list = list(set(eir_best_ex_ids_list))
        eir_best_tr_ids_list = []
        for ex_id in eir_best_ex_ids_list:
            eir_best_tr_ids_list.append(exid2trid_dic[ex_id])
        idfilt2best_trids_dic["%s,EIR" %(site_id)] = eir_best_tr_ids_list
        idfilt2best_exids_dic["%s,EIR" %(site_id)] = eir_best_ex_ids_list

        """
        Site part of pair at exon border (EXB).
        ids2isrc_dic:
            CLIP ISR count (not RNA-seq!) connecting pair sites.
            So the connection is checked based on CLIP read evidence only.

        """

        exb_best_ex_ids_list, pair_id = hoodlib.get_border_pair_exons(site_id,
                                            id2exids_dic, exid2trid_dic,
                                            id2ids_dic, ids2isrc_dic,
                                            min_isr_c=args.min_exbs_isr_c)


        # if site_id == "SRSF1_K562_IDR_0372":
        #     print("SRSF1_K562_IDR_0372")
        #     print("exb_best_ex_ids_list:", exb_best_ex_ids_list)
        #     print("pair_id:", pair_id)
        #
        # if site_id == "SRSF1_K562_IDR_1388":
        #     print("SRSF1_K562_IDR_1388")
        #     print("exb_best_ex_ids_list:", exb_best_ex_ids_list)
        #     print("pair_id:", pair_id)
        #
        # if site_id == "SRSF1_K562_IDR_1412":
        #     print("SRSF1_K562_IDR_1412")
        #     print("exb_best_ex_ids_list:", exb_best_ex_ids_list)
        #     print("pair_id:", pair_id)
        #



        """
SRSF1_K562_IDR_0372
exb_best_ex_ids_list: ['ENST00000505658.6_e10']
pair_id:
SRSF1_K562_IDR_1388
exb_best_ex_ids_list: ['ENST00000505658.6_e10', 'ENST00000240304.5_e10']
pair_id:
SRSF1_K562_IDR_1412
exb_best_ex_ids_list: ['ENST00000505658.6_e9']
pair_id: SRSF1_K562_IDR_0372

SRSF1_K562_IDR_0372
id2ids_dic: ['SRSF1_K562_IDR_1388', 'SRSF1_K562_IDR_1412']





        print("id2ids_dic:", id2ids_dic[sid])
        print("id2ids_dic[SRSF1_K562_IDR_1388]:", id2ids_dic["SRSF1_K562_IDR_1388"])
        print("id2ids_dic[SRSF1_K562_IDR_1412]:", id2ids_dic["SRSF1_K562_IDR_1412"])


        sid2 = "SRSF1_K562_IDR_1388"
        sid3 = "SRSF1_K562_IDR_1412"
        sids1 = "%s-EB-%s" %(sid, sid2)
        sids2 = "%s-EB-%s" %(sid, sid3)
        if sids1 in ids2isrc_dic:
            print(sids1, ids2isrc_dic[sids1])
        if sids2 in ids2isrc_dic:
            print(sids2, ids2isrc_dic[sids2])



        SRSF1_K562_IDR_0372
        exb_best_ex_ids_list: ['ENST00000505658.6_e10']
        pair_id:
        id2ids_dic: ['SRSF1_K562_IDR_1388', 'SRSF1_K562_IDR_1412']


Get adjacent sites at exon borders ...
# adjacent sites at exon borders:  115
SRSF1_K562_IDR_0372
exb_best_ex_ids_list: ['ENST00000505658.6_e10']
pair_id:


id2ids_dic[SRSF1_K562_IDR_1388]: ['SRSF1_K562_IDR_0372']
id2ids_dic[SRSF1_K562_IDR_1412]: ['SRSF1_K562_IDR_0372']
SRSF1_K562_IDR_0372-EB-SRSF1_K562_IDR_1388 11
SRSF1_K562_IDR_0372-EB-SRSF1_K562_IDR_1412 2



        """


        if pair_id:
            id2exb_pair_dic[site_id] = pair_id
            pair_ids_list = [site_id, pair_id]
            pair_ids_list.sort()
            pair_ids_str = '-EB-'.join(pair_ids_list)
            id2new_pair_id_dic[site_id] = pair_ids_str
        exb_best_ex_ids_list = list(set(exb_best_ex_ids_list))
        exb_best_tr_ids_list = []
        for ex_id in exb_best_ex_ids_list:
            exb_best_tr_ids_list.append(exid2trid_dic[ex_id])
        idfilt2best_trids_dic["%s,EXB" %(site_id)] = exb_best_tr_ids_list
        idfilt2best_exids_dic["%s,EXB" %(site_id)] = exb_best_ex_ids_list

        # Site-exon overlap (SEO).
        seo_best_sex_ids_list = hoodlib.get_highest_scoring_ids(eir_sex_ids_list, siteexid2seo_dic)
        seo_best_sex_ids_list = list(set(seo_best_sex_ids_list))
        seo_best_ex_ids_list = []
        seo_best_tr_ids_list = []
        for sex_id in seo_best_sex_ids_list:
            sid, ex_id = sex_id.split(",")
            seo_best_ex_ids_list.append(ex_id)
            seo_best_tr_ids_list.append(exid2trid_dic[ex_id])
        idfilt2best_trids_dic["%s,SEO" %(site_id)] = seo_best_tr_ids_list
        idfilt2best_exids_dic["%s,SEO" %(site_id)] = seo_best_ex_ids_list

        # Transcript site count (TSC).
        tsc_best_tr_ids_list = hoodlib.get_highest_scoring_ids(eir_tr_ids_list, trid2tsc_dic)
        tsc_best_tr_ids_list = list(set(tsc_best_tr_ids_list))
        idfilt2best_trids_dic["%s,TSC" %(site_id)] = tsc_best_tr_ids_list

        # Intron-spanning reads in exon neighborhood (ISRN).
        isrn_best_ex_ids_list = hoodlib.get_highest_scoring_ids(eir_ex_ids_list, exid2isrn_dic)
        isrn_best_ex_ids_list = list(set(isrn_best_ex_ids_list))
        isrn_best_tr_ids_list = []
        for ex_id in isrn_best_ex_ids_list:
            isrn_best_tr_ids_list.append(exid2trid_dic[ex_id])
        idfilt2best_trids_dic["%s,ISRN" %(site_id)] = isrn_best_tr_ids_list
        idfilt2best_exids_dic["%s,ISRN" %(site_id)] = isrn_best_ex_ids_list

        # Intron-spanning reads over whole transcript (ISR).
        isr_best_tr_ids_list = hoodlib.get_highest_scoring_ids(eir_tr_ids_list, trid2isrc_dic)
        isr_best_tr_ids_list = list(set(isr_best_tr_ids_list))
        idfilt2best_trids_dic["%s,ISR" %(site_id)] = isr_best_tr_ids_list

        # All transcript exons have read support (FUCO).
        fuco_best_tr_ids_list = hoodlib.get_highest_scoring_ids(eir_tr_ids_list, trid2fuco_dic)
        fuco_best_tr_ids_list = list(set(fuco_best_tr_ids_list))
        idfilt2best_trids_dic["%s,FUCO" %(site_id)] = fuco_best_tr_ids_list

        # Intron-spanning reads connecting each transcript exon (ISRFC).
        isrfc_best_tr_ids_list = hoodlib.get_highest_scoring_ids(eir_tr_ids_list, trid2isrfc_dic)
        isrfc_best_tr_ids_list = list(set(isrfc_best_tr_ids_list))
        idfilt2best_trids_dic["%s,ISRFC" %(site_id)] = isrfc_best_tr_ids_list

        # Transcript read coverage (TCOV).
        tcov_best_tr_ids_list = hoodlib.get_highest_scoring_ids(eir_tr_ids_list, trid2tcov_dic)
        tcov_best_tr_ids_list = list(set(tcov_best_tr_ids_list))
        idfilt2best_trids_dic["%s,TCOV" %(site_id)] = tcov_best_tr_ids_list

        # Transcript support level (TSL).
        tsl_best_tr_ids_list = hoodlib.get_highest_scoring_ids(eir_tr_ids_list, trid2tslsc_dic)
        tsl_best_tr_ids_list = list(set(tsl_best_tr_ids_list))
        idfilt2best_trids_dic["%s,TSL" %(site_id)] = tsl_best_tr_ids_list


    """
    Go over exon border pair sites, and check for exon border site groups
    with > 2 connected sites.

    Here we want to remove exon border sites which are connected to other
    exon border sites, and these are again connected to other border sites.
    In this case, we select the best connection, and remove the sites
    from the transcript context set with lower connections. This way we
    keep the actual binding site (exon border spanning), and only remove
    redundant sites.

    """

    EXBGTSVOUT = open(exb_groups_tsv_out, "w")
    EXBGTSVOUT.write("site_id\tpair_id\tis_read_count\toutput_id\tgroup_size\tconnected_exb_group_ids\tassociated_transcripts\tassociated_genes\n")

    c_exb_groups_found = 0
    bed_out_exbs_dic = {}
    id2new_pair_dic = {}
    remove_ids_dic = {}  # site IDs part of exon border group to be removed.
    groups_seen_dic = {}

    for site_id in id2exb_pair_dic:

        con_exb_sites_dic = {}
        hoodlib.get_connected_exb_sites(site_id, id2exb_pair_dic, con_exb_sites_dic)

        con_exb_sites_list = []
        for sid in con_exb_sites_dic:
            con_exb_sites_list.append(sid)
        con_exb_sites_list.sort()

        con_exb_sites_str = ','.join(con_exb_sites_list)
        if con_exb_sites_str in groups_seen_dic:
            continue
        groups_seen_dic[con_exb_sites_str] = 1

        group_size = len(con_exb_sites_dic)

        if group_size > 2:
            c_exb_groups_found += 1

            # Get the one pair connected to each other in group.
            best_sids_list = hoodlib.get_exb_group_best_con(con_exb_sites_list,
                                                            id2exb_pair_dic)
            best_sids_str = '-EB-'.join(best_sids_list)
            best_isrc = ids2isrc_dic[best_sids_str]

            pair_seen_dic = {}
            for sid in con_exb_sites_list:
                bed_out_exbs_dic[sid] = 1

                if sid not in best_sids_list:
                    remove_ids_dic[sid] = 1

                pid = id2exb_pair_dic[sid]
                sids_list = [sid, pid]
                sids_list.sort()
                sids_str = '-EB-'.join(sids_list)
                if sids_str in pair_seen_dic:
                    continue
                pair_seen_dic[sids_str] = 1

                output_id = "-"
                if sids_str == best_sids_str:
                    output_id = sids_str

                isrc = ids2isrc_dic[sids_str]

                assoc_trid_list = idfilt2best_trids_dic["%s,EXB" %(sid)]
                assoc_trid_str = ','.join(assoc_trid_list)
                assoc_gid_list = []
                for trid in assoc_trid_list:
                    assoc_gid_list.append(trid2gid_dic[trid])
                assoc_gid_str = ','.join(assoc_gid_list)

                EXBGTSVOUT.write("%s\t%s\t%i\t%s\t%i\t%s\t%s\t%s\n" %(sid, pid, isrc, output_id, group_size, con_exb_sites_str, assoc_trid_str, assoc_gid_str))

    EXBGTSVOUT.close()


    if c_exb_groups_found:

        print("Exon border site groups found ... ")

        hoodlib.bed_write_row_dic_into_file(id2row_dic, exb_groups_bed_out,
                                            id2out_dic=bed_out_exbs_dic)

        # Delete left-out exon border site IDs inside groups.
        c_ids_pre_filt = len(id2exids_dic)
        c_ids_remove = len(remove_ids_dic)
        c_ids_remain = c_ids_pre_filt - c_ids_remove
        for site_id in remove_ids_dic:
            del id2exids_dic[site_id]
            del id2exb_pair_dic[site_id]

        print("# of exon border groups with > 2 members:        %i" %(c_exb_groups_found))
        print("# of exonic sites removed (exon border groups):  %i" %(c_ids_remove))
        print("# of exonic sites remaining:                     %i" %(c_ids_remain))


    """
    Get site ID - transcript ID combination scores.

    sitetrid2comb_sc_dic:
        site_id,tr_id -> combination score

    """
    sitetrid2comb_sc_dic = {}

    for site_id in id2exids_dic:

        # Exon IDs list > min_eir overlapping with site ID.
        eir_ex_ids_list = id2exids_dic[site_id]
        eir_tr_ids_list = []
        for ex_id in eir_ex_ids_list:
            eir_tr_ids_list.append(exid2trid_dic[ex_id])

        # Get combination score for each site_id tr_id combination.
        trid2comb_sc_dic = hoodlib.get_sid_trid_combination_score(site_id, eir_tr_ids_list, idfilt2best_trids_dic)
        for tr_id in trid2comb_sc_dic:
            sitetrid = "%s,%s" %(site_id, tr_id)
            sitetrid2comb_sc_dic[sitetrid] = trid2comb_sc_dic[tr_id]


    """
    Go over transcript context sites again, to extract stats and determine
    most likely transcript for each transcript context site.

    """


    # Transcript exon regions with exonic sites BED.
    TREXBED = open(exon_regions_all_tr_bed, "w")
    TREXIGVBED = open(exon_regions_all_tr_igv_bed, "w")

    # Exonic sites statistics.
    OUTSTATS = open(exonic_site_stats_out, "w")
    OUTSTATS.write("site_id\ttranscript_id\tsite_tr_comb_sc\tgene_id\tgene_name\tol_exon_id\tselected_transcript\tselect_criterion\tigv_exon_region\tfull_hit\tconnected_exb_ids\tmerged_exb_id\toverlap_exon_cov\tsurround_intron_cov\texon_intron_ratio\tisn_read_c\tis_read_c\texons_fully_con\ttr_cov\treads_on_all_ex\tc_tr_sites\ttr_len\ttr_ex_c\ttr_supp_level\tgencode_basic\tccds\ttr_biotype\n")

    tr_id_output_dic = {} # remember transcript IDs for which exon IDs already output.
    trid2stats_dic = {} # Transcript ID to isr+coverage+#sites stats.
    sitetrid2coords_dic = {} # Site ID coordinates on transcripts.
    exid2stats_dic = {} # Exon ID to eir+isr stats.
    id2sel_trid_exid_crit_dic = {} # site ID to selected exon ID + criterion.
    all_tr_ex_reg_dic = {} # exon ID to genomic region string.
    all_tr_ex_reg_igv_dic = {} # transcript ID to region in IGV format / bed-12 format.

    print("Select most likely transcript for each transcript context site ... ")

    print("F1 filter list:", list_f1_filter)
    print("F2 filter list:", list_f2_filter)

    for site_id in id2exids_dic:

        # Exons > min_eir overlapping with site.
        eir_ex_ids_list = id2exids_dic[site_id]
        c_rem_ids = len(eir_ex_ids_list)
        rem_ex_ids_list = []
        for ex_id in eir_ex_ids_list:
            rem_ex_ids_list.append(ex_id)
        rem_tr_ids_list = []
        for ex_id in rem_ex_ids_list:
            rem_tr_ids_list.append(exid2trid_dic[ex_id])

        sel_tr_id = ""
        sel_criter = ""

        """
        If only one overlapping exon left after min_eir filtering, use this
        exon / transcript.

        """
        if c_rem_ids == 1:
            sel_tr_id = exid2trid_dic[eir_ex_ids_list[0]]
            sel_criter = "ONE_MIN_EIR_EXON"

        """
        In case of site being located at exon border and adjacent site on
        connected exon border is present, keep only exon(s) /
        transcript(s) compatible with this exon border connection.

        """

        if c_rem_ids > 1 and site_id in id2exb_pair_dic:
            exb_best_ex_ids_list = idfilt2best_exids_dic["%s,EXB" %(site_id)]

            c_rem_ids = len(exb_best_ex_ids_list)
            if c_rem_ids == 1:
                sel_tr_id = exid2trid_dic[exb_best_ex_ids_list[0]]
                sel_criter = "ONE_EXB_PAIR_COMB"
            # In case of exon border pairs, also filter eir_ex_ids_list.
            eir_ex_ids_list = []
            # Exon IDs for remaining filtering steps.
            rem_ex_ids_list = []
            for ex_id in exb_best_ex_ids_list:
                eir_ex_ids_list.append(ex_id)
                rem_ex_ids_list.append(ex_id)
            rem_tr_ids_list = []
            for ex_id in rem_ex_ids_list:
                rem_tr_ids_list.append(exid2trid_dic[ex_id])

        """
        F1 Filtering.

        Sequential Filtering.

        """

        if c_rem_ids > 1 and not args.no_f1_filter:
            assert list_f1_filter, "list_f1_filter empty"
            for fid in list_f1_filter:
                if fid == "EIR":
                    rem_ex_ids_list = hoodlib.get_highest_scoring_ids(rem_ex_ids_list, exid2eir_dic)
                    rem_tr_ids_list = []
                    for ex_id in rem_ex_ids_list:
                        rem_tr_ids_list.append(exid2trid_dic[ex_id])
                elif fid == "ISRN":
                    rem_ex_ids_list = hoodlib.get_highest_scoring_ids(rem_ex_ids_list, exid2isrn_dic)
                    rem_tr_ids_list = []
                    for ex_id in rem_ex_ids_list:
                        rem_tr_ids_list.append(exid2trid_dic[ex_id])
                elif fid == "SEO":
                    rem_sex_ids_list = []
                    for ex_id in rem_ex_ids_list:
                        rem_sex_ids_list.append(site_id + "," + ex_id)
                    rem_sex_ids_list = hoodlib.get_highest_scoring_ids(rem_sex_ids_list, siteexid2seo_dic)
                    rem_tr_ids_list = []
                    for sex_id in rem_sex_ids_list:
                        sid, ex_id = sex_id.split(",")
                        rem_tr_ids_list.append(exid2trid_dic[ex_id])
                elif fid == "TSC":
                    rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2tsc_dic)
                elif fid == "ISR":
                    rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2isrc_dic)
                elif fid == "FUCO":
                    rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2fuco_dic)
                elif fid == "ISRFC":
                    rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2isrfc_dic)
                elif fid == "TCOV":
                    rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2tcov_dic)
                elif fid == "TSL":
                    rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2tslsc_dic)
                else:
                    assert False, "invalid feature ID \"%s\" set" %(fid)
                c_rem_ids = len(rem_tr_ids_list)
                if c_rem_ids == 1:
                    sel_tr_id = rem_tr_ids_list[0]
                    sel_criter = "F1_%s" %(fid)
                    break

        """
        F2 Filtering.

        Majority vote or sequential Filtering.

        """

        if c_rem_ids > 1:

            # Remaining exon / transcript IDs after F1 sequential filtering.
            rem_ex_ids_list = []
            for ex_id in eir_ex_ids_list:
                tr_id = exid2trid_dic[ex_id]
                if tr_id in rem_tr_ids_list:
                    rem_ex_ids_list.append(ex_id)
            rem_ex_ids_list = list(set(rem_ex_ids_list))
            rem_tr_ids_list = list(set(rem_tr_ids_list))

            assert list_f2_filter, "list_f2_filter empty"

            if args.f2_mode == 1:
                # Majority vote.
                # Default: list_f2_filter = ['EIR', 'ISRN', 'ISR', 'FUCO', 'TCOV']
                best_ids_list = []
                for fid in list_f2_filter:
                    if fid == "EIR":
                        top_ex_ids_list = hoodlib.get_highest_scoring_ids(rem_ex_ids_list, exid2eir_dic)
                        top_tr_ids_list = []
                        for ex_id in top_ex_ids_list:
                            top_tr_ids_list.append(exid2trid_dic[ex_id])
                    elif fid == "ISRN":
                        top_ex_ids_list = hoodlib.get_highest_scoring_ids(rem_ex_ids_list, exid2isrn_dic)
                        top_tr_ids_list = []
                        for ex_id in top_ex_ids_list:
                            top_tr_ids_list.append(exid2trid_dic[ex_id])
                    elif fid == "SEO":
                        rem_sex_ids_list = []
                        for ex_id in rem_ex_ids_list:
                            rem_sex_ids_list.append(site_id + "," + ex_id)
                        top_sex_ids_list = hoodlib.get_highest_scoring_ids(rem_sex_ids_list, siteexid2seo_dic)
                        top_tr_ids_list = []
                        for sex_id in top_sex_ids_list:
                            sid, ex_id = sex_id.split(",")
                            top_tr_ids_list.append(exid2trid_dic[ex_id])
                    elif fid == "TSC":
                        top_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2tsc_dic)
                    elif fid == "ISR":
                        top_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2isrc_dic)
                    elif fid == "ISRFC":
                        top_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2isrfc_dic)
                    elif fid == "FUCO":
                        top_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2fuco_dic)
                    elif fid == "TCOV":
                        top_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2tcov_dic)
                    elif fid == "TSL":
                        top_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2tslsc_dic)
                    else:
                        assert False, "invalid feature ID \"%s\" set" %(fid)

                    best_ids_list += top_tr_ids_list

                assert best_ids_list, "no transcript IDs resulting from majority vote filtering"

                best_ids_c_dic = {}
                for tr_id in best_ids_list:
                    if tr_id in best_ids_c_dic:
                        best_ids_c_dic[tr_id] += 1
                    else:
                        best_ids_c_dic[tr_id] = 1

                f2_best_tr_ids_list = hoodlib.get_highest_scoring_ids(best_ids_list, best_ids_c_dic)

                # print("f2_best_tr_ids_list", f2_best_tr_ids_list)

                c_rem_ids = len(f2_best_tr_ids_list)
                if c_rem_ids == 1:
                    sel_tr_id = f2_best_tr_ids_list[0]
                    sel_criter = "F2_MAJORITY_VOTE"

                rem_tr_ids_list = []
                for tr_id in f2_best_tr_ids_list:
                    rem_tr_ids_list.append(tr_id)


            elif args.f2_mode == 2:
                # Sequential filtering.
                for fid in list_f2_filter:
                    if fid == "EIR":
                        rem_ex_ids_list = hoodlib.get_highest_scoring_ids(rem_ex_ids_list, exid2eir_dic)
                        rem_tr_ids_list = []
                        for ex_id in rem_ex_ids_list:
                            rem_tr_ids_list.append(exid2trid_dic[ex_id])
                    elif fid == "ISRN":
                        rem_ex_ids_list = hoodlib.get_highest_scoring_ids(rem_ex_ids_list, exid2isrn_dic)
                        rem_tr_ids_list = []
                        for ex_id in rem_ex_ids_list:
                            rem_tr_ids_list.append(exid2trid_dic[ex_id])
                    elif fid == "SEO":
                        rem_sex_ids_list = []
                        for ex_id in rem_ex_ids_list:
                            rem_sex_ids_list.append(site_id + "," + ex_id)
                        rem_sex_ids_list = hoodlib.get_highest_scoring_ids(rem_sex_ids_list, siteexid2seo_dic)
                        rem_tr_ids_list = []
                        for sex_id in rem_sex_ids_list:
                            sid, ex_id = sex_id.split(",")
                            rem_tr_ids_list.append(exid2trid_dic[ex_id])
                    elif fid == "TSC":
                        rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2tsc_dic)
                    elif fid == "ISR":
                        rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2isrc_dic)
                    elif fid == "ISRFC":
                        rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2isrfc_dic)
                    elif fid == "FUCO":
                        rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2fuco_dic)
                    elif fid == "TCOV":
                        rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2tcov_dic)
                    elif fid == "TSL":
                        rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2tslsc_dic)
                    else:
                        assert False, "invalid feature ID \"%s\" set" %(fid)
                    c_rem_ids = len(rem_tr_ids_list)
                    if c_rem_ids == 1:
                        sel_tr_id = rem_tr_ids_list[0]
                        sel_criter = "F2_%s" %(fid)
                        break

            else:
                assert False, "invalid args.f2_mode set (%s)" %(args.f2_mode)

        """
        Post-filtering.

        """

        if c_rem_ids > 1:
            #
            # print("Post-filtering with %s" %(site_id))
            # print("rem_tr_ids_list:", rem_tr_ids_list)

            rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2tslsc_dic)
            sel_tr_id = rem_tr_ids_list[0]
            sel_criter = "POST_FILT_TSL_SC"
            if len(rem_tr_ids_list) > 1:
                rem_tr_ids_list = hoodlib.get_highest_scoring_ids(rem_tr_ids_list, trid2len_dic)
                sel_tr_id = rem_tr_ids_list[0]
                sel_criter = "POST_FILT_TR_LEN"
                if len(rem_tr_ids_list) > 1:
                    rem_tr_ids_list.sort()
                    sel_tr_id = rem_tr_ids_list[0]
                    sel_criter = "POST_FILT_ID_SORT"

        """
        Get selected transcript ID stats.

        """

        assert sel_tr_id, "no transcript ID selected during filtering procedure"
        assert sel_criter, "no selection criterion stored during filtering procedure"

        # Get selected exon ID.
        sel_ex_id = eir_ex_ids_list[0]
        sel_ex_c = trid2exc_dic[sel_tr_id]
        for i in range(sel_ex_c):
            ex_nr = i + 1
            ex_id = sel_tr_id + "_e%i" %(ex_nr)
            if ex_id in eir_ex_ids_list:
                sel_ex_id = ex_id
                break
        sel_next = exid2next_dic[sel_ex_id]

        id2sel_trid_exid_crit_dic[site_id] = [sel_tr_id, sel_ex_id, sel_criter]
        # Merged exon border sites ID.
        merged_exb_id = "-"
        if site_id in id2new_pair_id_dic:
            merged_exb_id = id2new_pair_id_dic[site_id]

        """
        Output all > min_eir (args.min_ei_ratio) site_ID,transcript_ID pairs.

        """

        for exon_id in eir_ex_ids_list:
            ei_ratio = exid2cov_dic[exon_id][0]
            exon_cov = exid2cov_dic[exon_id][1]
            intron_cov = exid2cov_dic[exon_id][2]
            isrn_c = exid2isrn_dic[exon_id]
            tr_id = exid2trid_dic[exon_id]
            isr_c = trid2isrc_dic[tr_id]
            full_cov = trid2fuco_dic[tr_id]
            isr_fc = trid2isrfc_dic[tr_id]
            tr_cov = trid2tcov_dic[tr_id]
            next_id = exid2next_dic[exon_id]
            idnext_id = "%s,%s" %(site_id, next_id)
            sitetrid = "%s,%s" %(site_id, tr_id)
            tr_site_c = exid2tsc_dic[exon_id]
            tr_len = trid2len_dic[tr_id]

            # siteexid = site_id + "," + exon_id
            # site_seo = siteexid2seo_dic[siteexid]
            #
            # # Site completely overlapping with exon ?
            # comp_site_ex_overlap = "no"
            # if site_seo:
            #     comp_site_ex_overlap = "yes"

            # Infos on connected site IDs via exon borders (+ # IDR reads connecting them).
            connected_exb_ids = ""
            if site_id in id2ids_dic:
                for sid in id2ids_dic[site_id]:
                    sids = "%s-EB-%s" %(site_id, sid)
                    con_c = ids2isrc_dic[sids]
                    connected_exb_ids += "%s,%i;" %(sid, con_c)
            else:
                connected_exb_ids = "-"

            exons_fully_con = "no"
            if isr_fc == 1:
                exons_fully_con = "yes"

            exons_fully_cov = "no"
            if full_cov == 1:
                exons_fully_cov = "yes"

            # Selected transcript ?
            selected = "no"
            criterion = "-"
            if sel_ex_id == exon_id:
                selected = "yes"
                criterion = sel_criter

            # site ID hit coordinates on genome.
            hit_s = idnext2ol_se_dic[idnext_id][0]
            hit_e = idnext2ol_se_dic[idnext_id][1]
            # NEXT exon coordinates on genome.
            gen_s = next2reg_dic[next_id][1]
            gen_e = next2reg_dic[next_id][2]
            gen_pol = next2reg_dic[next_id][3]

            hit_l = hit_e - hit_s
            site_l = id2len_dic[site_id]
            assert site_l >= hit_l, "site ID length < hit length (%i < %i) for site ID %s" %(site_l, hit_l, site_id)

            full_hit = "yes"
            if hit_l < id2len_dic[site_id]:
                full_hit = "no"

            hit_us_l = hit_s - gen_s
            if gen_pol == "-":
                hit_us_l = gen_e - hit_e

            # Get transcript hit start + end.
            tr_hit_s = 0
            for i in range(trid2exc_dic[tr_id]):
                ex_nr = i + 1
                ex_id = tr_id + "_e" + str(ex_nr)
                ex_l = regid2nc_dic[ex_id][2]
                if ex_id != exon_id:
                    tr_hit_s += ex_l
                else:
                    tr_hit_s += hit_us_l
                    break
            tr_hit_e = tr_hit_s + hit_l

            #site_id_sc = id2sc_dic[site_id]
            #tr_reg_row = "%s\t%i\t%i\t%s\t%s\t+" %(tr_id, tr_hit_s, tr_hit_e, site_id, str(site_id_sc))
            #TRCONBED.write("%s\n" %(tr_reg_row))
            #sitetrid2tr_row_dic[sitetrid] = tr_reg_row

            # Store site ID <-> exon ID / transcript ID stats.
            trid2stats_dic[tr_id] = [isr_c, full_cov, tr_cov]
            sitetrid2coords_dic[sitetrid] = [tr_hit_s, tr_hit_e]
            exid2stats_dic[exon_id] = [ei_ratio, isrn_c]

            # Output potential transcript exons (genomic coordinates).
            if tr_id not in tr_id_output_dic:
                tr_chr_id = trid2reg_dic[tr_id][0]
                tr_gen_s = trid2reg_dic[tr_id][1] # 0-based.
                tr_gen_e = trid2reg_dic[tr_id][2]
                tr_gen_pol = trid2reg_dic[tr_id][3]
                tr_id_output_dic[tr_id] = 1
                tr_exc = trid2exc_dic[tr_id]
                ex_len_list = []
                ex_offset_list = []
                range_start = 0
                range_stop = tr_exc
                range_step = 1
                range_add = 1
                if tr_gen_pol == "-":
                    range_start = tr_exc
                    range_stop = 0
                    range_step = -1
                    range_add = 0
                for i in range(range_start, range_stop, range_step):
                    ex_nr = i + range_add
                    ex_id = tr_id + "_e" + str(ex_nr)
                    ex_next = exid2next_dic[ex_id]
                    chr_id = next2reg_dic[ex_next][0]
                    assert tr_chr_id == chr_id, "transcript chromosome ID != NEXT region chromosome ID (%s != %s)" %(tr_chr_id, chr_id)
                    gen_s = next2reg_dic[ex_next][1] # 0-based.
                    gen_e = next2reg_dic[ex_next][2]
                    gen_pol = next2reg_dic[ex_next][3]
                    assert tr_gen_pol == gen_pol, "transcript gene polarity != NEXT region polarity (%s != %s)" %(tr_gen_pol, gen_pol)
                    ex_l = gen_e - gen_s
                    ex_offset = gen_s - tr_gen_s
                    ex_len_list.append(str(ex_l))
                    ex_offset_list.append(str(ex_offset))
                    trex_out = "%s\t%i\t%i\t%s\t0\t%s" %(chr_id, gen_s, gen_e, ex_id, gen_pol)
                    TREXBED.write("%s\n" %(trex_out))
                    all_tr_ex_reg_dic[ex_id] = trex_out

                # Output 12-col BED for IGV viewing.
                ex_len_str = ",".join(ex_len_list)
                ex_offset_str = ",".join(ex_offset_list)
                trexigv_out = "%s\t%i\t%i\t%s\t0\t%s\t%i\t%i\t100,100,100\t%i\t%s\t%s" %(tr_chr_id, tr_gen_s, tr_gen_e, tr_id, tr_gen_pol, tr_gen_s, tr_gen_e, tr_exc, ex_len_str, ex_offset_str)
                TREXIGVBED.write("%s\n" %(trexigv_out))
                all_tr_ex_reg_igv_dic[tr_id] = trexigv_out

            # Output exonic sites stats TSV.
            # Construct IGV region, format: chr2:12,942,218-15,050,597
            igv_chr = next2reg_dic[sel_next][0]
            igv_s = hoodlib.koma_sepp(next2reg_dic[sel_next][1])
            igv_e = hoodlib.koma_sepp(next2reg_dic[sel_next][2])
            igv_reg = "%s:%s-%s" %(igv_chr, igv_s, igv_e)

            sitetrid_comb_sc = sitetrid2comb_sc_dic[sitetrid]

            OUTSTATS.write("%s\t%s\t%i\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" %(
                    site_id, tr_id, sitetrid_comb_sc, trid2gid_dic[tr_id], trid2gna_dic[tr_id],
                    exon_id, selected, criterion, igv_reg, full_hit, connected_exb_ids, merged_exb_id,
                    str(exon_cov), str(intron_cov), str(ei_ratio), str(isrn_c), str(isr_c), exons_fully_con,
                    str(tr_cov), exons_fully_cov, str(tr_site_c), str(tr_len),
                    str(trid2exc_dic[tr_id]), str(trid2tsl_dic[tr_id][0]),
                    trid2tsl_dic[tr_id][1], trid2tsl_dic[tr_id][2], trid2tbt_dic[tr_id]))

    TREXBED.close()
    TREXIGVBED.close()
    OUTSTATS.close()


    """
    For exon border pair sites, assign transcript ID with highest EIR to
    both sites.

    id2sel_trid_exid_crit_dic[site_id] = [sel_tr_id, sel_ex_id, sel_criter]

    """

    pair_seen_dic = {} # Remember seen pair ID.
    for site_id in id2sel_trid_exid_crit_dic:
        if site_id in id2exb_pair_dic:

            pair_id = id2exb_pair_dic[site_id]
            if site_id in pair_seen_dic:
                continue

            sel_tr_id1 = id2sel_trid_exid_crit_dic[site_id][0]
            sel_tr_id2 = id2sel_trid_exid_crit_dic[pair_id][0]
            sel_ex_id1 = id2sel_trid_exid_crit_dic[site_id][1]
            sel_ex_id2 = id2sel_trid_exid_crit_dic[pair_id][1]
            sel_criter1 = id2sel_trid_exid_crit_dic[site_id][2]
            sel_criter2 = id2sel_trid_exid_crit_dic[pair_id][2]
            eir_sid1 = exid2eir_dic[sel_ex_id1]
            eir_sid2 = exid2eir_dic[sel_ex_id2]

            if eir_sid1 < eir_sid2:
                id2sel_trid_exid_crit_dic[site_id][0] = sel_tr_id2
                id2sel_trid_exid_crit_dic[site_id][1] = sel_ex_id2
                id2sel_trid_exid_crit_dic[site_id][2] = sel_criter2
            else:
                id2sel_trid_exid_crit_dic[pair_id][0] = sel_tr_id1
                id2sel_trid_exid_crit_dic[pair_id][1] = sel_ex_id1
                id2sel_trid_exid_crit_dic[pair_id][2] = sel_criter1

            pair_seen_dic[pair_id] = 1

    """
    Output selected exon / transcript regions.

    """

    SELTREXBED = open(exon_regions_sel_tr_bed, "w")
    SELTREXIGVBED = open(exon_regions_sel_tr_igv_bed, "w")

    tr_seen_dic = {}
    for site_id in id2sel_trid_exid_crit_dic:
        sel_tr_id = id2sel_trid_exid_crit_dic[site_id][0]
        if sel_tr_id in tr_seen_dic:
            continue
        tr_seen_dic[sel_tr_id] = 1
        sel_ex_c = trid2exc_dic[sel_tr_id]
        for i in range(sel_ex_c):
            ex_nr = i + 1
            ex_id = sel_tr_id + "_e%i" %(ex_nr)
            SELTREXBED.write("%s\n" %(all_tr_ex_reg_dic[ex_id]))

        SELTREXIGVBED.write("%s\n" %(all_tr_ex_reg_igv_dic[sel_tr_id]))

    SELTREXBED.close()
    SELTREXIGVBED.close()


    """
    Output transcript context sites to BED.
    Merge exon border sites with new ID "id1,id2" and site score == average
    score of the two sites.

    """

    c_tr_con_out = 0
    c_merged_ids = 0
    pair_sitetrids_dic = {} # Remember pair site_id,tr_id for filtering.
    id2new_id_dic = {} # site ID to new pair ID mapping.
    id2tr_row_dic = {} # Store selected transcript BED rows.
    tc_tr_ids_dic = {} # Transcript IDs for transcript context.
    sel_sitetrids_dic = {} # Selected transcript context site_id,transcript_id combinations.
    c_sel_tc_tr_ids = 0

    for sitetrid in sitetrid2coords_dic:
        if sitetrid in pair_sitetrids_dic:
            continue
        m = re.search("(.+),(.+)", sitetrid)
        assert m, "invalid sitetrid %s" %(sitetrid)
        site_id = m.group(1)
        tr_id = m.group(2)
        tr_hit_s = sitetrid2coords_dic[sitetrid][0]
        tr_hit_e = sitetrid2coords_dic[sitetrid][1]
        sel_tr_id = id2sel_trid_exid_crit_dic[site_id][0]
        new_id = site_id
        new_s = tr_hit_s
        new_e = tr_hit_e
        new_sc = id2sc_dic[site_id]

        """
        If site is part of exon border pair:
            Merge the two regions, take average score. Remember pair to not
            output the pair on same transcript ID.

        """
        if site_id in id2exb_pair_dic:
            if tr_id == sel_tr_id:
                c_merged_ids += 1
            pair_id = id2exb_pair_dic[site_id]
            pair_sc = id2sc_dic[pair_id]
            sitetrid2 = "%s,%s" %(pair_id, tr_id)
            assert sitetrid2 in sitetrid2coords_dic, "pair_id,tr_id combination %s not in sitetrid2coords_dic (paired with: %s)" %(sitetrid2, site_id)
            # Extend to pair region.
            pair_s = sitetrid2coords_dic[sitetrid2][0]
            pair_e = sitetrid2coords_dic[sitetrid2][1]
            if pair_s < tr_hit_s:
                new_s = pair_s
            if pair_e > tr_hit_e:
                new_e = pair_e
            two_sc = [new_sc, pair_sc]
            new_sc = statistics.mean(two_sc)
            new_id = id2new_pair_id_dic[site_id]
            id2new_id_dic[site_id] = new_id
            id2new_id_dic[pair_id] = new_id
            pair_sitetrids_dic[sitetrid2] = 1

        c_tr_con_out += 1
        new_id = new_id + "," + tr_id
        bed_row = "%s\t%i\t%i\t%s\t%s\t+" %(tr_id, new_s, new_e, new_id, str(new_sc))
        id2tr_row_dic[new_id] = bed_row
        id2sc_dic[new_id] = new_sc
        tc_tr_ids_dic[tr_id] = 1
        if tr_id == sel_tr_id:
            sel_sitetrids_dic[new_id] = 1
            c_sel_tc_tr_ids += 1

    c_exb_sites = len(id2exb_pair_dic)

    if c_exb_sites:
        print("# exon border sites:                  %i" %(c_exb_sites))
        print("# merged exon border sites:           %i" %(c_merged_ids))
    print("# transcript context sites:           %i" %(c_tr_con_out))
    print("# selected transcript context sites:  %i" %(c_sel_tc_tr_ids))


    """
    Get transcript sequences.

    """
    ref_len_dic = {}
    for chr_id in chr_len_dic:
        ref_len_dic[chr_id] = chr_len_dic[chr_id]
    tr_len_dic = {}
    tr_seqs_dic = {}
    if tc_tr_ids_dic:
        # Extract transcript sequences.
        print("Get transcript sequences from --gtf and --gen ... ")
        tr_seqs_dic = hoodlib.get_transcript_sequences_from_gtf(args.in_gtf,
                                                        args.in_2bit,
                                                        lc_repeats=True,
                                                        correct_min_ex_order=correct_min_ex_order,
                                                        tr2exc_dic=tr2exc_dic,
                                                        tr_ids_dic=tc_tr_ids_dic)
        assert tr_seqs_dic, "tr_seqs_dic empty"
        for tr_id in tr_seqs_dic:
            tr_len_dic[tr_id] = len(tr_seqs_dic[tr_id])
            ref_len_dic[tr_id] = len(tr_seqs_dic[tr_id])

    if tr_seqs_dic:
        print("Output transcript sequences ... ")
        hoodlib.fasta_output_dic(tr_seqs_dic, tr_seqs_fa,
                                 to_upper=to_upper,
                                 split_size=60,
                                 split=True)
    else:
        hoodlib.create_empty_file(tr_seqs_fa, check=False)


    """
    Merge transcript context sites on transcripts.

    """
    tr_sites_merged_dic = {}

    if do_merge and tr_len_dic:
        print("Extend and merge transcript context sites ... ")
        tr_sites_merged_dic = hoodlib.ext_merge_bed_regions(id2tr_row_dic, tr_len_dic,
                                                alpha_merge=alpha_merge,
                                                merge_ext=args.merge_ext,
                                                rev_filter=args.rev_filter)
        assert tr_sites_merged_dic, "no genomic sites left after merging"
    else:
        for sitetrid in id2tr_row_dic:
            tr_sites_merged_dic[sitetrid] =  1

    """
    Update site ID, transcript ID to combination scores dictionary,
    by merging pair IDs and calculating new scores.

    idfilt2best_trids_dic["%s,EXB" %(site_id)] = exb_best_tr_ids_list
    exb_best_tr_ids_list: tr_ids supporting exon border pair

    """
    upd_sitetrid2comb_sc_dic = {}
    for sitetrid in sitetrid2comb_sc_dic:
        sitetrid_sc = sitetrid2comb_sc_dic[sitetrid]
        sitetrid_list = sitetrid.split(",")
        site_id = sitetrid_list[0]
        tr_id = sitetrid_list[1]
        new_sitetrid = sitetrid
        new_sc = sitetrid_sc
        if site_id in id2new_pair_id_dic:
            pair_id = id2exb_pair_dic[site_id]
            pairtrid = "%s,%s" %(pair_id, tr_id)
            if pairtrid in sitetrid2comb_sc_dic:
                pairtrid_sc = sitetrid2comb_sc_dic[pairtrid]
                new_site_id = id2new_pair_id_dic[site_id]
                new_sc = max(sitetrid_sc, pairtrid_sc)
                new_sitetrid = "%s,%s" %(id2new_pair_id_dic[site_id], tr_id)
        upd_sitetrid2comb_sc_dic[new_sitetrid] = new_sc


    """
    Extend and extract transcript BED+FASTA for transcript context sites.

    tr_sites_merged_dic:
        All transcript context sites (not just selected), with ID format:
        "site_id,transcript_id"
        Or for pair sites:
        "site_id1-EB-site_id2,transcript_id"

    """

    tr_rr_ratios_dic = {}
    all_tr_site_seqs_dic = {}
    sel_tr_site_seqs_dic = {}

    if tc_tr_ids_dic:

        # Extract transcript context site sequences.
        all_tr_site_seqs_dic = hoodlib.extract_transcript_sequences(
                                                    id2tr_row_dic,
                                                    tr_seqs_dic,
                                                    out_bed=exonic_sites_tr_con_all_tr_bed,
                                                    out_bed_add_sc_dic=upd_sitetrid2comb_sc_dic,
                                                    ids_dic=tr_sites_merged_dic,
                                                    ext_mode=args.seq_ext_mode,
                                                    ext_lr=args.seq_ext)

        # Calculate repeat region ratios for each site.
        tr_rr_ratios_dic = hoodlib.get_seqs_dic_repeat_region_ratios(all_tr_site_seqs_dic)
        # Output transcript context sites.
        hoodlib.fasta_output_dic(all_tr_site_seqs_dic, exonic_sites_tr_con_all_tr_fa,
                                 header_add_sc_dic=upd_sitetrid2comb_sc_dic,
                                 to_upper=to_upper,
                                 split_size=60,
                                 split=True)

        # Output selected transcript context sites.
        sitetrid2ext_tr_row_dic = hoodlib.bed_read_rows_into_dic(
                                                    exonic_sites_tr_con_all_tr_bed,
                                                    remove_id_count=True,
                                                    check_chr_id_format=False)

        hoodlib.bed_write_row_dic_into_file(sitetrid2ext_tr_row_dic,
                                            exonic_sites_tr_con_sel_tr_bed,
                                            ext_mode=1,
                                            out_bed_add_sc_dic=upd_sitetrid2comb_sc_dic,
                                            id2out_dic=sel_sitetrids_dic,
                                            zero_scores=False)

        for sitetrid in sel_sitetrids_dic:
            if sitetrid in all_tr_site_seqs_dic:
                sel_tr_site_seqs_dic[sitetrid] = all_tr_site_seqs_dic[sitetrid]

        hoodlib.fasta_output_dic(sel_tr_site_seqs_dic, exonic_sites_tr_con_sel_tr_fa,
                                 header_add_sc_dic=upd_sitetrid2comb_sc_dic,
                                 to_upper=to_upper,
                                 split_size=60,
                                 split=True)

    else:
        hoodlib.create_empty_file(exonic_sites_tr_con_all_tr_bed, check=False)
        hoodlib.create_empty_file(exonic_sites_tr_con_all_tr_fa, check=False)
        hoodlib.create_empty_file(exonic_sites_tr_con_sel_tr_bed, check=False)
        hoodlib.create_empty_file(exonic_sites_tr_con_sel_tr_fa, check=False)



    # all_gc_sites_dic = {}
    # for site_id in id2row_dic:
    #     if site_id not in id2tr_context_dic:
    #         all_gc_sites_dic[site_id] = id2row_dic[site_id]
    #
    # # Merge all genomic sites.
    # all_gc_sites_merged_dic = {}
    # if do_merge:
    #     print("Extend and merge all genomic context sites ... ")
    #     all_gc_sites_merged_dic = hoodlib.ext_merge_bed_regions(
    #                                             id2row_dic, chr_len_dic,
    #                                             alpha_merge=alpha_merge,
    #                                             merge_ext=args.merge_ext,
    #                                             rev_filter=args.rev_filter)
    #     assert all_gc_sites_merged_dic, "no genomic context sites left after merging"
    # else:
    #     for site_id in all_gc_sites_dic:
    #         all_gc_sites_merged_dic[site_id] = 1
    #
    # # Get extended genomic sequences.
    # print("Get all genomic context site sequences ... ")
    # rr_ratios_dic = {}
    # all_gc_site_seqs_dic = hoodlib.get_extended_gen_seqs(
    #                                     args, all_gc_sites_dic,
    #                                     ref_len_dic=chr_len_dic,
    #                                     id2out_dic=all_gc_sites_merged_dic,
    #                                     rr_ratios_dic=rr_ratios_dic)


    """
    Get intronic and intergenic sites.

    id2tr_list_dic:
        site IDs overlapping with GTF transcript regions.
    id2next_list_dic:
        site IDs overlapping with NEXT exon regions.

    """

    intron_site_ids_dic = {}
    for site_id in gen_sites_merged_dic:
        if site_id in id2tr_list_dic and site_id not in id2next_list_dic:
            intron_site_ids_dic[site_id] = site_seqs_dic[site_id]

    intergen_site_ids_dic = {}
    for site_id in site_no_tol_dic:
        if site_id in gen_sites_merged_dic:
            intergen_site_ids_dic[site_id] = site_seqs_dic[site_id]

    if intron_site_ids_dic:
        print("# of intronic sites:                  %i" %(len(intron_site_ids_dic)))
    if intergen_site_ids_dic:
        print("# of intergenic sites:                %i" %(len(intergen_site_ids_dic)))


    """
    Output different genomic BED+FASTA sites.

    gen_sites_merged_dic:
        All sites from id2row_dic, optionally merged.
    site_seqs_dic:
        Same as gen_sites_merged_dic.
    id2next_list_dic:
        All exonic site IDs.
    id2tr_context_dic:
        Exonic sites assigned transcript context. These include removed sites
        from id2exids_dic due to exon border group best sites selection.
        Removed IDs are stored in remove_ids_dic.
    id2gen_context_dic:
        Exonic sites assigned to genomic context.

    """

    # all_ex_site_ids_dic = {} # All exonic site IDs -> genomic sequence
    tc_ex_site_ids_dic = {} # TC exonic site IDs -> genomic sequence
    gc_ex_site_ids_dic = {} # GC exonic site IDs -> genomic sequence

    for site_id in site_seqs_dic:
        # if site_id in id2next_list_dic:
        #     all_ex_site_ids_dic[site_id] = site_seqs_dic[site_id]
        if site_id in id2tr_context_dic:
            tc_ex_site_ids_dic[site_id] = site_seqs_dic[site_id]
        if site_id in id2gen_context_dic:
            gc_ex_site_ids_dic[site_id] = site_seqs_dic[site_id]

    # Output intronic sites.
    if intron_site_ids_dic:
        hoodlib.fasta_output_dic(site_seqs_dic, sites_tol_intron_fa,
                                 out_ids_dic=intron_site_ids_dic,
                                 to_upper=to_upper,
                                 split_size=60,
                                 split=True)
        hoodlib.bed_write_row_dic_into_file(id2row_dic, sites_tol_intron_bed,
                                    ext_mode=args.seq_ext_mode,
                                    ext_lr=args.seq_ext,
                                    zero_scores=False,
                                    chr_len_dic=chr_len_dic,
                                    id2out_dic=intron_site_ids_dic)
    else:
        hoodlib.create_empty_file(sites_tol_intron_bed, check=False)
        hoodlib.create_empty_file(sites_tol_intron_fa, check=False)

    # Output transcript context exonic sites (genomic sites).
    if tc_ex_site_ids_dic:
        hoodlib.fasta_output_dic(site_seqs_dic, exonic_sites_tr_con_gen_fa,
                                 out_ids_dic=tc_ex_site_ids_dic,
                                 to_upper=to_upper,
                                 split_size=60,
                                 split=True)
        hoodlib.bed_write_row_dic_into_file(id2row_dic, exonic_sites_tr_con_gen_bed,
                                    ext_mode=args.seq_ext_mode,
                                    ext_lr=args.seq_ext,
                                    zero_scores=False,
                                    chr_len_dic=chr_len_dic,
                                    id2out_dic=tc_ex_site_ids_dic)
    else:
        hoodlib.create_empty_file(exonic_sites_tr_con_gen_bed, check=False)
        hoodlib.create_empty_file(exonic_sites_tr_con_gen_fa, check=False)

    # Output genomic context exonic sites (genomic sites).
    if gc_ex_site_ids_dic:
        hoodlib.fasta_output_dic(site_seqs_dic, exonic_sites_gen_con_fa,
                                 out_ids_dic=gc_ex_site_ids_dic,
                                 to_upper=to_upper,
                                 split_size=60,
                                 split=True)
        hoodlib.bed_write_row_dic_into_file(id2row_dic, exonic_sites_gen_con_bed,
                                    ext_mode=args.seq_ext_mode,
                                    ext_lr=args.seq_ext,
                                    zero_scores=False,
                                    chr_len_dic=chr_len_dic,
                                    id2out_dic=gc_ex_site_ids_dic)
    else:
        hoodlib.create_empty_file(exonic_sites_gen_con_bed, check=False)
        hoodlib.create_empty_file(exonic_sites_gen_con_fa, check=False)


    """
    Output all sites table with IGV coordinates.
    Also include assigned region type (exon_gc, exon_tc, intron, intergenic),
    new merged ID, and exon genomic context filter.

    exon genomic context filter:
        What filter caused exonic site to be assigned to genomic context
        EIR: exon-intron coverage ratio
        EIBR: exon-intron border coverage ratio
        TIS: transcripts with intronic sites
        TRS: other filters like overlap with ISR introns or genes containing
        ISR reads

    """
    ALLSITEOUT = open(all_sites_igv_out, "w")
    ALLSITEOUT.write("site_id\tassigned_region_type\tnew_merged_id\texon_gc_filter\tigv_region\tstrand\n")

    for site_id in tc_ex_site_ids_dic:
        cols = id2row_dic[site_id].split("\t")
        igv_chr = cols[0]
        site_pol = cols[5]
        igv_s = hoodlib.koma_sepp(int(cols[1]))
        igv_e = hoodlib.koma_sepp(int(cols[2]))
        merged_eb_id = "-"
        if site_id in id2new_pair_id_dic:
            merged_eb_id = id2new_pair_id_dic[site_id]
        igv_reg = "%s:%s-%s" %(igv_chr, igv_s, igv_e)
        ALLSITEOUT.write("%s\texon_tc\t%s\t-\t%s\t%s\n" %(site_id, merged_eb_id, igv_reg, site_pol))

    for site_id in gc_ex_site_ids_dic:
        cols = id2row_dic[site_id].split("\t")
        igv_chr = cols[0]
        site_pol = cols[5]
        igv_s = hoodlib.koma_sepp(int(cols[1]))
        igv_e = hoodlib.koma_sepp(int(cols[2]))
        igv_reg = "%s:%s-%s" %(igv_chr, igv_s, igv_e)
        gc_filter = "-"
        if site_id in eir_filtered_gen_ids_dic:
            gc_filter = "EIR"
        elif site_id in eir_wt_filtered_gen_ids_dic:
            gc_filter = "EIR_WT"
        elif site_id in eibr_filtered_gen_ids_dic:
            gc_filter = "EIBR"
        elif site_id in eibr_wt_filtered_gen_ids_dic:
            gc_filter = "EIBR_WT"
        elif site_id in tis_filtered_gen_ids_dic:
            gc_filter = "TIS"
        elif site_id in tr_filtered_gen_ids_dic:
            gc_filter = "TRS"
        else:
            assert False, "no GC filter set for site ID %s" %(site_id)
        ALLSITEOUT.write("%s\texon_gc\t-\t%s\t%s\t%s\n" %(site_id, gc_filter, igv_reg, site_pol))

    for site_id in intron_site_ids_dic:
        cols = id2row_dic[site_id].split("\t")
        igv_chr = cols[0]
        site_pol = cols[5]
        igv_s = hoodlib.koma_sepp(int(cols[1]))
        igv_e = hoodlib.koma_sepp(int(cols[2]))
        igv_reg = "%s:%s-%s" %(igv_chr, igv_s, igv_e)
        ALLSITEOUT.write("%s\tintron\t-\t-\t%s\t%s\n" %(site_id, igv_reg, site_pol))

    for site_id in intergen_site_ids_dic:
        cols = id2row_dic[site_id].split("\t")
        igv_chr = cols[0]
        site_pol = cols[5]
        igv_s = hoodlib.koma_sepp(int(cols[1]))
        igv_e = hoodlib.koma_sepp(int(cols[2]))
        igv_reg = "%s:%s-%s" %(igv_chr, igv_s, igv_e)
        ALLSITEOUT.write("%s\tintergen\t-\t-\t%s\t%s\n" %(site_id, igv_reg, site_pol))

    ALLSITEOUT.close()


    """
    Output reference lengths.

    """
    hoodlib.output_ref_lengths(ref_len_dic, ref_len_out)


    """
    Output transcript / gene annotations.

    """

    ANNOTOUT = open(tr_gene_annot_out, "w")
    ANNOTOUT.write("transcript_id\ttr_biotype\ttr_length\ttr_exon_c\ttr_gene_id\ttr_gene_name\ttr_gene_biotype\n")
    for tr_id in tr2reg_dic:
        # If transcript ID not filtered out (e.g. by biotype filter ... ).
        if tr_id in trid2gid_dic:
            tr_gid = trid2gid_dic[tr_id]
            tr_gna = trid2gna_dic[tr_id]
            tr_gbt = trid2gbt_dic[tr_id]
            tr_tbt = trid2tbt_dic[tr_id]
            tr_len = trid2len_dic[tr_id]
            tr_exc = trid2exc_dic[tr_id]
            ANNOTOUT.write("%s\t%s\t%i\t%i\t%s\t%s\t%s\n" %(tr_id, tr_tbt, tr_len, tr_exc, tr_gid, tr_gna, tr_gbt))
    ANNOTOUT.close()


    """
    Output sites overlapping with transcript regions with corresponding gene infos.

    """

    ANNOTOUT = open(sites_ol_gene_infos_out, "w")
    ANNOTOUT.write("site_id\tol_gene_ids\tol_gene_names\n")
    for site_id in id2tr_list_dic:
        gene_ids = []
        gene_names = []
        for tr_id in id2tr_list_dic[site_id]:
            if tr_id in trid2gid_dic:
                gene_ids.append(trid2gid_dic[tr_id])
                gene_names.append(trid2gna_dic[tr_id])
        gene_ids = list(set(gene_ids))
        gids_str = ",".join(gene_ids)
        gene_names = list(set(gene_names))
        gna_str = ",".join(gene_names)

        ANNOTOUT.write("%s\t%s\t%s\n" %(site_id, gids_str, gna_str))
    ANNOTOUT.close()


    """
    Exon ID EIR ratio stats.

    """

    print("Calculate and output NEXT EIR EIBR stats ... ")

    # next2eir_dic = {}
    next_eir_list = []
    next_eibr_list = []

    for next_id in ol_nexts_dic:

        eir_sum = 0.0
        eir_c = 0
        eibr_sum = 0.0
        eibr_c = 0
        for ex_id in next2exids_dic[next_id]:

            # Skip NEXTs removed by rem_tr_ids_dic filtering.
            if ex_id not in exid2eir_dic:
                continue

            eir = exid2eir_dic[ex_id]
            eir_sum += eir
            eir_c += 1
            for eib_ratio in exid2eibrs_dic[ex_id]:
                if eib_ratio != -1:
                    eibr_sum += eib_ratio
                    eibr_c += 1
        if eir_c:
            next_eir = eir_sum / eir_c
            next_eir_list.append(next_eir)

            if eibr_c:
                next_eibr = eibr_sum / eibr_c
                next_eibr_list.append(next_eibr)

    assert next_eir_list, "no exon-intron ratios calculated for NEXT IDs"
    assert next_eibr_list, "no exon-intron border ratios calculated for NEXT IDs"

    c_uniq_exons = len(next_eir_list)
    c_eibr_regions = len(next_eibr_list)
    eir_mean = next_eir_list[0]
    eir_median = next_eir_list[0]
    eir_stdev = 0.0
    eibr_mean = next_eibr_list[0]
    eibr_median = next_eibr_list[0]
    eibr_stdev = 0.0

    if len(next_eir_list) > 1:
        eir_mean = statistics.mean(next_eir_list)
        eir_median = statistics.median(next_eir_list)
        eir_stdev = statistics.stdev(next_eir_list)

    if len(next_eibr_list) > 1:
        eibr_mean = statistics.mean(next_eibr_list)
        eibr_median = statistics.median(next_eibr_list)
        eibr_stdev = statistics.stdev(next_eibr_list)

    # c_exons = len(ei_ratios_list)
    # eir_mean = ei_ratios_list[0]
    # eir_median = ei_ratios_list[0]
    # eir_stdev = 0.0
    # if len(ei_ratios_list) > 1:
    #     eir_mean = statistics.mean(ei_ratios_list)
    #     eir_median = statistics.median(ei_ratios_list)
    #     eir_stdev = statistics.stdev(ei_ratios_list)

    eir_perc_list = np.percentile(next_eir_list, [5,25,50,75,95])
    eir_perc5 = eir_perc_list[0]
    eir_perc25 = eir_perc_list[1]
    eir_perc50 = eir_perc_list[2]
    eir_perc75 = eir_perc_list[3]
    eir_perc95 = eir_perc_list[4]
    eir_min = min(next_eir_list)
    eir_max = max(next_eir_list)

    eibr_perc_list = np.percentile(next_eibr_list, [5,25,50,75,95])
    eibr_perc5 = eibr_perc_list[0]
    eibr_perc25 = eibr_perc_list[1]
    eibr_perc50 = eibr_perc_list[2]
    eibr_perc75 = eibr_perc_list[3]
    eibr_perc95 = eibr_perc_list[4]
    eibr_min = min(next_eibr_list)
    eibr_max = max(next_eibr_list)

    eir_stats_dic = {}
    eir_stats_dic["c_uniq_exons"] = c_uniq_exons
    eir_stats_dic["eir_mean"] = eir_mean
    eir_stats_dic["eir_median"] = eir_median
    eir_stats_dic["eir_stdev"] = eir_stdev
    eir_stats_dic["eir_perc5"] = eir_perc5
    eir_stats_dic["eir_perc25"] = eir_perc25
    eir_stats_dic["eir_perc50"] = eir_perc50
    eir_stats_dic["eir_perc75"] = eir_perc75
    eir_stats_dic["eir_perc95"] = eir_perc95
    eir_stats_dic["eir_min"] = eir_min
    eir_stats_dic["eir_max"] = eir_max

    eir_stats_dic["c_eibr_regions"] = c_eibr_regions
    eir_stats_dic["eibr_mean"] = eibr_mean
    eir_stats_dic["eibr_median"] = eibr_median
    eir_stats_dic["eibr_stdev"] = eibr_stdev
    eir_stats_dic["eibr_perc5"] = eibr_perc5
    eir_stats_dic["eibr_perc25"] = eibr_perc25
    eir_stats_dic["eibr_perc50"] = eibr_perc50
    eir_stats_dic["eibr_perc75"] = eibr_perc75
    eir_stats_dic["eibr_perc95"] = eibr_perc95
    eir_stats_dic["eibr_min"] = eibr_min
    eir_stats_dic["eibr_max"] = eibr_max

    eir_stats_dic["c_intergen_sites"] = len(intergen_site_ids_dic)
    eir_stats_dic["c_intron_sites"] = len(intron_site_ids_dic)
    eir_stats_dic["c_exon_sites_tc"] = len(tc_ex_site_ids_dic)
    eir_stats_dic["c_exon_sites_merged_tc"] = len(sel_tr_site_seqs_dic)
    eir_stats_dic["c_exon_sites_gc"] = len(gc_ex_site_ids_dic)
    eir_stats_dic["c_exb_sites"] = c_exb_sites

    # Spliced exonic sites before exon border merging.
    eir_stats_dic["c_tr_con_sites"] = c_tr_con_sites
    # All exonic sites.
    eir_stats_dic["c_exonic_sites"] = c_exonic_sites
    # All (filtered and if pre-merged if --pre-merge set) --in sites.
    c_in_sites = filt_stats_dic['c_out']
    eir_stats_dic["c_in_sites"] = c_in_sites

    # Percentage of exonic sites.
    perc_exonic_sites = "0.0 %"
    if c_exonic_sites and c_in_sites:
        perc_exonic_sites = "%.2f " %((c_exonic_sites / c_in_sites) * 100) + "%"
    # Percentage of spliced context sites.
    perc_exonic_tc_sites = "0.0 %"
    if c_tr_con_sites and c_exonic_sites:
        perc_exonic_tc_sites = "%.2f " %((c_tr_con_sites / c_exonic_sites) * 100) + "%"
    perc_exb_sites = "0.0 %"
    if c_exb_sites and c_tr_con_sites:
        perc_exb_sites = "%.2f " %((c_exb_sites / c_tr_con_sites) * 100) + "%"


    # Plot data ID.
    if args.data_id:
        plot_data_id = args.data_id
    else:
        bed_file = args.in_bed
        elem = bed_file.split('/')
        file_name = elem[-1]
        if re.search(".+?\.", file_name):
            m = re.search("^(.+?)\.", file_name)
            plot_data_id = m.group(1)
        else:
            plot_data_id = file_name
    eir_stats_dic["plot_data_id"] = plot_data_id

    print("")
    print("Percentage (# exonic sites / # all input sites):\n%s" %(perc_exonic_sites))
    print("Percentage (# transcript context sites / # exonic sites):\n%s" %(perc_exonic_tc_sites))
    print("Percentage (# exon border sites / # transcript context sites):\n%s" %(perc_exb_sites))
    print("")

    STATSOUT = open(extract_stats_out, "w")
    for eir_stat in eir_stats_dic:
        STATSOUT.write("%s\t%s\n" %(eir_stat, str(eir_stats_dic[eir_stat])))
    STATSOUT.close()

    """
    Output all NEXT (unique exon) exon-intron ratios.

    """

    STATSOUT = open(eir_all_out, "w")
    for eir in next_eir_list:
        STATSOUT.write("%s\n" %(str(eir)))
    STATSOUT.close()

    """
    Output all NEXT (unique exon) exon-intron border ratios
    above threshold (ignore -1 assigned).

    """

    STATSOUT = open(eibr_all_out, "w")
    for eibr in next_eibr_list:
        STATSOUT.write("%s\n" %(str(eibr)))
    STATSOUT.close()


    """
    Create empty files for intronic + intergenic files
    if these not exist.

    """

    if not os.path.exists(sites_no_tol_bed):
        hoodlib.create_empty_file(sites_no_tol_bed, check=False)
    if not os.path.exists(sites_no_tol_fa):
        hoodlib.create_empty_file(sites_no_tol_fa, check=False)
    if not os.path.exists(sites_tol_intron_bed):
        hoodlib.create_empty_file(sites_tol_intron_bed, check=False)
    if not os.path.exists(sites_tol_intron_fa):
        hoodlib.create_empty_file(sites_tol_intron_fa, check=False)


    """
    HTML report.

    """

    if args.report:

        # HTML report output file.
        html_report_out = args.out_folder + "/" + "report.peakhood_extract.html"
        # Plots subfolder.
        plots_subfolder = "html_plots"
        # Get library and logo path.
        hoodlib_path = os.path.dirname(hoodlib.__file__)
        print("Generate HTML report ... ")
        hoodlib.ph_extract_generate_html_report(args.out_folder, hoodlib_path,
                                            html_report_out=html_report_out,
                                            plots_subfolder=plots_subfolder,
                                            intergen_site_ids_dic=intergen_site_ids_dic,
                                            intron_site_ids_dic=intron_site_ids_dic,
                                            tc_ex_site_ids_dic=tc_ex_site_ids_dic,
                                            gc_ex_site_ids_dic=gc_ex_site_ids_dic,
                                            all_tr_site_seqs_dic=all_tr_site_seqs_dic,
                                            sel_tr_site_seqs_dic=sel_tr_site_seqs_dic,
                                            gen_rr_ratios_dic=gen_rr_ratios_dic,
                                            tr_rr_ratios_dic=tr_rr_ratios_dic,
                                            ei_ratios_list=next_eir_list,
                                            site_lengths_list=site_lengths_list,
                                            eib_ratios_list=next_eibr_list,
                                            eir_stats_dic=eir_stats_dic)

    """
    Remove tmp files.

    """

    if os.path.exists(in_sites_tmp_bed):
        os.remove(in_sites_tmp_bed)
    if os.path.exists(tr_regions_gtf_tmp_bed):
        os.remove(tr_regions_gtf_tmp_bed)
    if os.path.exists(tr_sites_intersect_tmp_bed):
        os.remove(tr_sites_intersect_tmp_bed)
    if os.path.exists(next_ol_in_sites_tmp_bed):
        os.remove(next_ol_in_sites_tmp_bed)
    if os.path.exists(intronic_sites_tmp_bed):
        os.remove(intronic_sites_tmp_bed)
    if os.path.exists(tc_sites_gen_tmp_bed):
        os.remove(tc_sites_gen_tmp_bed)
    if os.path.exists(isr_tmp_bed):
        os.remove(isr_tmp_bed)
    if os.path.exists(isr_rnaseq_tmp_bed):
        os.remove(isr_rnaseq_tmp_bed)
    if not args.keep_bam:
        if os.path.exists(tr_regions_bam):
            os.remove(tr_regions_bam)
        if os.path.exists(tr_regions_rnaseq_bam):
            os.remove(tr_regions_rnaseq_bam)
    if os.path.exists(exon_intron_bed):
        os.remove(exon_intron_bed)


    """
    Output report.

    """

    print("")
    print("OUTPUT FILES")
    print("============")
    print("")
    if args.report:
        assert os.path.exists(html_report_out), "HTML report %s not found" %(html_report_out)
        print("Context extraction statistics report HTML:\n%s" %(html_report_out))
    print("All sites + assigned region type information TSV:\n%s" %(all_sites_igv_out))
    # print("All transcript regions 12-column (IGV display) BED:\n%s" %(tr_sol_igv_bed))

    if tc_tr_ids_dic:
        print("")
        print("EXONIC SITES ASSIGNED TO TRANSCRIPT CONTEXT:")
        print("")
        print("All transcript context site-transcript combinations BED:\n%s" %(exonic_sites_tr_con_all_tr_bed))
        print("All transcript context site-transcript combinations FASTA:\n%s" %(exonic_sites_tr_con_all_tr_fa))
        print("Selected transcript context site-transcript combinations BED:\n%s" %(exonic_sites_tr_con_sel_tr_bed))
        print("Selected transcript context site-transcript combinations FASTA:\n%s" %(exonic_sites_tr_con_sel_tr_fa))
        print("Assigned transcript context site statistics TSV:\n%s" %(exonic_site_stats_out))
        print("Associated full transcript sequences FASTA:\n%s" %(tr_seqs_fa))
    if tc_ex_site_ids_dic:
        print("Transcript context sites on genome BED:\n%s" %(exonic_sites_tr_con_gen_bed))
        print("Transcript context sites on genome FASTA:\n%s" %(exonic_sites_tr_con_gen_fa))
    if gc_ex_site_ids_dic:
        print("")
        print("EXONIC SITES ASSIGNED TO GENOMIC CONTEXT:")
        print("")
        print("Exonic sites assigned to genomic context BED:\n%s" %(exonic_sites_gen_con_bed))
        print("Exonic sites assigned to genomic context FASTA:\n%s" %(exonic_sites_gen_con_fa))
    if intron_site_ids_dic:
        print("")
        print("INTRONIC SITES:")
        print("")
        print("Intronic sites BED:\n%s" %(sites_tol_intron_bed))
        print("Intronic sites FASTA:\n%s" %(sites_tol_intron_fa))
    if intergen_site_ids_dic:
        print("")
        print("INTERGENIC SITES:")
        print("")
        print("Intergenic sites BED:\n%s" %(sites_no_tol_bed))
        print("Intergenic sites FASTA:\n%s" %(sites_no_tol_fa))
    print("")


################################################################################

def main_merge(args):
    """
    Merge extracted datasets.

    """

    print("Running for you in MERGE mode ... ")

    # Check input folders.
    c_in_folders = len(args.list_in_folders)
    assert c_in_folders > 1, "# of given --in folders needs to be > 1 for merging"
    for in_folder in args.list_in_folders:
        assert os.path.exists(in_folder), "--in folder \"%s\" not found" %(in_folder)

    # Results output folder.
    if not os.path.exists(args.out_folder):
        os.makedirs(args.out_folder)

    """
    Output files.

    """
    tr_all_sites_out = args.out_folder + "/" + "transcripts_with_sites.all_tr.tsv"
    tr_sel_sites_out = args.out_folder + "/" + "transcripts_with_sites.sel_tr.tsv"
    sites_on_same_all_tr_out = args.out_folder + "/" + "sites_on_same_transcripts.all_tr.tsv"
    sites_on_same_sel_tr_out = args.out_folder + "/" + "sites_on_same_transcripts.sel_tr.tsv"
    merge_stats_out = args.out_folder + "/" + "merge_stats.out"
    all_tr_seqs_fa_out = args.out_folder + "/" + "all_transcript_sequences.fa"
    all_tr_regs_bed_out = args.out_folder + "/" + "all_transcript_regions.bed"
    exonic_site_set_stats_out = args.out_folder + "/" + "exonic_site_set_stats.tsv"

    """
    If --gtf file given, extract gene BED and get gene ID to gene name and
    gene biotype mappings.

    """

    gid2gn_dic = {}  # gene ID -> gene name.
    gid2gbt_dic = {}  # gene ID -> gene biotype.

    if args.in_gtf:
        assert os.path.exists(args.in_gtf), "--gtf file %s not found" %(args.in_gtf)
        gene_regions_gtf_tmp_bed = args.out_folder + "/" + "gene_regions.gtf.tmp.bed"
        print("Extract gene regions + infos from --gtf ... ")
        hoodlib.gtf_extract_gene_bed(args.in_gtf, gene_regions_gtf_tmp_bed,
                                     gid2gn_dic=gid2gn_dic,
                                     gid2gbt_dic=gid2gbt_dic)


    """
    Go over input folders and extract site infos.

    """

    refid2len_dic = {}  # reference_id -> reference length
    id2selreg_dic = {}  # site_id -> [tr_id, s, e, score]
    id2allreg_dic = {}  # site_id -> ["tr_id,s,e", "tr_id,s,e", ... ]
    id2bed_sc_dic = {} # site_id -> BED col5 score
    sitetrid2sc_dic = {} # sitetrid -> combination score
    id2genreg_dic = {}  # site_id -> [chr_id, s, e, pol]
    id2dataset_dic = {}  # site_id -> dataset ID (number)
    trid2gbt_dic = {}  # transcript ID -> gene biotype.
    trid2gn_dic = {}  # transcript ID -> gene name.
    trid2gid_dic = {}  # transcript ID -> gene ID.
    trid2tbt_dic = {} # transcript ID -> transcript biotype.
    id2gids_dic = {}  # site_id -> overlapping gene region IDs.
    id2pairid_dic = {} # site_id -> exon border pair ID.
    id2regtype_dic = {} # site_id -> assigned region type.
    tr_seqs_dic = {} # Transcript sequences dictionary.
    ex_sites_perc_dic = {} # Dataset ID to exonic sites %.
    tc_sites_perc_dic = {} # Dataset ID to transcript context sites %.
    set2site_len_dic = {} # Dataset ID to input site lengths list.
    exb_sites_perc_dic = {} # Dataset ID to exon border sites %.
    tr_row_dic = {} # transcript ID to 12-column bed row.
    set_stats_dd = {} # Dataset stats dictionary of dictionaries.
    c_set = 0


    SETSTATSOUT = open(exonic_site_set_stats_out,"w")
    SETSTATSOUT.write("dataset_id\tc_all_sites\tc_intronic_sites\tc_intergenic_sites\tc_exonic_sites_gc\tc_exonic_sites_tc\tc_exonic_sites_tc_exb_sites_merged\tc_exb_isr_sites\tperc_exonic_sites_of_all\tperc_exonic_sites_tc_of_all_exonic\tperc_exb_isr_sites_of_tc_exonic\n")

    for in_folder in args.list_in_folders:

        print("Processing --in folder %s ... " %(in_folder))
        c_set += 1

        # Necessary --in folder input files.
        extract_stats_out = in_folder + "/extract_stats.out"
        transcript_regions_igv_bed = in_folder + "/" + "exon_regions.all_tr.igv.bed"
        ref_len_in = in_folder + "/ref_lengths.out"
        exonic_sites_tr_con_all_tr_bed = in_folder + "/exonic_sites.tr_con.all_tr.bed"
        exonic_sites_tr_con_sel_tr_bed = in_folder + "/exonic_sites.tr_con.sel_tr.bed"
        exonic_sites_tr_con_gen_bed = in_folder + "/exonic_sites.tr_con.gen.bed"
        tr_gene_annot_tsv = in_folder + "/tr_gene_annot.tsv"
        all_sites_igv_tsv = in_folder + "/all_sites.tsv"
        tr_seqs_fa = in_folder + "/" + "transcript_sequences.fa"
        input_site_len_in = in_folder + "/" + "input_site_lengths.out"

        assert os.path.exists(extract_stats_out), "--in %s file missing" %(extract_stats_out)
        assert os.path.exists(transcript_regions_igv_bed), "--in %s file missing" %(transcript_regions_igv_bed)
        assert os.path.exists(ref_len_in), "--in %s file missing" %(ref_len_in)
        assert os.path.exists(exonic_sites_tr_con_all_tr_bed), "--in %s file missing" %(exonic_sites_tr_con_all_tr_bed)
        assert os.path.exists(exonic_sites_tr_con_sel_tr_bed), "--in %s file missing" %(exonic_sites_tr_con_sel_tr_bed)
        assert os.path.exists(exonic_sites_tr_con_gen_bed), "--in %s file missing" %(exonic_sites_tr_con_gen_bed)
        assert os.path.exists(tr_gene_annot_tsv), "--in %s file missing" %(tr_gene_annot_tsv)
        assert os.path.exists(all_sites_igv_tsv), "--in %s file missing" %(all_sites_igv_tsv)
        assert os.path.exists(tr_seqs_fa), "--in %s file missing" %(tr_seqs_fa)
        assert os.path.exists(input_site_len_in), "--in %s file missing" %(input_site_len_in)

        # Get some extract stats.
        extr_stats_dic = hoodlib.read_settings_into_dic(extract_stats_out, check=False)
        assert extr_stats_dic, "no stats extracted from extract_stats.out file inside --in folder %s" %(in_folder)

        c_exonic_sites = int(extr_stats_dic["c_exonic_sites"])
        c_tr_con_sites = int(extr_stats_dic["c_tr_con_sites"])
        c_in_sites = int(extr_stats_dic["c_in_sites"])
        c_exb_sites = int(extr_stats_dic["c_exb_sites"])
        plot_data_id = extr_stats_dic["plot_data_id"]
        set_stats_dd[plot_data_id] = {}

        if args.report:
            assert plot_data_id not in ex_sites_perc_dic, "> 1 dataset with same dataset ID %s encountered. Please provide unique IDs data IDs (--data-id) during extraction, otherwise peakhood merge --report will not work"

        # Exonic site percentage.
        perc_exonic_sites = (c_exonic_sites / c_in_sites) * 100
        # Transcript context percentage.
        perc_exonic_tc_sites = (c_tr_con_sites / c_exonic_sites) * 100
        # Exon border sites percentage.
        perc_exb_sites = (c_exb_sites / c_tr_con_sites) * 100

        ex_sites_perc_dic[plot_data_id] = perc_exonic_sites
        tc_sites_perc_dic[plot_data_id] = perc_exonic_tc_sites
        exb_sites_perc_dic[plot_data_id] = perc_exb_sites

        # Get input site lengths (after pre-merging and pre-filtering).
        site_len_list = hoodlib.get_site_len_list(input_site_len_in)
        set2site_len_dic[plot_data_id] = site_len_list

        c_intergen_sites = int(extr_stats_dic["c_intergen_sites"])
        c_intron_sites = int(extr_stats_dic["c_intron_sites"])
        c_exon_sites_tc = int(extr_stats_dic["c_exon_sites_tc"])
        c_exon_sites_merged_tc = int(extr_stats_dic["c_exon_sites_merged_tc"])
        c_exon_sites_gc = int(extr_stats_dic["c_exon_sites_gc"])
        c_all_sites = c_intergen_sites + c_intron_sites + c_exon_sites_gc + c_exon_sites_tc

        set_stats_dd[plot_data_id]["c_all_sites"] = c_all_sites
        set_stats_dd[plot_data_id]["c_intron_sites"] = c_intron_sites
        set_stats_dd[plot_data_id]["c_intergen_sites"] = c_intergen_sites
        set_stats_dd[plot_data_id]["c_exon_sites_gc"] = c_exon_sites_gc
        set_stats_dd[plot_data_id]["c_exon_sites_tc"] = c_exon_sites_tc
        set_stats_dd[plot_data_id]["c_exon_sites_merged_tc"] = c_exon_sites_merged_tc
        set_stats_dd[plot_data_id]["c_exonic_sites"] = c_exonic_sites
        set_stats_dd[plot_data_id]["c_exb_sites"] = c_exb_sites

        SETSTATSOUT.write("%s\t%i\t%i\t%i\t%i\t%i\t%i\t%i\t%.2f\t%.2f\t%.2f\n" %(plot_data_id, c_all_sites, c_intron_sites, c_intergen_sites, c_exon_sites_gc, c_exon_sites_tc, c_exon_sites_merged_tc, c_exb_sites, perc_exonic_sites, perc_exonic_tc_sites, perc_exb_sites))

        # Read in transcript region rows (12-column BED).
        tr_row_dic = hoodlib.read_in_12col_bed(transcript_regions_igv_bed,
                                               bed_row_dic=tr_row_dic)

        hoodlib.read_in_sel_tr_regs(exonic_sites_tr_con_sel_tr_bed, id2selreg_dic,
                                    id2dataset_dic=id2dataset_dic,
                                    dataset_id=c_set)
        hoodlib.read_in_all_tr_regs(exonic_sites_tr_con_all_tr_bed, id2allreg_dic,
                                    sitetrid2sc_dic, id2bed_sc_dic)
        refid2len_dic= hoodlib.read_in_ref_lengths(ref_len_in,
                                                   ref_len_dic=refid2len_dic)
        id2genreg_dic = hoodlib.read_in_genomic_regs(exonic_sites_tr_con_gen_bed,
                                                     id2genreg_dic=id2genreg_dic)

        # Read in transcript ID -> gene info mappings.
        hoodlib.get_gene_infos_from_annot_table(tr_gene_annot_tsv, trid2gid_dic,
                                                trid2gn_dic, trid2gbt_dic, trid2tbt_dic)

        # Site ID -> Pair ID + region type mapping.
        hoodlib.get_site_to_pair_id_mapping(all_sites_igv_tsv, id2pairid_dic,
                                            id2regtype_dic=id2regtype_dic)

        # Read in transcript sequences.
        tr_seqs_dic= hoodlib.read_fasta_into_dic(tr_seqs_fa,
                                                 seqs_dic=tr_seqs_dic,
                                                 all_uc=True,
                                                 empty_check=False,
                                                 skip_n_seqs=False,
                                                 id_check=False)

        # If --gtf file given, overlap exonic_sites_tr_con_gen_bed with gene regions.
        if args.in_gtf:
            hoodlib.bed_intersect_sites_genes_get_infos(exonic_sites_tr_con_gen_bed,
                                                        gene_regions_gtf_tmp_bed,
                                                        id2gids_dic)

    SETSTATSOUT.close()

    assert refid2len_dic, "nothing read in from supplied --in folders. Be sure to use --in folders generated by peakhood extract (--out results folder)"
    if not id2selreg_dic:
        assert False, "no exonic sites mapped to transcript context found in supplied --in folders"
    assert tr_row_dic, "no transript regions (BED) read in"

    """
    Reverse mapping.

    pairid2ids_dic:
        exon border pair ID -> [sid1, sid2]
    """
    pairid2ids_dic = {}

    for site_id in id2pairid_dic:
        exb_id = id2pairid_dic[site_id]
        sids = exb_id.split("-EB-")
        pairid2ids_dic[exb_id] = [sids[0], sids[1]]

    """
    Collect sites on same transcripts.

    refid2len_dic = {}  # reference_id -> reference length
    id2selreg_dic = {}  # site_id -> [tr_id, s, e, score]
    id2allreg_dic = {}  # site_id -> ["tr_id,s,e", "tr_id,s,e", ... ]
    id2genreg_dic = {}  # site_id -> [chr_id, s, e, pol]
    sitetrid2sc_dic = {} # sitetrid -> combination score

    site_id example formats:
    PUM2_K562_IDR_0024 (normal ID)
    PUM2_K562_IDR_0031-EB-PUM2_K562_IDR_0090 (exon border IDs)
    Exon border IDs NOT in id2genreg_dic, only single IDs there !

    """

    trid2all_tr_sites_dic = {}
    sitetrid2coords_dic = {}
    sitetrid2cp_dic = {}

    print("Collect sites on same transcripts ... ")

    for site_id in id2allreg_dic:
        for tr_reg in id2allreg_dic[site_id]:
            cols = tr_reg.split(",")
            tr_id = cols[0]
            tr_s = int(cols[1])
            tr_e = int(cols[2])
            sitetr_cols = tr_reg.split(",")
            sitetrid = "%s,%s" %(site_id, tr_id)
            sitetrid2coords_dic[sitetrid] = [tr_s, tr_e]
            sitetrid2cp_dic[sitetrid] = hoodlib.get_center_position(tr_s, tr_e)
            if tr_id in trid2all_tr_sites_dic:
                trid2all_tr_sites_dic[tr_id].append(site_id)
            else:
                trid2all_tr_sites_dic[tr_id] = [site_id]

    trid2sel_tr_sites_dic = {}
    for site_id in id2selreg_dic:
        tr_id = id2selreg_dic[site_id][0]
        sitetrid = "%s,%s" %(site_id, tr_id)
        assert sitetrid in sitetrid2coords_dic, "site-transcript ID %s in sel_tr set but missing in all_tr set" %(sitetrid)
        if tr_id in trid2sel_tr_sites_dic:
            trid2sel_tr_sites_dic[tr_id].append(site_id)
        else:
            trid2sel_tr_sites_dic[tr_id] = [site_id]

    id2cp_dic = {}
    for site_id in id2genreg_dic:
        gen_s = int(id2genreg_dic[site_id][1])
        gen_e = int(id2genreg_dic[site_id][2])
        id2cp_dic[site_id] = hoodlib.get_center_position(gen_s, gen_e)


    """
    Transcript ID to associated gene IDs.

    id2gids_dic:
        Mapping from overlapping --gtf gene regions with site regions.
        {'PUM2_K562_IDR_5382': ['ENSG00000198799.12'], ... }

    """

    trid2gene_infos_dic = {}

    print("Associate transcript IDs to gene IDs ... ")

    for tr_id in trid2all_tr_sites_dic:
        # Gene information.
        assoc_gene_ids_str = trid2gid_dic[tr_id]
        gene_names_str = trid2gn_dic[tr_id]
        gene_biotypes_str = trid2gbt_dic[tr_id]
        tr_biotypes_str = trid2tbt_dic[tr_id]
        # If --gtf supplied.
        if id2gids_dic:
            assoc_gene_ids = []
            for site_id in trid2all_tr_sites_dic[tr_id]:
                if site_id in id2gids_dic:
                    for gene_id in id2gids_dic[site_id]:
                        assoc_gene_ids.append(gene_id)
            if assoc_gene_ids:
                gene_names = []
                gene_biotypes = []
                assoc_gene_ids = list(set(assoc_gene_ids))
                assoc_gene_ids.sort()
                for gid in assoc_gene_ids:
                    gene_names.append(gid2gn_dic[gid])
                    gene_biotypes.append(gid2gbt_dic[gid])

                assoc_gene_ids_str = ','.join(assoc_gene_ids)
                gene_names_str = ','.join(gene_names)
                gene_biotypes_str = ','.join(gene_biotypes)
            else:
                # Keep current ones if no overlap with --gtf.
                # assoc_gene_ids = trid2gid_dic[tr_id]
                # gene_names = trid2gn_dic[tr_id]
                # gene_biotypes = trid2gbt_dic[tr_id]
                # If no overlaps with --gtf.
                assoc_gene_ids_str = "-"
                gene_names_str = "-"
                gene_biotypes_str = "-"

        trid2gene_infos_dic[tr_id] = [assoc_gene_ids_str, gene_names_str, gene_biotypes_str, tr_biotypes_str]


    """
    Output file: tr_all_sites_out
    All transcripts and sites on these transcripts

    """
    OUTTSV = open(tr_all_sites_out, "w")
    OUTTSV.write("transript_id\ttr_len\tnr_sites\tsite_ids\ttr_biotype\tassoc_gene_ids\tgene_names\tgene_biotypes\n")
    c_all_tr = 0

    print("Output all transcripts with sites ... ")

    for tr_id in trid2all_tr_sites_dic:
        tr_len = refid2len_dic[tr_id]
        nr_sites = len(trid2all_tr_sites_dic[tr_id])
        site_ids_str = ','.join(trid2all_tr_sites_dic[tr_id])
        c_all_tr += 1

        # Gene information.
        assoc_gene_ids_str = trid2gene_infos_dic[tr_id][0]
        gene_names_str = trid2gene_infos_dic[tr_id][1]
        gene_biotypes_str = trid2gene_infos_dic[tr_id][2]
        tr_biotypes_str = trid2gene_infos_dic[tr_id][3]

        OUTTSV.write("%s\t%i\t%i\t%s\t%s\t%s\t%s\t%s\n" %(tr_id, tr_len, nr_sites, site_ids_str, tr_biotypes_str, assoc_gene_ids_str, gene_names_str, gene_biotypes_str))
    OUTTSV.close()


    """
    Output file: tr_sel_sites_out
    Selected transcripts and sites on these transcripts

    """
    OUTTSV = open(tr_sel_sites_out, "w")
    OUTTSV.write("transript_id\ttr_len\tnr_sites\tsite_ids\ttr_biotype\tassoc_gene_ids\tgene_names\tgene_biotypes\n")
    c_sel_tr = 0

    print("Output selected transcripts with sites ... ")

    for tr_id in trid2sel_tr_sites_dic:
        tr_len = refid2len_dic[tr_id]
        nr_sites = len(trid2sel_tr_sites_dic[tr_id])
        site_ids_str = ','.join(trid2sel_tr_sites_dic[tr_id])
        c_sel_tr += 1

        # Gene information.
        assoc_gene_ids_str = trid2gene_infos_dic[tr_id][0]
        gene_names_str = trid2gene_infos_dic[tr_id][1]
        gene_biotypes_str = trid2gene_infos_dic[tr_id][2]
        tr_biotypes_str = trid2gene_infos_dic[tr_id][3]

        OUTTSV.write("%s\t%i\t%i\t%s\t%s\t%s\t%s\t%s\n" %(tr_id, tr_len, nr_sites, site_ids_str, tr_biotypes_str, assoc_gene_ids_str, gene_names_str, gene_biotypes_str))
    OUTTSV.close()


    """
    Output file: sites_on_same_all_tr_out
    Co-occuring sites (pairs) on all transcripts

    trid2all_tr_sites_dic:
        tr_id -> [sid1, sid2, ... ] mapping
    sitetrid2coords_dic:
        sitetrid -> [tr_s, tr_e] mapping
    id2pairid_dic:
        site_id -> exon border pair ID mapping.
        E.g. "PUM2_K562_IDR_1022" -> "PUM2_K562_IDR_1022-EB-PUM2_K562_IDR_5260"

    """

    OUTTSV = open(sites_on_same_all_tr_out, "w")

    OUTTSV.write("transcript_id\ttr_biotype\tassoc_gene_ids\ttr_len\tsame_set\tsite1_id\tsite1_start\tsite1_end\tsite2_id\tsite2_start\tsite2_end\tsite_distance\tgenomic_distance\tdist_diff\ts1_bed_sc\ts2_bed_sc\ts1_tr_comb_score\ts2_tr_comb_score\n")
    c_pair_sites_all_tr = 0
    c_pair_sites_all_tr_diff_set = 0
    one_based_start = True

    print("Output site pairs on all transcripts  ... ")

    for tr_id in trid2all_tr_sites_dic:

        assoc_gene_ids_str = trid2gene_infos_dic[tr_id][0]
        tr_biotypes_str = trid2gene_infos_dic[tr_id][3]

        tr_len = refid2len_dic[tr_id]
        sitetrids_list = []

        for site_id in trid2all_tr_sites_dic[tr_id]:
            sitetrids_list.append("%s,%s" %(site_id, tr_id))

        # If only one site on transcript, i.e. no pair on transcript.
        if len(sitetrids_list) == 1:
            continue

        # Calculate distances.
        # sids2dist_dic = hoodlib.calc_site_distances(sitetrids_list, sitetrid2cp_dic)
        sids2dist_dic = hoodlib.calc_full_site_distances(sitetrids_list, sitetrid2coords_dic)

        for sids in sids2dist_dic:
            tr_dist = sids2dist_dic[sids]
            sitetrids = sids.split(";")

            sitetrid1 = sitetrids[0].split(",")
            sitetrid2 = sitetrids[1].split(",")
            sid1 = sitetrid1[0]
            sid2 = sitetrid2[0]

            sid1_bed_sc = id2bed_sc_dic[sid1]
            sid2_bed_sc = id2bed_sc_dic[sid2]

            """
            Genomic coordinates for site IDs.

            In case sid1 or sid2 is an exon border pair ID, e.g.
            PUM2_K562_IDR_1022-EB-PUM2_K562_IDR_5260,
            Take the minimum genomic start and maximum end, from the two
            single genomic sites PUM2_K562_IDR_1022 and PUM2_K562_IDR_5260.
            Use these coordinates to calculate the genomic distance to
            other sites on the transcript.

            Use mapping:
                pairid2ids_dic:
                    exon border pair ID -> [sid1, sid2]

            """

            if sid1 in pairid2ids_dic:
                sid1_s = min(id2genreg_dic[pairid2ids_dic[sid1][0]][1], id2genreg_dic[pairid2ids_dic[sid1][1]][1])
                sid1_e = min(id2genreg_dic[pairid2ids_dic[sid1][0]][2], id2genreg_dic[pairid2ids_dic[sid1][1]][2])
            else:
                sid1_s = id2genreg_dic[sid1][1]
                sid1_e = id2genreg_dic[sid1][2]

            if sid2 in pairid2ids_dic:
                sid2_s = min(id2genreg_dic[pairid2ids_dic[sid2][0]][1], id2genreg_dic[pairid2ids_dic[sid2][1]][1])
                sid2_e = min(id2genreg_dic[pairid2ids_dic[sid2][0]][2], id2genreg_dic[pairid2ids_dic[sid2][1]][2])
            else:
                sid2_s = id2genreg_dic[sid2][1]
                sid2_e = id2genreg_dic[sid2][2]

            # if sid1 in id2pairid_dic:
            #     sid1_s = min(sid1_s, id2genreg_dic[id2pairid_dic[sid1]][1])
            #     sid1_e = max(sid1_e, id2genreg_dic[id2pairid_dic[sid1]][2])
            # if sid2 in id2pairid_dic:
            #     sid2_s = min(sid2_s, id2genreg_dic[id2pairid_dic[sid2]][1])
            #     sid2_e = max(sid2_e, id2genreg_dic[id2pairid_dic[sid2]][2])

            # Genomic distance of the two sites.
            gen_dist = hoodlib.get_site_ends_distance(sid1_s, sid1_e, sid2_s, sid2_e)
            # gen_dist = abs(id2cp_dic[sid1] - id2cp_dic[sid2])

            dist_diff = gen_dist - tr_dist
            sitetrid1 = "%s,%s" %(sid1, tr_id)
            sitetrid2 = "%s,%s" %(sid2, tr_id)
            sid1_s = sitetrid2coords_dic[sitetrid1][0]
            sid1_e = sitetrid2coords_dic[sitetrid1][1]
            sid2_s = sitetrid2coords_dic[sitetrid2][0]
            sid2_e = sitetrid2coords_dic[sitetrid2][1]
            if one_based_start:
                sid1_s += 1
                sid2_s += 1

            # Combination scores.
            sitetrid1_sc = sitetrid2sc_dic[sitetrid1]
            sitetrid2_sc = sitetrid2sc_dic[sitetrid2]

            c_pair_sites_all_tr += 1

            same_set = "Y"
            if id2dataset_dic[sid1] != id2dataset_dic[sid2]:
                same_set = "N"
                c_pair_sites_all_tr_diff_set += 1

            OUTTSV.write("%s\t%s\t%s\t%i\t%s\t%s\t%i\t%i\t%s\t%i\t%i\t%i\t%i\t%i\t%s\t%s\t%i\t%i\n" %(tr_id, tr_biotypes_str, assoc_gene_ids_str, tr_len, same_set, sid1, sid1_s, sid1_e, sid2, sid2_s, sid2_e, tr_dist, gen_dist, dist_diff, sid1_bed_sc, sid2_bed_sc, sitetrid1_sc, sitetrid2_sc))
    OUTTSV.close()


    """
    Output file: sites_on_same_sel_tr_out
    Co-occuring sites (pairs) on selected transcripts

    """

    OUTTSV = open(sites_on_same_sel_tr_out, "w")
    OUTTSV.write("transcript_id\ttr_biotype\tassoc_gene_ids\ttr_len\tsame_set\tsite1_id\tsite1_start\tsite1_end\tsite2_id\tsite2_start\tsite2_end\tsite_distance\tgenomic_distance\tdist_diff\ts1_bed_sc\ts2_bed_sc\ts1_tr_comb_score\ts2_tr_comb_score\n")

    c_pair_sites_sel_tr = 0
    c_pair_sites_sel_tr_diff_set = 0

    print("Output site pairs on selected transcripts  ... ")

    for tr_id in trid2sel_tr_sites_dic:

        assoc_gene_ids_str = trid2gene_infos_dic[tr_id][0]
        tr_biotypes_str = trid2gene_infos_dic[tr_id][3]

        tr_len = refid2len_dic[tr_id]
        sitetrids_list = []

        for site_id in trid2sel_tr_sites_dic[tr_id]:
            sitetrids_list.append("%s,%s" %(site_id, tr_id))

        # If only one site on transcript, i.e. no pair on transcript.
        if len(sitetrids_list) == 1:
            continue

        # Calculate distances.
        # sids2dist_dic = hoodlib.calc_site_distances(sitetrids_list, sitetrid2cp_dic)
        sids2dist_dic = hoodlib.calc_full_site_distances(sitetrids_list, sitetrid2coords_dic)

        for sids in sids2dist_dic:
            tr_dist = sids2dist_dic[sids]
            sitetrids = sids.split(";")

            sitetrid1 = sitetrids[0].split(",")
            sitetrid2 = sitetrids[1].split(",")
            sid1 = sitetrid1[0]
            sid2 = sitetrid2[0]

            sid1_bed_sc = id2bed_sc_dic[sid1]
            sid2_bed_sc = id2bed_sc_dic[sid2]

            # Genomic coordinates for site IDs.
            if sid1 in pairid2ids_dic:
                sid1_s = min(id2genreg_dic[pairid2ids_dic[sid1][0]][1], id2genreg_dic[pairid2ids_dic[sid1][1]][1])
                sid1_e = max(id2genreg_dic[pairid2ids_dic[sid1][0]][2], id2genreg_dic[pairid2ids_dic[sid1][1]][2])
            else:
                sid1_s = id2genreg_dic[sid1][1]
                sid1_e = id2genreg_dic[sid1][2]

            if sid2 in pairid2ids_dic:
                sid2_s = min(id2genreg_dic[pairid2ids_dic[sid2][0]][1], id2genreg_dic[pairid2ids_dic[sid2][1]][1])
                sid2_e = max(id2genreg_dic[pairid2ids_dic[sid2][0]][2], id2genreg_dic[pairid2ids_dic[sid2][1]][2])
            else:
                sid2_s = id2genreg_dic[sid2][1]
                sid2_e = id2genreg_dic[sid2][2]

            # if sid1 == "PUM2_K562_IDR_1367-EB-PUM2_K562_IDR_3341":
            #     print(sid1, "genomic coords")
            #     print("sid1_s:", sid1_s)
            #     print("sid1_e", sid1_e)
            # if sid2 == "PUM2_K562_IDR_1367-EB-PUM2_K562_IDR_3341":
            #     print(sid2, "genomic coords")
            #     print("sid2_s:", sid2_s)
            #     print("sid2_e", sid2_e)

            # sid1_s = id2genreg_dic[sid1][1]
            # sid1_e = id2genreg_dic[sid1][2]
            # sid2_s = id2genreg_dic[sid2][1]
            # sid2_e = id2genreg_dic[sid2][2]
            # if sid1 in id2pairid_dic:
            #     sid1_s = min(sid1_s, id2genreg_dic[id2pairid_dic[sid1]][1])
            #     sid1_e = max(sid1_e, id2genreg_dic[id2pairid_dic[sid1]][2])
            # if sid2 in id2pairid_dic:
            #     sid2_s = min(sid2_s, id2genreg_dic[id2pairid_dic[sid2]][1])
            #     sid2_e = max(sid2_e, id2genreg_dic[id2pairid_dic[sid2]][2])

            # Genomic distance of the two sites.
            gen_dist = hoodlib.get_site_ends_distance(sid1_s, sid1_e, sid2_s, sid2_e)
            # gen_dist = abs(id2cp_dic[sid1] - id2cp_dic[sid2])

            dist_diff = gen_dist - tr_dist
            sitetrid1 = "%s,%s" %(sid1, tr_id)
            sitetrid2 = "%s,%s" %(sid2, tr_id)
            sid1_s = sitetrid2coords_dic[sitetrid1][0]
            sid1_e = sitetrid2coords_dic[sitetrid1][1]
            sid2_s = sitetrid2coords_dic[sitetrid2][0]
            sid2_e = sitetrid2coords_dic[sitetrid2][1]
            if one_based_start:
                sid1_s += 1
                sid2_s += 1

            # Combination scores.
            sitetrid1_sc = sitetrid2sc_dic[sitetrid1]
            sitetrid2_sc = sitetrid2sc_dic[sitetrid2]

            c_pair_sites_sel_tr += 1

            same_set = "Y"
            if id2dataset_dic[sid1] != id2dataset_dic[sid2]:
                same_set = "N"
                c_pair_sites_sel_tr_diff_set += 1

            OUTTSV.write("%s\t%s\t%s\t%i\t%s\t%s\t%i\t%i\t%s\t%i\t%i\t%i\t%i\t%i\t%s\t%s\t%i\t%i\n" %(tr_id, tr_biotypes_str, assoc_gene_ids_str, tr_len, same_set, sid1, sid1_s, sid1_e, sid2, sid2_s, sid2_e, tr_dist, gen_dist, dist_diff, sid1_bed_sc, sid2_bed_sc, sitetrid1_sc, sitetrid2_sc))
    OUTTSV.close()


    """
    Output all transcript regions.
    """
    print("Output all transcript regions (12-column BED) ... ")
    hoodlib.write_12col_bed(tr_row_dic, all_tr_regs_bed_out)


    """
    Output transcript sequences.

    """
    print("Output all transcript sequences (FASTA) ... ")
    hoodlib.fasta_output_dic(tr_seqs_dic, all_tr_seqs_fa_out,
                             to_upper=True,
                             split_size=60,
                             split=True)

    print("# of all transcripts with sites:          %i" %(c_all_tr))
    print("# of selected transcripts with sites:     %i" %(c_sel_tr))
    print("# of site pairs on all transcripts:         %i" %(c_pair_sites_all_tr))
    print("# of site pairs (from different datasets):  %i" %(c_pair_sites_all_tr_diff_set))
    print("# of site pairs on selected transcripts:    %i" %(c_pair_sites_sel_tr))
    print("# of site pairs (from different datasets):  %i" %(c_pair_sites_sel_tr_diff_set))

    STATSOUT = open(merge_stats_out, "w")
    STATSOUT.write("c_all_tr\t%i\n" %(c_all_tr))
    STATSOUT.write("c_sel_tr\t%i\n" %(c_sel_tr))
    STATSOUT.write("c_pair_sites_all_tr\t%i\n" %(c_pair_sites_all_tr))
    STATSOUT.write("c_pair_sites_sel_tr\t%i\n" %(c_pair_sites_sel_tr))
    STATSOUT.close()


    add_stats_dic = {}
    add_stats_dic["c_all_tr"] = c_all_tr
    add_stats_dic["c_sel_tr"] = c_sel_tr
    add_stats_dic["c_pair_sites_all_tr"] = c_pair_sites_all_tr
    add_stats_dic["c_pair_sites_all_tr_diff_set"] = c_pair_sites_all_tr_diff_set
    add_stats_dic["c_pair_sites_sel_tr"] = c_pair_sites_sel_tr
    add_stats_dic["c_pair_sites_sel_tr_diff_set"] = c_pair_sites_sel_tr_diff_set




    """
    HTML report.

    """

    if args.report:

        # HTML report output file.
        html_report_out = args.out_folder + "/" + "report.peakhood_merge.html"
        # Plots subfolder.
        plots_subfolder = "html_plots"
        # Get library and logo path.
        hoodlib_path = os.path.dirname(hoodlib.__file__)
        print("Generate HTML report ... ")
        hoodlib.ph_merge_generate_html_report(args.out_folder, hoodlib_path,
                                            html_report_out=html_report_out,
                                            plots_subfolder=plots_subfolder,
                                            add_stats_dic=add_stats_dic,
                                            set_stats_dd=set_stats_dd,
                                            set2site_len_dic=set2site_len_dic,
                                            exb_sites_perc_dic=exb_sites_perc_dic,
                                            ex_sites_perc_dic=ex_sites_perc_dic,
                                            tc_sites_perc_dic=tc_sites_perc_dic)

    """
    Output report.

    """

    print("")
    print("OUTPUT FILES")
    print("============")
    print("")

    if args.report:
        assert os.path.exists(html_report_out), "HTML report %s not found" %(html_report_out)
        print("Merged dataset statistics report HTML:\n%s" %(html_report_out))
    print("Exonic site stats for each dataset TSV:\n%s" %(exonic_site_set_stats_out))
    print("All transcript regions BED:\n%s" %(all_tr_regs_bed_out))
    print("All transcript sequences FASTA:\n%s" %(all_tr_seqs_fa_out))
    print("All transcripts with sites TSV:\n%s" %(tr_all_sites_out))
    print("Selected transcripts with sites TSV:\n%s" %(tr_sel_sites_out))
    print("Site pairs on all transcripts TSV:\n%s" %(sites_on_same_all_tr_out))
    print("Site pairs on selected transcripts TSV:\n%s" %(sites_on_same_sel_tr_out))
    print("")



"""

    TO ADD:
    Gene annotations in tables,
    overlap with given GTF

    For transcript IDs inside given GTF, assign gene regions + biotype ...
    For transcript IDs not inside given GTF, overlap with gene regions,
    and select the fitting (?) one.
    DO like this:
    use transcript region from --in folder (store this info)
    and overlap with gene regions. Use overlap with most nucleotides overlap

    # overlapping nt / # nt longer feature (gene)
    Or say: transcript should overlap 90 %, otherwise it's probably not
    the gene

    Output genomic sites to BED, overlap with gene regions



    tr_all_sites_out = args.out_folder + "/" + "transcripts_with_sites.all_tr.tsv"
    tr_sel_sites_out = args.out_folder + "/" + "transcripts_with_sites.sel_tr.tsv"
    sites_on_same_all_tr_out = args.out_folder + "/" + "sites_on_same_transcripts.all_tr.tsv"
    sites_on_same_sel_tr_out = args.out_folder + "/" + "sites_on_same_transcripts.sel_tr.tsv"



    get_center_position(start, end) # 0-based 1-based


    Report:
    Number of pair sites (on same transcripts)
    Number of pair sites (on same selected transcripts)
    ...



    tr_all_sites_out = args.out_folder + "/" + "transcripts_with_sites.all_tr.tsv"
    tr_sel_sites_out = args.out_folder + "/" + "transcripts_with_sites.sel_tr.tsv"
    sites_on_same_all_tr_out = args.out_folder + "/" + "sites_on_same_transcripts.all_tr.tsv"
    sites_on_same_sel_tr_out = args.out_folder + "/" + "sites_on_same_transcripts.sel_tr.tsv"




Merge:
======
Should run fast ...
Merge two or more sets
What exactly

- Merge selected ones (report in BED file transcripts with
> 1 binding site from different RBPs)
- Merge all (report in BED file ... )


Site_id to close_by site IDs (< 100)

Report sites for which distance comes from > 100 (user-definable)
to < 100


All transcript context site-transcript combinations BED:
pum2_ir_ex_test2_out/exonic_sites.tr_con.all_tr.bed

Selected transcript context site-transcript combinations BED:
pum2_ir_ex_test2_out/exonic_sites.tr_con.sel_tr.bed

Transcript context sites on genome BED:
pum2_ir_ex_test2_out/exonic_sites.tr_con.gen.bed

    # Reference lengths out.
    ref_len_out = args.out_folder + "/" + "ref_lengths.out"
"""

################################################################################

def main_batch(args):
    """

    ID convention for:
    ID_rep1.bam
    ID_rep2.bam
    ...
    And binding sites:
    ID.bed

    """

    print("Running for you in BATCH mode ... ")

    assert os.path.exists(args.in_folder), "--in folder \"%s\" does not exist" %(args.in_folder)

    # Some checks.
    assert os.path.exists(args.in_gtf), "--gtf GTF file \"%s\" not found" %(args.in_gtf)
    assert os.path.exists(args.in_2bit), "--gen .2bit file \"%s\" not found" %(args.in_2bit)
    assert args.min_eol <= 1 and args.min_eol >= 0.5, "set reasonable --min-exon-overlap (>= 0.5 and <= 1.0)"
    assert args.min_ei_ratio > 1, "set reasonable --min-ei-ratio (> 1)"
    assert args.min_eib_ratio > 1, "set reasonable --min-eib-ratio (> 1)"
    assert args.isr_max_reg_len >= 0 and args.isr_max_reg_len <= 50, "set reasonable --isr-max-reg-len (>= 0 and <= 50)"

    if args.isrn_prefilter:
        assert args.isrn_prefilter > 0, "given --isr-prefilter read number has to be > 0"
    if args.merge_gtf:
        assert os.path.exists(args.merge_gtf), "--add-gtf GTF file \"%s\" not found" %(args.merge_gtf)
    if args.rnaseq_bam:
        assert os.path.exists(args.rnaseq_bam), "--rnaseq-bam BAM file \"%s\" not found" %(args.rnaseq_bam)

    # Check filter settings.
    list_f1_filter, list_f2_filter = hoodlib.get_filter_lists(args.list_f1_filter,
                                                              args.list_f2_filter)

    # Batch results output folder.
    assert not os.path.exists(args.out_folder), "--out folder already exists"
    os.makedirs(args.out_folder)

    # Output mode settings.
    settings_file = args.out_folder + "/settings.peakhood_batch.out"
    SETOUT = open(settings_file, "w")
    for arg in vars(args):
        SETOUT.write("%s\t%s\n" %(arg, str(getattr(args, arg))))
    SETOUT.close()

    # Get BED + BAM files.
    in_bed_files = hoodlib.dir_get_files(args.in_folder, file_ending="bed", check=False)
    assert in_bed_files, "no BED files found (.bed file endings) in given --in folder %s" %(args.in_folder)
    in_bam_files = hoodlib.dir_get_files(args.in_folder, file_ending="bam", check=False)
    assert in_bam_files, "no BAM files found (.bam file endings) in given --in folder %s" %(args.in_folder)

    # Get dataset IDs.
    bed_files_dic = {}
    for bed_file in in_bed_files:
        m = re.search("(.+)\.bed", bed_file)
        dataset_id = m.group(1)
        bed_files_dic[dataset_id] = args.in_folder + "/" + bed_file
    assert bed_files_dic, "no dataset IDs extracted for --in folder %s BED files" %(args.in_folder)

    # Get BAM files.
    bam_files_dic = {}
    for bam_file in in_bam_files:
        if re.search(".+_rep\d+\.bam", bam_file):
            m = re.search("(.+)_rep\d+\.bam", bam_file)
            dataset_id = m.group(1)
            assert dataset_id in bed_files_dic, "no BED file found inside --in folder for BAM dataset ID %s" %(dataset_id)
            bam_path = args.in_folder + "/" + bam_file
            if dataset_id in bam_files_dic:
                bam_files_dic[dataset_id].append(bam_path)
            else:
                bam_files_dic[dataset_id] = [bam_path]
        elif re.search(".+\.bam", bam_file):
            m = re.search("(.+)\.bam", bam_file)
            dataset_id = m.group(1)
            assert dataset_id in bed_files_dic, "no BED file found inside --in folder for BAM dataset ID %s" %(dataset_id)
            bam_path = args.in_folder + "/" + bam_file
            if dataset_id in bam_files_dic:
                bam_files_dic[dataset_id].append(bam_path)
            else:
                bam_files_dic[dataset_id] = [bam_path]

    # Checks.
    for dataset_id in bed_files_dic:
        assert dataset_id in bam_files_dic, "no BAM files found inside --in folder for BED dataset ID %s" %(dataset_id)

    c_sets = len(bed_files_dic)

    print("# of datasets inside --in folder:  %i" %(c_sets))
    assert c_sets > 1, "peakhood batch needs at least two --in datasets"


    """
    Extract sites for each dataset (peakhood extract).

    """

    # Same extract parameters for all runs.
    extract_params = " --min-exon-overlap " + str(args.min_eol)
    extract_params += " --min-ei-ratio " + str(args.min_ei_ratio)
    # EIB ratios.
    if args.no_eibr_filter:
        extract_params += " --no-eibr-filter "
    else:
        extract_params += " --min-eib-ratio " + str(args.min_eib_ratio)
        extract_params += " --eib-width " + str(args.eib_width)
        extract_params += " --eibr-mode " + str(args.eib_ratio_mode)
    if args.no_eir_wt_filter:
        extract_params += " --no-eir-wt-filter "
    if args.no_eibr_wt_filter:
        extract_params += " --no-eibr-wt-filter "

    if args.sc_thr is not None:
        extract_params += " --thr " + str(args.sc_thr)
        if args.rev_filter:
                extract_params += " --thr-rev-filter "

    extract_params += " --max-len " + str(args.max_len)
    extract_params += " --bam-pp-mode " + str(args.bam_pp_mode)
    extract_params += " --read-pos-mode " + str(args.read_pos_mode)

    if args.no_tbt_filter:
        extract_params += " --no-biotype-filter "
    else:
        if args.list_tbt_filter_ids:
            list_tbt_filter_ids_str = ' '.join(list_tbt_filter_ids)
            extract_params += " --tbt-filter-ids " + list_tbt_filter_ids_str

    if args.no_tis_filter:
        extract_params += " --no-tis-filter "
    else:
        extract_params += " --min-tis-sites " + str(args.min_n_tis_sites)

    if args.min_exbs_isr_c:
        extract_params += " --min-exbs-isr-c " + str(args.min_exbs_isr_c)

    if args.no_f1_filter:
        extract_params += " --no-f1-filter "
    else:
        if args.list_f1_filter:
            list_f1_filter_str = ' '.join(list_f1_filter)
            extract_params += " --f1-filter " + list_f1_filter_str
    if args.list_f2_filter:
        list_f2_filter_str = ' '.join(list_f2_filter)
        extract_params += " --f2-filter " + list_f2_filter_str

    extract_params += " --f2-mode " + str(args.f2_mode)

    if args.isrn_prefilter:
        extract_params += " --isrn-prefilter "
    extract_params += " --merge-mode " + str(args.merge_mode)
    extract_params += " --merge-ext " + str(args.merge_ext)
    extract_params += " --seq-ext-mode " + str(args.seq_ext_mode)
    extract_params += " --seq-ext " + str(args.seq_ext)
    if args.pre_merge:
        extract_params += " --pre-merge "

    extract_params += " --isr-ext-mode " + str(args.isr_ext_mode)
    extract_params += " --isr-max-reg-len " + str(args.isr_max_reg_len)

    if args.rnaseq_bam:
        assert os.path.exists(args.rnaseq_bam), "--rnaseq-bam file %s does not exist" %(args.rnaseq_bam)
        extract_params += " --rnaseq-bam " + args.rnaseq_bam
    if args.rnaseq_bam and args.rnaseq_bam_rev:
        extract_params += " --rnaseq-bam-rev "
    if args.report:
        extract_params += " --report "

    extract_folders_list = []

    # Run peakhood extract each dataset from --in folder.
    for dataset_id in bed_files_dic:
        bed_file = bed_files_dic[dataset_id]
        bam_files_list = bam_files_dic[dataset_id]
        bam_files_str = ' '.join(bam_files_list)

        c_in_sites = hoodlib.count_file_rows(bed_file, nr_cols=6)
        assert c_in_sites, "--in BED file \"%s\" contains no 6-column BED regions. Make sure to provide --in BED file with genomic regions in 6-column format" %(bed_file)

        # Peakhood extract output folder.
        extract_out_folder = args.out_folder + "/" + dataset_id + "_extract_out"
        extract_folders_list.append(extract_out_folder)

        # Construct peakhood extract command.
        extract_cmd = "peakhood extract --in " + bed_file + " --bam " + bam_files_str + " --gtf " + args.in_gtf + " --gen " + args.in_2bit + " --out " + extract_out_folder
        extract_cmd += extract_params
        if args.new_ids:
            extract_cmd += " --new-site-id " + dataset_id

        # Run peakhood extract.
        import subprocess

        print("Extract transcript context sites for dataset %s ... " %(dataset_id))
        print(extract_cmd)
        output = subprocess.getoutput(extract_cmd)

        # Save output.
        run_log_file = extract_out_folder + "/run.peakhood_extract.log"
        RUNLOGOUT = open(run_log_file, "w")
        RUNLOGOUT.write(output)
        RUNLOGOUT.close()

        # Check for errors in log file.
        error_found = hoodlib.check_string_in_file(run_log_file, "AssertionError")
        assert not error_found, "An assertion error was raised during this peakhood extract run, check run log file %s for details" %(run_log_file)

        # Check for results.
        stats_out_file = extract_out_folder + "/extract_stats.out"
        assert os.path.exists(stats_out_file), "missing extract_stats.out file inside folder %s. Probably this peakhood extract run produced errors, check run log file %s" %(extract_out_folder, run_log_file)
        extr_stats_dic = hoodlib.read_settings_into_dic(stats_out_file, check=False)
        assert extr_stats_dic, "no stats extracted from extract_stats.out file inside folder %s. Probably this peakhood extract run produced errors, check run log file %s" %(extract_out_folder, run_log_file)
        c_intergen_sites = int(extr_stats_dic["c_intergen_sites"])
        c_intron_sites = int(extr_stats_dic["c_intron_sites"])
        c_exon_sites_tc = int(extr_stats_dic["c_exon_sites_tc"])
        c_exon_sites_merged_tc = int(extr_stats_dic["c_exon_sites_merged_tc"])
        c_exon_sites_gc = int(extr_stats_dic["c_exon_sites_gc"])
        c_all_sites = c_intergen_sites + c_intron_sites + c_exon_sites_gc + c_exon_sites_tc
        c_exonic_sites = int(extr_stats_dic["c_exonic_sites"])
        c_exb_sites = int(extr_stats_dic["c_exb_sites"])

        # Percentage of exonic sites.
        perc_exonic_sites = "0.0 %"
        if c_exonic_sites and c_all_sites:
            perc_exonic_sites = "%.2f " %((c_exonic_sites / c_all_sites) * 100) + "%"
        # Percentage of spliced context sites.
        perc_exonic_tc_sites = "0.0 %"
        if c_exon_sites_tc and c_exonic_sites:
            perc_exonic_tc_sites = "%.2f " %((c_exon_sites_tc / c_exonic_sites) * 100) + "%"
        # Percentage of exon border sites (connected by ISR reads).
        perc_exb_sites = "0.0 %"
        if c_exb_sites and c_exon_sites_tc:
            perc_exb_sites = "%.2f " %((c_exb_sites / c_exon_sites_tc) * 100) + "%"


        print("dataset:  %s" %(dataset_id))
        print("# of all sites                                    %i" %(c_all_sites))
        print("# of intronic sites:                              %i" %(c_intron_sites))
        print("# of intergenic sites:                            %i" %(c_intergen_sites))
        print("# of exonic sites (assigned genome context):      %i" %(c_exon_sites_gc))
        print("# of exonic sites (assigned transcript context):  %i" %(c_exon_sites_tc))
        print("# of sites after merging exon border sites:       %i" %(c_exon_sites_merged_tc))

        print("Percentage (# exonic sites / # all input sites):\n%s" %(perc_exonic_sites))
        print("Percentage (# transcript context sites / # exonic sites):\n%s" %(perc_exonic_tc_sites))
        print("Percentage (# exon border sites / # transcript context sites):\n%s" %(perc_exb_sites))

        print("")


    """
    Merge extract --out folders with peakhood merge.

    """

    assert extract_folders_list, "no peakhood extract --out folders collected"

    extract_folders_str = ' '.join(extract_folders_list)

    # Construct peakhood merge command.
    merge_cmd = "peakhood merge --in " + extract_folders_str + " --out " + args.out_folder
    if args.merge_gtf:
        merge_cmd += " --gtf " + args.merge_gtf
    if args.report:
        merge_cmd += " --report "

    # Run peakhood merge.
    print("Merge peakhood extract folders ... ")

    print(merge_cmd)
    output = subprocess.getoutput(merge_cmd)

    # Save output.
    run_log_file = args.out_folder + "/run.peakhood_merge.log"
    RUNLOGOUT = open(run_log_file, "w")
    RUNLOGOUT.write(output)
    RUNLOGOUT.close()

    # Check for results.
    merge_stats_out = args.out_folder + "/" + "merge_stats.out"
    assert os.path.exists(merge_stats_out), "missing merge_stats.out file inside folder %s. Probably peakhood merge produced errors, check run log file %s" %(args.out_folder, run_log_file)
    merge_stats_dic = hoodlib.read_settings_into_dic(merge_stats_out, check=False)
    assert merge_stats_dic, "no stats extracted from %s. Probably peakhood merge produced errors, check run log file %s" %(merge_stats_out, run_log_file)

    c_all_tr = int(merge_stats_dic["c_all_tr"])
    c_sel_tr = int(merge_stats_dic["c_sel_tr"])
    c_pair_sites_all_tr = int(merge_stats_dic["c_pair_sites_all_tr"])
    c_pair_sites_sel_tr = int(merge_stats_dic["c_pair_sites_sel_tr"])

    tr_all_sites_out = args.out_folder + "/" + "transcripts_with_sites.all_tr.tsv"
    tr_sel_sites_out = args.out_folder + "/" + "transcripts_with_sites.sel_tr.tsv"
    sites_on_same_all_tr_out = args.out_folder + "/" + "sites_on_same_transcripts.all_tr.tsv"
    sites_on_same_sel_tr_out = args.out_folder + "/" + "sites_on_same_transcripts.sel_tr.tsv"
    all_tr_seqs_fa_out = args.out_folder + "/" + "all_transcript_sequences.fa"
    all_tr_regs_bed_out = args.out_folder + "/" + "all_transcript_regions.bed"
    html_report_out = args.out_folder + "/" + "report.peakhood_merge.html"

    assert os.path.exists(tr_all_sites_out), "merge output file %s not found. Probably peakhood merge produced errors, check run log file %s" %(tr_all_sites_out, run_log_file)
    assert os.path.exists(tr_sel_sites_out), "merge output file %s not found. Probably peakhood merge produced errors, check run log file %s" %(tr_sel_sites_out, run_log_file)
    assert os.path.exists(sites_on_same_all_tr_out), "merge output file %s not found. Probably peakhood merge produced errors, check run log file %s" %(sites_on_same_all_tr_out, run_log_file)
    assert os.path.exists(sites_on_same_sel_tr_out), "merge output file %s not found. Probably peakhood merge produced errors, check run log file %s" %(sites_on_same_sel_tr_out, run_log_file)
    assert os.path.exists(all_tr_seqs_fa_out), "merge output file %s not found. Probably peakhood merge produced errors, check run log file %s" %(all_tr_seqs_fa_out, run_log_file)
    assert os.path.exists(all_tr_regs_bed_out), "merge output file %s not found. Probably peakhood merge produced errors, check run log file %s" %(all_tr_regs_bed_out, run_log_file)
    assert os.path.exists(html_report_out), "merge output file %s not found. Probably peakhood merge produced errors, check run log file %s" %(html_report_out, run_log_file)

    print("Merged dataset results:")
    print("# of all transcripts with sites:          %i" %(c_all_tr))
    print("# of selected transcripts with sites:     %i" %(c_sel_tr))
    print("# of site pairs on all transcripts:       %i" %(c_pair_sites_all_tr))
    print("# of site pairs on selected transcripts:  %i" %(c_pair_sites_sel_tr))

    print("")
    print("OUTPUT FILES")
    print("============")
    print("")

    if args.report:
        print("Merged dataset statistics report HTML:\n%s" %(html_report_out))
    print("All transcript regions BED:\n%s" %(all_tr_regs_bed_out))
    print("All transcript sequences FASTA:\n%s" %(all_tr_seqs_fa_out))
    print("All transcripts with sites TSV:\n%s" %(tr_all_sites_out))
    print("Selected transcripts with sites TSV:\n%s" %(tr_sel_sites_out))
    print("Site pairs on all transcripts TSV:\n%s" %(sites_on_same_all_tr_out))
    print("Site pairs on selected transcripts TSV:\n%s" %(sites_on_same_sel_tr_out))
    print("")


################################################################################

def main_motif(args):
    """
    Search motif in context sets.

    """

    print("Running for you in MOTIF mode ... ")

    assert os.path.exists(args.in_data), "--in file or folder \"%s\" does not exist" %(args.in_data)

    if os.path.isdir(args.in_data):

        """
        --in type peakhood extract folder.

        """

        if args.stats_out or args.data_id:
            assert args.stats_out and args.data_id, "--stats-out requires --data-id and the other way around"

        hits_tr_con_bed = False
        hits_tr_con_fa = False
        hits_tr_con_gen_reg_bed=False
        hits_tr_con_gen_reg_split_bed=False
        hits_tr_con_gen_bed = False
        hits_tr_con_gen_fa = False
        hits_gen_con_bed = False
        hits_gen_con_fa = False
        hits_intron_bed = False
        hits_intron_fa = False
        hits_intergen_bed = False
        hits_intergen_fa = False

        if args.out_folder:

            if not os.path.exists(args.out_folder):
                os.makedirs(args.out_folder)

            hits_tr_con_bed = args.out_folder + "/exonic_sites.tr_con.sel_tr.hits.bed"
            hits_tr_con_fa = args.out_folder + "/exonic_sites.tr_con.sel_tr.hits.fa"
            hits_tr_con_gen_reg_bed = args.out_folder + "/exonic_sites.tr_con.sel_tr.gen_reg.all_hits.bed"
            hits_tr_con_gen_reg_split_bed = args.out_folder + "/exonic_sites.tr_con.sel_tr.gen_reg.split_hits.bed"
            hits_tr_con_gen_bed = args.out_folder + "/exonic_sites.tr_con.gen.hits.bed"
            hits_tr_con_gen_fa = args.out_folder + "/exonic_sites.tr_con.gen.hits.fa"
            hits_gen_con_bed = args.out_folder + "/exonic_sites.gen_con.hits.bed"
            hits_gen_con_fa = args.out_folder + "/exonic_sites.gen_con.hits.fa"
            hits_intron_bed = args.out_folder + "/intronic_sites.hits.bed"
            hits_intron_fa = args.out_folder + "/intronic_sites.hits.fa"
            hits_intergen_bed = args.out_folder + "/intergenic_sites.hits.bed"
            hits_intergen_fa = args.out_folder + "/intergenic_sites.hits.fa"

        # Input sites to look for motifs.
        tr_con_bed = args.in_data + "/exonic_sites.tr_con.sel_tr.bed"
        tr_con_fa = args.in_data + "/exonic_sites.tr_con.sel_tr.fa"
        tr_con_gen_bed = args.in_data + "/exonic_sites.tr_con.gen.bed"
        tr_con_gen_fa = args.in_data + "/exonic_sites.tr_con.gen.fa"
        gen_con_bed = args.in_data + "/exonic_sites.gen_con.bed"
        gen_con_fa = args.in_data + "/exonic_sites.gen_con.fa"
        intron_bed = args.in_data + "/intronic_sites.bed"
        intron_fa = args.in_data + "/intronic_sites.fa"
        intergen_bed = args.in_data + "/intergenic_sites.bed"
        intergen_fa = args.in_data + "/intergenic_sites.fa"
        exon_regions_sel_tr_bed = args.in_data + "/exon_regions.sel_tr.bed"

        assert os.path.exists(tr_con_bed), "--in folder does not contain \"%s\". Please provide genuine peakhood extract --out folder" %(tr_con_bed)
        assert os.path.exists(tr_con_fa), "--in folder does not contain \"%s\". Please provide genuine peakhood extract --out folder" %(tr_con_fa)
        assert os.path.exists(tr_con_gen_bed), "--in folder does not contain \"%s\". Please provide genuine peakhood extract --out folder" %(tr_con_gen_bed)
        assert os.path.exists(tr_con_gen_fa), "--in folder does not contain \"%s\". Please provide genuine peakhood extract --out folder" %(tr_con_gen_fa)
        assert os.path.exists(gen_con_bed), "--in folder does not contain \"%s\". Please provide genuine peakhood extract --out folder" %(gen_con_bed)
        assert os.path.exists(gen_con_fa), "--in folder does not contain \"%s\". Please provide genuine peakhood extract --out folder" %(gen_con_fa)
        assert os.path.exists(intron_bed), "--in folder does not contain \"%s\". Please provide genuine peakhood extract --out folder" %(intron_bed)
        assert os.path.exists(intron_fa), "--in folder does not contain \"%s\". Please provide genuine peakhood extract --out folder" %(intron_fa)
        assert os.path.exists(intergen_bed), "--in folder does not contain \"%s\". Please provide genuine peakhood extract --out folder" %(intergen_bed)
        assert os.path.exists(intergen_fa), "--in folder does not contain \"%s\". Please provide genuine peakhood extract --out folder" %(intergen_fa)
        assert os.path.exists(exon_regions_sel_tr_bed), "--in folder does not contain exon_regions.sel_tr.bed file. This is either due to no spliced transcript context sites extracted, or no genuine peakhood extract output folder provided"

        # Get exonic transcript context hits.
        c_tc_hits, c_tc_uniq_hits, c_tc_sites, tc_reg_size = hoodlib.get_tr_motif_hits(
                                                        args.in_regex,
                                                        tr_con_fa, tr_con_bed,
                                                        exon_regions_sel_tr_bed,
                                                        hits_tr_con_gen_reg_bed=hits_tr_con_gen_reg_bed,
                                                        hits_tr_con_gen_reg_split_bed=hits_tr_con_gen_reg_split_bed,
                                                        hits_out_bed=hits_tr_con_bed,
                                                        hits_out_fa=hits_tr_con_fa)

        # Get exonic transcript context genomic hits.
        c_tcg_hits, c_tcg_uniq_hits, c_tcg_sites, tcg_reg_size = hoodlib.get_gen_motif_hits(
                                                        args.in_regex,
                                                        tr_con_gen_fa, tr_con_gen_bed,
                                                        hits_out_bed=hits_tr_con_gen_bed,
                                                        hits_out_fa=hits_tr_con_gen_fa)

        # Get exonic genomic context hits.
        c_gc_hits, c_gc_uniq_hits, c_gc_sites, gc_reg_size = hoodlib.get_gen_motif_hits(
                                                        args.in_regex,
                                                        gen_con_fa, gen_con_bed,
                                                        hits_out_bed=hits_gen_con_bed,
                                                        hits_out_fa=hits_gen_con_fa)

        # Get intronic hits.
        c_intron_hits, c_intron_uniq_hits, c_intron_sites, intron_reg_size = hoodlib.get_gen_motif_hits(
                                                        args.in_regex,
                                                        intron_fa, intron_bed,
                                                        hits_out_bed=hits_intron_bed,
                                                        hits_out_fa=hits_intron_fa)

        # Get intergenic hits.
        c_inter_hits, c_inter_uniq_hits, c_inter_sites, inter_reg_size = hoodlib.get_gen_motif_hits(
                                                        args.in_regex,
                                                        intergen_fa, intergen_bed,
                                                        hits_out_bed=hits_intergen_bed,
                                                        hits_out_fa=hits_intergen_fa)


        # Number of split hits (transcript to genome mapping).
        c_split_hits = 0
        if hits_tr_con_gen_reg_split_bed:
            if os.path.exists(hits_tr_con_gen_reg_split_bed):
                print("Here 4 ... ")
                print("Path:", hits_tr_con_gen_reg_split_bed)
                c_split_hits = hoodlib.count_file_rows(hits_tr_con_gen_reg_split_bed)

        if args.out_folder:

            # Get GC or TC exclusive hits.
            tc_reg_str_dic = hoodlib.bed_read_reg_str_into_dic(hits_tr_con_gen_reg_bed)
            gc_reg_str_dic = hoodlib.bed_read_reg_str_into_dic(hits_tr_con_gen_bed)

            gc_excl_reg_list = []
            tc_excl_reg_list = []
            for reg_str in tc_reg_str_dic:
                if reg_str not in gc_reg_str_dic:
                    tc_excl_reg_list.append(reg_str)
            for reg_str in gc_reg_str_dic:
                if reg_str not in tc_reg_str_dic:
                    gc_excl_reg_list.append(reg_str)

            tr_con_gen_excl_hits_tsv = args.out_folder + "/tr_con_gen_excl_hits.igv.tsv"
            EXCLOUT = open(tr_con_gen_excl_hits_tsv, "w")
            EXCLOUT.write("region_type\thit_ids\tigv_genomic_hit_region\tstrand\n")
            for reg_str in gc_excl_reg_list:
                reg_col = reg_str.split(",")
                igv_chr = reg_col[0]
                hit_pol = reg_col[3]
                igv_s = hoodlib.koma_sepp(int(reg_col[1])+1)
                igv_e = hoodlib.koma_sepp(int(reg_col[2]))
                igv_reg = "%s:%s-%s" %(igv_chr, igv_s, igv_e)
                hit_ids = gc_reg_str_dic[reg_str]
                hit_ids_str = ','.join(hit_ids)
                EXCLOUT.write("exon_tcg\t%s\t%s\t%s\n" %(hit_ids_str,igv_reg,hit_pol))
            for reg_str in tc_excl_reg_list:
                reg_col = reg_str.split(",")
                igv_chr = reg_col[0]
                hit_pol = reg_col[3]
                igv_s = hoodlib.koma_sepp(int(reg_col[1])+1)
                igv_e = hoodlib.koma_sepp(int(reg_col[2]))
                igv_reg = "%s:%s-%s" %(igv_chr, igv_s, igv_e)
                hit_ids = tc_reg_str_dic[reg_str]
                hit_ids_str = ','.join(hit_ids)
                EXCLOUT.write("exon_tc\t%s\t%s\t%s\n" %(hit_ids_str,igv_reg,hit_pol))
            EXCLOUT.close()

        # Ratios.
        tc_ratio = "0"
        tcg_ratio = "0"
        gc_ratio = "0"
        intron_ratio = "0"
        inter_ratio = "0"
        if c_tc_uniq_hits:
            tc_ratio = "%.5f" %(( c_tc_uniq_hits / tc_reg_size ) * 1000)
        if c_tcg_uniq_hits:
            tcg_ratio = "%.5f" %(( c_tcg_uniq_hits / tcg_reg_size ) * 1000)
        if c_gc_uniq_hits:
            gc_ratio = "%.5f" %(( c_gc_uniq_hits / gc_reg_size ) * 1000)
        if c_intron_uniq_hits:
            intron_ratio = "%.5f" %(( c_intron_uniq_hits / intron_reg_size ) * 1000)
        if c_inter_uniq_hits:
            inter_ratio = "%.5f" %(( c_inter_uniq_hits / inter_reg_size ) * 1000)

        tr_gen_ratio = 0
        if c_tc_uniq_hits:
            tr_gen_ratio = str(c_tc_uniq_hits)
        if c_tc_uniq_hits and c_tcg_uniq_hits:
            tr_gen_ratio = "%.5f" %( ( c_tc_uniq_hits / tc_reg_size ) / ( c_tcg_uniq_hits / tcg_reg_size ) )

        # If --stats-out.
        if args.stats_out:
            append = False
            if os.path.exists(args.stats_out):
                append = True
                STATOUT = open(args.stats_out, "a")
            else:
                STATOUT = open(args.stats_out, "w")
            # Output.
            if not append:
                STATOUT.write("data_id\tmotif\tintron_sites\tintergen_sites\tgen_con_sites\ttr_con_sites\tc_intron_hits\tintron_hit_ratio\tc_intergen_hits\tintergen_hit_ratio\tc_gen_con_hits\tgen_con_hit_ratio\tc_tr_con_hits\ttr_con_hit_ratio\tc_tr_con_gen_hits\ttr_con_gen_hit_ratio\ttr_gen_ratio\n")
            STATOUT.write("%s\t%s\t%i\t%i\t%i\t%i\t%i\t%s\t%i\t%s\t%i\t%s\t%i\t%s\t%i\t%s\t%s\n" %(args.data_id, args.in_regex, c_intron_sites, c_inter_sites, c_gc_sites, c_tc_sites, c_intron_uniq_hits, intron_ratio, c_inter_uniq_hits, inter_ratio, c_gc_uniq_hits, gc_ratio, c_tc_uniq_hits, tc_ratio, c_tcg_uniq_hits, tcg_ratio, tr_gen_ratio))
            STATOUT.close()

        # Report.
        print("--motif:  %s" %(args.in_regex))
        print("")
        print("SITE NUMBERS PER REGION TYPE:")
        print("# exonic transcript context sites:          %i" %(c_tc_sites))
        print("# associated sites with genomic context:    %i" %(c_tcg_sites))
        print("# exonic genomic context sites:             %i" %(c_gc_sites))
        if c_intron_sites:
            print("# intronic sites:                           %i" %(c_intron_sites))
        if c_inter_sites:
            print("# intergenic sites:                         %i" %(c_inter_sites))
        print("HIT COUNTS & RATIOS PER REGION TYPE:")
        print("# exonic transcript context hits:           %i" %(c_tc_uniq_hits))
        print("Transcript context region size:             %i" %(tc_reg_size))
        print("Ratio (# hits / 1000 nt):                   %s" %(tc_ratio))
        print("# hits on same sites with genomic context:  %i" %(c_tcg_uniq_hits))
        print("Genomic context region size:                %i" %(tcg_reg_size))
        print("Ratio (# hits / 1000 nt):                   %s" %(tcg_ratio))
        print("# exonic genomic context hits:              %i" %(c_gc_uniq_hits))
        print("Genomic context region size:                %i" %(gc_reg_size))
        print("Ratio (# hits / 1000 nt):                   %s" %(gc_ratio))
        if c_intron_sites:
            print("# intronic hits:                            %i" %(c_intron_uniq_hits))
            print("Intronic region size:                       %i" %(intron_reg_size))
            print("Ratio (# hits / 1000 nt):                   %s" %(intron_ratio))
        if c_inter_sites:
            print("# intergenic hits:                          %i" %(c_inter_uniq_hits))
            print("Intergenic region size:                     %i" %(inter_reg_size))
            print("Ratio (# hits / 1000 nt):                   %s" %(inter_ratio))
        print("")

        # Report output files.
        if args.out_folder:
            print("HIT BED + FASTA OUTPUT FILES:")
            if c_tc_uniq_hits:
                print("Transcript context hits on transcripts BED:\n%s" %(hits_tr_con_bed))
                print("Transcript context hits on transcripts FASTA:\n%s" %(hits_tr_con_fa))
                print("Transcript context hits on genome (all hits) BED:\n%s" %(hits_tr_con_gen_reg_bed))
                if c_split_hits:
                    print("Transcript context hits on genome (only split hits) BED:\n%s" %(hits_tr_con_gen_reg_split_bed))
            if c_tcg_uniq_hits:
                print("Transcript context site hits on original genomic context BED:\n%s" %(hits_tr_con_gen_bed))
                print("Transcript context site hits on original genomic context FASTA:\n%s" %(hits_tr_con_gen_fa))
            if c_gc_uniq_hits:
                print("Exonic genomic context hits BED:\n%s" %(hits_gen_con_bed))
                print("Exonic genomic context hits FASTA:\n%s" %(hits_gen_con_fa))
            if c_intron_sites:
                print("Intronic hits BED:\n%s" %(hits_intron_bed))
                print("Intronic hits FASTA:\n%s" %(hits_intron_fa))
            if c_inter_sites:
                print("Intergenic hits BED:\n%s" %(hits_intergen_bed))
                print("Intergenic hits FASTA:\n%s" %(hits_intergen_fa))
            print("")

    elif os.path.isfile(args.in_data):

        """
        --in BED or transcript list file.

        """

        assert args.in_gtf and args.in_2bit, "--in file of type 2 or 3 requires --gtf and --gen"
        assert os.path.exists(args.in_gtf), "--gtf GTF file \"%s\" not found" %(args.in_gtf)
        assert os.path.exists(args.in_2bit), "--gen .2bit file \"%s\" not found" %(args.in_2bit)

        # Get column count to identify which input type is present.
        col_c = hoodlib.get_col_count(args.in_data)

        if col_c == 1:
            # Transcript list given (type 3).
            print("--in transcript list input assumed. Check whether IDs are in --gtf ... ")
            # Read in --in IDs and check.
            tr_ids_dic = hoodlib.read_ids_into_dic(args.in_data)
            all_tr_ids_dic = hoodlib.gtf_get_transcript_ids(args.in_gtf)
            for tr_id in tr_ids_dic:
                assert tr_id in all_tr_ids_dic, "--in transcript ID %s not found in --gtf"
            tr_ids_c = len(tr_ids_dic)
            print("# transcript IDs read in from --in:  %i" %(tr_ids_c))
            # Get transcript sequences.
            print("Extract transcript sequences using --gen and --gtf ... ")
            # Returns RNA sequences.
            tr_seqs_dic = hoodlib.get_transcript_sequences_from_gtf(args.in_gtf, args.in_2bit,
                                                                    tr_ids_dic=tr_ids_dic)
            if args.out_folder:
                # Motif hits BED files.
                hits_on_transcripts_bed = args.out_folder + "/" + "motif_hits_on_transcripts.bed"
                hits_on_transcripts_fa = args.out_folder + "/" + "motif_hits_on_transcripts.fa"
                # Generate results output folder.
                if not os.path.exists(args.out_folder):
                    os.makedirs(args.out_folder)
                THOUT = open(hits_on_transcripts_bed, "w")
                THFOUT = open(hits_on_transcripts_fa, "w")

            # Scan for hits on transcript sequences.
            c_tr_hits = 0
            c_tr_seqs_len = 0
            for seq_id in tr_seqs_dic:
                seq = tr_seqs_dic[seq_id]
                c_tr_seqs_len += len(seq)
                seq_id_hit_c = 0
                for match in re.finditer(args.in_regex, seq):
                    c_tr_hits += 1
                    seq_id_hit_c += 1
                    hit = match.group()
                    hit_s = match.start() # 0-based.
                    hit_e = match.end() # 1-based.
                    motif_id = seq_id + "_" + str(seq_id_hit_c)

                    if args.out_folder:
                        THOUT.write("%s\t%i\t%i\t%s\t0\t+\n" %(seq_id, hit_s, hit_e, motif_id))
                        THFOUT.write(">%s\n%s\n" %(motif_id, hit))

            if args.out_folder:
                THOUT.close()
                THFOUT.close()

            if not c_tr_hits:
                print("No motif hits on specified transcript sequences")
                sys.exit()

            if args.out_folder:
                # Map transcript hits to genome.
                print("Mapping motif hits on transcripts to genome ... ")
                site2hitc_dic = {}
                hoodlib.bed_convert_transcript_to_genomic_sites(hits_on_transcripts_bed, args.in_gtf,
                                                                args.out_folder,
                                                                site2hitc_dic=site2hitc_dic,
                                                                out_folder=True)
                assert site2hitc_dic, "site ID to hit count dictionary empty"

                # Rename output files.
                out_all_hits_bed = args.out_folder + "/" + "all_hits.bed"
                out_unique_hits_bed = args.out_folder + "/" + "unique_hits.bed"
                out_split_hits_bed = args.out_folder + "/" + "split_hits.bed"
                gen_all_bed = args.out_folder + "/" + "all_hits_on_genome.bed"
                gen_unique_bed = args.out_folder + "/" + "full_length_hits_on_genome.bed"
                gen_split_bed = args.out_folder + "/" + "split_hits_on_genome.bed"
                hoodlib.move_rename_file(out_all_hits_bed, gen_all_bed)
                hoodlib.move_rename_file(out_unique_hits_bed, gen_unique_bed)
                hoodlib.move_rename_file(out_split_hits_bed, gen_split_bed)

                # Get hit counts and split numbers.
                splitc_dic = {}
                c_all_hits = 0
                for site_id in site2hitc_dic:
                    hitc = site2hitc_dic[site_id]
                    c_all_hits += 1
                    if hitc in splitc_dic:
                        splitc_dic[hitc] += 1
                    else:
                        splitc_dic[hitc] = 1
                split_hits_on_genome = False
                # Report mapping stats (split numbers and hit counts).
                print("# motif hits mapped to genome:           %i" %(c_all_hits))
                for hitc in splitc_dic:
                    if hitc == 1:
                        print("# motif hits without split mapping:      %i" %(splitc_dic[hitc]))
                    else:
                        print("# motif hits with split mapping (split in %i):  %i" %(hitc, splitc_dic[hitc]))
                        split_hits_on_genome = True

            c_tr_sites = len(tr_seqs_dic)

            # Summary.
            tr_ratio = "%.5f" %((c_tr_hits / c_tr_seqs_len) * 1000)
            print("--motif:                      %s" %(args.in_regex))
            print("# --in transcripts:           %i" %(c_tr_sites))
            print("--in total sequence length:   %i" %(c_tr_seqs_len))
            print("# motif hits on transcripts:  %i" %(c_tr_hits))
            print("Ratio (# hits / 1000 nt):     %s" %(tr_ratio))
            if args.out_folder:
                print("Motif hits transcript BED:\n%s" %(hits_on_transcripts_bed))
                print("Motif hits transcript FASTA:\n%s" %(hits_on_transcripts_fa))
                if split_hits_on_genome:
                    print("Motif hits (split and full hits) on genome BED:\n%s" %(gen_all_bed))
                    print("Motif hits (split hits only) on genome BED:\n%s" %(gen_split_bed))
                    print("Motif hits (full hits only) on genome BED:\n%s" %(gen_unique_bed))
                else:
                    print("Motif hits on genome BED:\n%s" %(gen_all_bed))
            print("")

        elif col_c == 6:
            # Genomic or transcript region BED given (type 2).
            print("--in BED file assumed ... ")
            # Check for unique IDs.
            assert hoodlib.bed_check_unique_ids(args.in_data), "--in BED file \"%s\" column 4 IDs not unique. Please provide unique IDs" %(args.in_data)
            # Check whether IDs are genomic or transcript.
            print("Check whether --in BED contains transcript or genomic regions ... ")
            random_id = uuid.uuid1()
            tmp_out = str(random_id) + ".chr_lengths"
            chr_len_dic = hoodlib.get_chromosome_lengths_from_2bit(args.in_2bit, tmp_out)
            if os.path.exists(tmp_out):
                os.remove(tmp_out)
            chr_ids_dic = hoodlib.bed_get_chromosome_ids(args.in_data)
            transcript_regions = False
            for chr_id in chr_ids_dic:
                if chr_id not in chr_len_dic:
                    transcript_regions = True
                    break
            # --in are transcript regions case.
            if transcript_regions:
                # Demand pure transcript or genomic sites --in BED.
                for chr_id in chr_ids_dic:
                    assert chr_id not in chr_len_dic, "chromosome and non-chromosome IDs encountered in --in BED column 1. --in column 1 must contain either chromsome or transcript IDs (conflicting IDs: \"%s\", \"%s\")" %(transcript_regions, chr_id)
                print("No chromosome IDs found in --in, interpret column 1 IDs as transcript IDs ... ")
                # Read in transcript lengths from --gtf.
                print("Get transcript lengths from --gtf ... ")
                tr_len_dic = hoodlib.gtf_get_transcript_lengths(args.in_gtf)
                print("Verifying transcript IDs by checking their presence in --gtf ... ")
                for tr_id in chr_ids_dic:
                    assert tr_id in tr_len_dic, "--in column 1 transcript ID \"%s\" not found in --gtf" %(tr_id)
                # Get spliced transcript sequences from gtf+2bit.
                print("Get transcript sequences from --gtf and --gen ... ")
                tr_seqs_dic = hoodlib.get_transcript_sequences_from_gtf(args.in_gtf, args.in_2bit,
                                                                       tr_ids_dic=chr_ids_dic)
                # Search for motif in sequences.
                tr_reg_dic = hoodlib.bed_read_rows_into_dic(args.in_data, to_list=True,
                                                            check_chr_id_format=False)

                if args.out_folder:
                    # Motif hits BED files.
                    hits_on_transcripts_bed = args.out_folder + "/" + "motif_hits_on_transcript_regions.bed"
                    hits_on_transcripts_fa = args.out_folder + "/" + "motif_hits_on_transcript_regions.fa"
                    # Generate results output folder.
                    if not os.path.exists(args.out_folder):
                        os.makedirs(args.out_folder)
                    THOUT = open(hits_on_transcripts_bed, "w")
                    THFOUT = open(hits_on_transcripts_fa, "w")

                c_tr_hits = 0
                c_tr_reg_len = 0
                for reg_id in tr_reg_dic:
                    tr_id = tr_reg_dic[reg_id][0] # Transcript ID.
                    tr_s = tr_reg_dic[reg_id][1] # Region start.
                    tr_e = tr_reg_dic[reg_id][2] # Region end.
                    assert tr_s < tr_e, "--in start >= end position for region %s" %(reg_id)
                    seq = tr_seqs_dic[tr_id][tr_s:tr_e] # Get region sequence.
                    c_tr_reg_len += len(seq)
                    seq_id_hit_c = 0
                    for match in re.finditer(args.in_regex, seq):
                        c_tr_hits += 1
                        seq_id_hit_c += 1
                        hit = match.group()
                        hit_s = match.start() # 0-based.
                        hit_e = match.end() # 1-based.

                        # Hit transcript coordinates.
                        hit_tr_s = tr_s + hit_s
                        hit_tr_e = tr_s + hit_e

                        # Output motif hit on transcript to BED.
                        motif_id = reg_id + "_" + str(seq_id_hit_c)
                        if args.out_folder:
                            THOUT.write("%s\t%i\t%i\t%s\t0\t+\n" %(tr_id, hit_tr_s, hit_tr_e, motif_id))
                            THFOUT.write(">%s\n%s\n" %(motif_id, hit))

                if args.out_folder:
                    THOUT.close()
                    THFOUT.close()

                if not c_tr_hits:
                    print("No motif hits on --in transcript regions")
                    sys.exit()

                if args.out_folder:
                    # Map transcript hits to genome.
                    print("Mapping motif hits on transcripts to genome ... ")
                    site2hitc_dic = {}
                    hoodlib.bed_convert_transcript_to_genomic_sites(hits_on_transcripts_bed, args.in_gtf,
                                                                    args.out_folder,
                                                                    site2hitc_dic=site2hitc_dic,
                                                                    out_folder=True)
                    assert site2hitc_dic, "site ID to hit count dictionary empty"

                    # Rename output files.
                    out_all_hits_bed = args.out_folder + "/" + "all_hits.bed"
                    out_unique_hits_bed = args.out_folder + "/" + "unique_hits.bed"
                    out_split_hits_bed = args.out_folder + "/" + "split_hits.bed"
                    gen_all_bed = args.out_folder + "/" + "all_hits_on_genome.bed"
                    gen_unique_bed = args.out_folder + "/" + "full_length_hits_on_genome.bed"
                    gen_split_bed = args.out_folder + "/" + "split_hits_on_genome.bed"
                    hoodlib.move_rename_file(out_all_hits_bed, gen_all_bed)
                    hoodlib.move_rename_file(out_unique_hits_bed, gen_unique_bed)
                    hoodlib.move_rename_file(out_split_hits_bed, gen_split_bed)

                    # Get hit counts and split numbers.
                    splitc_dic = {}
                    c_all_hits = 0
                    for site_id in site2hitc_dic:
                        hitc = site2hitc_dic[site_id]
                        c_all_hits += 1
                        if hitc in splitc_dic:
                            splitc_dic[hitc] += 1
                        else:
                            splitc_dic[hitc] = 1
                    # Report mapping stats (split numbers and hit counts).
                    print("# motif hits mapped to genome:           %i" %(c_all_hits))
                    for hitc in splitc_dic:
                        if hitc == 1:
                            print("# motif hits without split mapping:      %i" %(splitc_dic[hitc]))
                        else:
                            print("# motif hits with split mapping (split in %i):  %i" %(hitc, splitc_dic[hitc]))

                # Summary.
                c_tr_reg = len(tr_reg_dic)
                tr_ratio = "%.5f" %((c_tr_hits / c_tr_reg_len) * 1000)
                print("--motif:                     %s" %(args.in_regex))
                print("--in transcript regions:     %i" %(c_tr_reg))
                print("--in total sequence length:  %i" %(c_tr_reg_len))
                print("# motif hits on regions:     %i" %(c_tr_hits))
                print("Ratio (# hits / 1000 nt):    %s" %(tr_ratio))
                if args.out_folder:
                    print("Motif hits transcript BED:\n%s" %(hits_on_transcripts_bed))
                    print("Motif hits transcript FASTA:\n%s" %(hits_on_transcripts_fa))
                    print("Motif hits (split and full hits) on genome BED:\n%s" %(gen_all_bed))
                print("")

            else:
                # Genomic regions.
                for chr_id in chr_ids_dic:
                    assert chr_id in chr_len_dic, "chromosome and non-chromosome IDs encountered in --in BED column 1 ID \"%s\" is not a valid chromosome ID (not found in --gen)" %(chr_id)
                print("--in column 1 IDs are chromosome IDs, assume genomic regions ... ")
                # Get genomic region sequences.
                print("Get genomic region sequences ... ")
                random_id = uuid.uuid1()
                tmp_fa = str(random_id) + ".tmp.fa"
                hoodlib.bed_extract_sequences_from_2bit(args.in_data, tmp_fa, args.in_2bit)
                gen_seq_dic = hoodlib.read_fasta_into_dic(tmp_fa,
                                                    dna=False,
                                                    skip_n_seqs=False)
                if os.path.exists(tmp_fa):
                    os.remove(tmp_fa)
                # Get BED regions.
                gen_reg_dic = hoodlib.bed_read_rows_into_dic(args.in_data, to_list=True,
                                                             check_chr_id_format=False)
                # Checks.
                for reg_id in gen_reg_dic:
                    assert reg_id in gen_seq_dic, "no sequence extracted for region ID %s" %(reg_id)
                    exp_reg_l = gen_reg_dic[reg_id][2] - gen_reg_dic[reg_id][1]
                    ext_reg_l = len(gen_seq_dic[reg_id])
                    assert exp_reg_l == ext_reg_l, "extracted sequence length != BED region length for region ID %s (%i != %i)" %(reg_id, ext_reg_l, exp_reg_l)

                if args.out_folder:
                    # Motif hits BED files.
                    hits_on_genome_bed = args.out_folder + "/" + "motif_hits_on_genomic_regions.bed"
                    hits_on_genome_fa = args.out_folder + "/" + "motif_hits_on_genomic_regions.fa"
                    # Generate results output folder.
                    if not os.path.exists(args.out_folder):
                        os.makedirs(args.out_folder)
                    GHOUT = open(hits_on_genome_bed, "w")
                    GHFOUT = open(hits_on_genome_fa, "w")

                c_gen_hits = 0
                c_gen_reg_len = 0
                for reg_id in gen_reg_dic:
                    seq = gen_seq_dic[reg_id]
                    c_gen_reg_len += len(seq)
                    chr_id = gen_reg_dic[reg_id][0]
                    gen_s = gen_reg_dic[reg_id][1]
                    gen_e = gen_reg_dic[reg_id][2]
                    gen_pol = gen_reg_dic[reg_id][5]
                    seq_id_hit_c = 0
                    for match in re.finditer(args.in_regex, seq):
                        c_gen_hits += 1
                        seq_id_hit_c += 1
                        hit = match.group()
                        hit_s = match.start()
                        hit_e = match.end()

                        # Hit genomic coordinates.
                        hit_gen_s = gen_s + hit_s
                        hit_gen_e = gen_s + hit_e
                        if gen_pol == "-":
                            hit_gen_s = gen_e - hit_e
                            hit_gen_e = gen_e - hit_s

                        # Output motif hit with its genomic coordinates to BED.
                        motif_id = reg_id + "_" + str(seq_id_hit_c)
                        if args.out_folder:
                            GHOUT.write("%s\t%i\t%i\t%s\t0\t%s\n" %(chr_id, hit_gen_s, hit_gen_e, motif_id, gen_pol))
                            GHFOUT.write(">%s\n%s\n" %(motif_id, hit))

                if args.out_folder:
                    GHOUT.close()
                    GHFOUT.close()

                if not c_gen_hits:
                    print("No motif hits on --in genomic regions")
                    sys.exit()

                # Summary.
                c_gen_reg = len(gen_reg_dic)
                gen_ratio = "%.5f" %( (c_gen_hits / c_gen_reg_len) * 1000 )
                print("--motif:                     %s" %(args.in_regex))
                print("--in genomic regions:        %i" %(c_gen_reg))
                print("--in total sequence length:  %i" %(c_gen_reg_len))
                print("# motif hits on regions:     %i" %(c_gen_hits))
                print("Ratio (# hits / 1000 nt):    %s" %(gen_ratio))
                if args.out_folder:
                    print("Motif hits genome BED:\n%s" %(hits_on_genome_bed))
                    print("Motif hits genome FASTA:\n%s" %(hits_on_genome_fa))
                print("")

        else:
            assert False, "--in file # columns to be expected 6 for (for type 2, BED) or 1 (for type 3, transcript list)"


################################################################################

if __name__ == '__main__':
    # Setup argparse.
    parser = setup_argument_parser()
    # Print help if no parameter is set.
    if len(sys.argv) < 2:
        parser.print_help()
        sys.exit()
    # Read in command line arguments.
    args = parser.parse_args()

    # Show some banner.
    print(hoodlib.print_some_banner())

    # Are my tools ready?
    assert hoodlib.is_tool("bedtools"), "bedtools not in PATH"
    assert hoodlib.is_tool("twoBitToFa"), "twoBitToFa not in PATH"
    assert hoodlib.is_tool("twoBitInfo"), "twoBitInfo not in PATH"

    # Run selected mode.
    if args.which == 'extract':
        main_extract(args)
    elif args.which == 'motif':
        main_motif(args)
    elif args.which == 'merge':
        main_merge(args)
    elif args.which == 'batch':
        main_batch(args)


################################################################################
